{
    "matches": {
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/src/scripts/conv-autoconfig.h.in": "/* conv-autoconfig.h.in.  Generated from configure.ac by autoheader.  */\n\n/* disable ampi fatal error return */\n#undef AMPI_ERRHANDLER_RETURN\n\n/* enable ampi error checking */\n#undef AMPI_ERROR_CHECKING\n\n/* Charm++ Release/API version number */\n#undef CHARM_VERSION\n\n/* whether Cray gni_pub has GNI_GetBIConfig */\n#undef CMK_BALANCED_INJECTION_API\n\n/* bproc version */\n#undef CMK_BPROC_VERSION\n\n/* build MPI. */\n#undef CMK_BUILD_ON_MPI\n\n/* build OFI. */\n#undef CMK_BUILD_ON_OFI\n\n/* build UCX. */\n#undef CMK_BUILD_ON_UCX\n\n/* enable ccs */\n#undef CMK_CCS_AVAILABLE\n\n/* enable charmdebug */\n#undef CMK_CHARMDEBUG\n\n/* disable charmpy */\n#undef CMK_CHARMPY\n\n/* enable STL CkSectionInfo */\n#undef CMK_CKSECTIONINFO_STL\n\n/* whether c compiler knows of the c11 standard */\n#undef CMK_COMPILER_KNOWS_C11\n\n/* whether ucontext has pointer */\n#undef CMK_CONTEXT_FPU_POINTER\n\n/* whether ucontext uses uc_regs union */\n#undef CMK_CONTEXT_FPU_POINTER_UCREGS\n\n/* whether ucontext has pointer (v_regs) of vector type */\n#undef CMK_CONTEXT_V_REGS\n\n/* Cray MAXNID */\n#undef CMK_CRAY_MAXNID\n\n/* Disables conflicting macros. */\n#undef CMK_CXX_MPI_BINDINGS\n\n/* whether C inline works in C */\n#undef CMK_C_INLINE\n\n/* whether sync_add_and_fetch primitive works in C */\n#undef CMK_C_SYNC_ADD_AND_FETCH_PRIMITIVE\n\n/* whether sync_synchronize primitives works in C */\n#undef CMK_C_SYNC_SYNCHRONIZE_PRIMITIVE\n\n/* dlopen */\n#undef CMK_DLL_USE_DLOPEN\n\n/* whether getProcAddress works */\n#undef CMK_DLL_USE_WIN32\n\n/* enable drone mode */\n#undef CMK_DRONE_MODE\n\n/* enable error checking */\n#undef CMK_ERROR_CHECKING\n\n/* whether expects __morecore symbol */\n#undef CMK_EXPECTS_MORECORE\n\n/* ALLCAPS */\n#undef CMK_FORTRAN_USES_ALLCAPS\n\n/* NOSCORE */\n#undef CMK_FORTRAN_USES_NOSCORE\n\n/* ONESCORE */\n#undef CMK_FORTRAN_USES_ONESCORE\n\n/* TWOSCORE */\n#undef CMK_FORTRAN_USES_TWOSCORE\n\n/* Allows gcc x86 assembly. */\n#undef CMK_GCC_X86_ASM\n\n/* Allows gcc x86 assembly for atomic increment. */\n#undef CMK_GCC_X86_ASM_ATOMICINCREMENT\n\n/* whether personality() and ADDR_NO_RANDOMIZE exist */\n#undef CMK_HAS_ADDR_NO_RANDOMIZE\n\n/* whether compiler supports std::alignment_of */\n#undef CMK_HAS_ALIGNMENT_OF\n\n/* whether has alloca.h */\n#undef CMK_HAS_ALLOCA_H\n\n/* whether has asctime */\n#undef CMK_HAS_ASCTIME\n\n/* whether the bindprocessor() exists */\n#undef CMK_HAS_BINDPROCESSOR\n\n/* whether supports cma */\n#undef CMK_HAS_CMA\n\n/* whether PAPI exists */\n#undef CMK_HAS_COUNTER_PAPI\n\n/* whether C++ library has <cstdatomic> */\n#undef CMK_HAS_CXX0X_CSTDATOMIC\n\n/* whether C++ library has <atomic> */\n#undef CMK_HAS_CXX11_ATOMIC\n\n/* whether has dlmopen */\n#undef CMK_HAS_DLMOPEN\n\n/* whether has dl_iterate_phdr */\n#undef CMK_HAS_DL_ITERATE_PHDR\n\n/* whether has elf.h */\n#undef CMK_HAS_ELF_H\n\n/* whether has __executable_start */\n#undef CMK_HAS_EXECUTABLE_START\n\n/* whether has fabsf */\n#undef CMK_HAS_FABSF\n\n/* whether has fdatasync */\n#undef CMK_HAS_FDATASYNC_FUNC\n\n/* whether has fsync */\n#undef CMK_HAS_FSYNC_FUNC\n\n/* whether gethostname() exists */\n#undef CMK_HAS_GETHOSTNAME\n\n/* whether getifaddrs() exists */\n#undef CMK_HAS_GETIFADDRS\n\n/* whether getpagesize exists */\n#undef CMK_HAS_GETPAGESIZE\n\n/* whether getpid exists */\n#undef CMK_HAS_GETPID\n\n/* whether has get_myaddress */\n#undef CMK_HAS_GET_MYADDRESS\n\n/* whether any 128-bit integer works */\n#undef CMK_HAS_INT16\n\n/* whether compiler supports std::is_constructible */\n#undef CMK_HAS_IS_CONSTRUCTIBLE\n\n/* whether iterator_traits works */\n#undef CMK_HAS_ITERATOR_TRAITS\n\n/* whether kill exists */\n#undef CMK_HAS_KILL\n\n/* whether has log2 */\n#undef CMK_HAS_LOG2\n\n/* whether has lustrefs */\n#undef CMK_HAS_LUSTREFS\n\n/* whether has mallinfo */\n#undef CMK_HAS_MALLINFO\n\n/* whether has malloc.h */\n#undef CMK_HAS_MALLOC_H\n\n/* whether has __malloc_hook */\n#undef CMK_HAS_MALLOC_HOOK\n\n/* whether the mmap() syscall exists */\n#undef CMK_HAS_MMAP\n\n/* whether mmap() accepts MAP_ANON */\n#undef CMK_HAS_MMAP_ANON\n\n/* whether mmap() accepts MAP_NORESERVE */\n#undef CMK_HAS_MMAP_NORESERVE\n\n/* whether has mprotect */\n#undef CMK_HAS_MPROTECT\n\n/* whether has mstats */\n#undef CMK_HAS_MSTATS\n\n/* whether has Multiprocessing.h */\n#undef CMK_HAS_MULTIPROCESSING_H\n\n/* whether ntohl is available */\n#undef CMK_HAS_NTOHL\n\n/* whether NUMA control related functions exist */\n#undef CMK_HAS_NUMACTRL\n\n/* whether offsetof exists */\n#undef CMK_HAS_OFFSETOF\n\n/* whether PMI_Get_nid exists */\n#undef CMK_HAS_PMI_GET_NID\n\n/* whether has popen */\n#undef CMK_HAS_POPEN\n\n/* whether the pthread_setaffinity_np() exists */\n#undef CMK_HAS_PTHREAD_SETAFFINITY\n\n/* whether Python is installed */\n#undef CMK_HAS_PYTHON\n\n/* whether Cray rca library is available */\n#undef CMK_HAS_RCALIB\n\n/* whether Cray rca has rca_get_max_dimension */\n#undef CMK_HAS_RCA_MAX_DIMENSION\n\n/* whether has readlink */\n#undef CMK_HAS_READLINK\n\n/* whether has realpath */\n#undef CMK_HAS_REALPATH\n\n/* whether compiler implements regex */\n#undef CMK_HAS_REGEX\n\n/* whether has regex.h */\n#undef CMK_HAS_REGEX_H\n\n/* whether has RTLD_DEFAULT */\n#undef CMK_HAS_RTLD_DEFAULT\n\n/* whether has RTLD_NEXT */\n#undef CMK_HAS_RTLD_NEXT\n\n/* whether getrusage accepts RUSAGE_THREAD */\n#undef CMK_HAS_RUSAGE_THREAD\n\n/* whether has sbrk */\n#undef CMK_HAS_SBRK\n\n/* whether the sched_setaffinity() exists */\n#undef CMK_HAS_SETAFFINITY\n\n/* whether the setpriority exists */\n#undef CMK_HAS_SETPRIORITY\n\n/* whether has sleep */\n#undef CMK_HAS_SLEEP\n\n/* whether has socklen_t */\n#undef CMK_HAS_SOCKLEN\n\n/* whether the pthread_spin_lock exists */\n#undef CMK_HAS_SPINLOCK\n\n/* whether has sqrtf */\n#undef CMK_HAS_SQRTF\n\n/* whether has stdint.h */\n#undef CMK_HAS_STDINT_H\n\n/* whether std::distance works */\n#undef CMK_HAS_STD_DISTANCE\n\n/* whether std::inserter works */\n#undef CMK_HAS_STD_INSERTER\n\n/* whether std::void_t works */\n#undef CMK_HAS_STD_VOID_T\n\n/* sync program */\n#undef CMK_HAS_SYNC\n\n/* whether has sync */\n#undef CMK_HAS_SYNC_FUNC\n\n/* whether has system */\n#undef CMK_HAS_SYSTEM\n\n/* Allows __thread. */\n#undef CMK_HAS_TLS_VARIABLES\n\n/* whether typeinfo/typeid works */\n#undef CMK_HAS_TYPEINFO\n\n/* whether has _setjmp/_longjmp */\n#undef CMK_HAS_UNDERSCORE_SETJMP\n\n/* whether has usleep */\n#undef CMK_HAS_USLEEP\n\n/* whether has values.h */\n#undef CMK_HAS_VALUES_H\n\n/* whether ibv_port_attr has link_layer field */\n#undef CMK_IBV_PORT_ATTR_HAS_LINK_LAYER\n\n/* enable 64 bit LB ID */\n#undef CMK_LBID_64BIT\n\n/* Setting load balancing timer type */\n#undef CMK_LBTIME_TYPE\n\n/* disable lb user data */\n#undef CMK_LB_USER_DATA\n\n/* enable lockless queue for pe/node queue */\n#undef CMK_LOCKLESS_QUEUE\n\n/* whether long double works */\n#undef CMK_LONG_DOUBLE_DEFINED\n\n/* whether long long works */\n#undef CMK_LONG_LONG_DEFINED\n\n/* machine name */\n#undef CMK_MACHINE_NAME\n\n/* mempool cutoff */\n#undef CMK_MEMPOOL_CUTOFFNUM\n\n/* Allows MPI_Init_thread. */\n#undef CMK_MPI_INIT_THREAD\n\n/* expected message priorities are arbitrarily sized */\n#undef CMK_MSG_PRIO_TYPE\n\n/* whether operator delete can be overloaded in same class */\n#undef CMK_MULTIPLE_DELETE\n\n/* OS is Linux */\n#undef CMK_OS_IS_LINUX\n\n/* whether is power7 */\n#undef CMK_POWER7\n\n/* Allows asm eieio assembly. */\n#undef CMK_PPC_ASM\n\n/* Python version */\n#undef CMK_PYTHON_VERSION\n\n/* disable the randomized msgq in the scheduler */\n#undef CMK_RANDOMIZED_MSGQ\n\n/* envelope refnum field set to UInt */\n#undef CMK_REFNUM_TYPE\n\n/* enable replay */\n#undef CMK_REPLAYSYSTEM\n\n/* disable shrinkexpand */\n#undef CMK_SHRINK_EXPAND\n\n/* whether C++ signed char and char differ */\n#undef CMK_SIGNEDCHAR_DIFF_CHAR\n\n/* whether to use signal-safe system() */\n#undef CMK_SIGSAFE_SYSTEM\n\n/* whether size_t 64bit */\n#undef CMK_SIZET_64BIT\n\n/* disable tracing comm thread */\n#undef CMK_SMP_TRACE_COMMTHREAD\n\n/* whether supports filesystem globals */\n#undef CMK_SUPPORTS_FSGLOBALS\n\n/* whether supports PiP globals */\n#undef CMK_SUPPORTS_PIPGLOBALS\n\n/* enable task queue */\n#undef CMK_TASKQUEUE\n\n/* Allows switching TLS on x86. */\n#undef CMK_TLS_SWITCHING_X86\n\n/* Allows switching TLS on x86_64. */\n#undef CMK_TLS_SWITCHING_X86_64\n\n/* enable tracing */\n#undef CMK_TRACE_ENABLED\n\n/* whether glibc backtrace works */\n#undef CMK_USE_BACKTRACE\n\n/* whether has libjpeg */\n#undef CMK_USE_LIBJPEG\n\n/* whether has mkstemp */\n#undef CMK_USE_MKSTEMP\n\n/* whether the poll syscall exists */\n#undef CMK_USE_POLL\n\n/* whether charm scheduler should use an STL-based msg q */\n#undef CMK_USE_STL_MSGQ\n\n/* whether has zlib */\n#undef CMK_USE_ZLIB\n\n/* disable controlpoint */\n#undef CMK_WITH_CONTROLPOINT\n\n/* enable statistics collection */\n#undef CMK_WITH_STATS\n\n/* whether __int128 works */\n#undef CMK___int128_DEFINED\n\n/* whether __int128_t works */\n#undef CMK___int128_t_DEFINED\n\n/* whether __int64 works */\n#undef CMK___int64_DEFINED\n\n/* Define to 1 if the system has the type `CACHE_DESCRIPTOR'. */\n#undef HAVE_CACHE_DESCRIPTOR\n\n/* Define to 1 if the system has the type `CACHE_RELATIONSHIP'. */\n#undef HAVE_CACHE_RELATIONSHIP\n\n/* Define to 1 if you have the `clz' function. */\n#undef HAVE_CLZ\n\n/* Define to 1 if you have the `clzl' function. */\n#undef HAVE_CLZL\n\n/* Define to 1 if you have the <CL/cl_ext.h> header file. */\n#undef HAVE_CL_CL_EXT_H\n\n/* Define to 1 if you have the `cpuset_setaffinity' function. */\n#undef HAVE_CPUSET_SETAFFINITY\n\n/* Define to 1 if you have the `cpuset_setid' function. */\n#undef HAVE_CPUSET_SETID\n\n/* Define to 1 if you have the <ctype.h> header file. */\n#undef HAVE_CTYPE_H\n\n/* Define to 1 if we have -lcuda */\n#undef HAVE_CUDA\n\n/* Define to 1 if you have the <cuda.h> header file. */\n#undef HAVE_CUDA_H\n\n/* Define to 1 if you have the <cuda_runtime_api.h> header file. */\n#undef HAVE_CUDA_RUNTIME_API_H\n\n/* Define to 1 if you have the declaration of `CL_DEVICE_TOPOLOGY_AMD', and to\n   0 if you don't. */\n#undef HAVE_DECL_CL_DEVICE_TOPOLOGY_AMD\n\n/* Define to 1 if you have the declaration of `CTL_HW', and to 0 if you don't.\n   */\n#undef HAVE_DECL_CTL_HW\n\n/* Define to 1 if you have the declaration of `fabsf', and to 0 if you don't.\n   */\n#undef HAVE_DECL_FABSF\n\n/* Define to 1 if you have the declaration of `getexecname', and to 0 if you\n   don't. */\n#undef HAVE_DECL_GETEXECNAME\n\n/* Define to 1 if you have the declaration of `GetModuleFileName', and to 0 if\n   you don't. */\n#undef HAVE_DECL_GETMODULEFILENAME\n\n/* Define to 1 if you have the declaration of `getprogname', and to 0 if you\n   don't. */\n#undef HAVE_DECL_GETPROGNAME\n\n/* Define to 1 if you have the declaration of `HW_NCPU', and to 0 if you\n   don't. */\n#undef HAVE_DECL_HW_NCPU\n\n/* Define to 1 if you have the declaration of `lgrp_latency_cookie', and to 0\n   if you don't. */\n#undef HAVE_DECL_LGRP_LATENCY_COOKIE\n\n/* Define to 1 if you have the declaration of `modff', and to 0 if you don't.\n   */\n#undef HAVE_DECL_MODFF\n\n/* Define to 1 if you have the declaration of\n   `nvmlDeviceGetMaxPcieLinkGeneration', and to 0 if you don't. */\n#undef HAVE_DECL_NVMLDEVICEGETMAXPCIELINKGENERATION\n\n/* Define to 1 if you have the declaration of `pthread_getaffinity_np', and to\n   0 if you don't. */\n#undef HAVE_DECL_PTHREAD_GETAFFINITY_NP\n\n/* Define to 1 if you have the declaration of `pthread_setaffinity_np', and to\n   0 if you don't. */\n#undef HAVE_DECL_PTHREAD_SETAFFINITY_NP\n\n/* Embedded mode; just assume we do not have Valgrind support */\n#undef HAVE_DECL_RUNNING_ON_VALGRIND\n\n/* Define to 1 if you have the declaration of `sched_getcpu', and to 0 if you\n   don't. */\n#undef HAVE_DECL_SCHED_GETCPU\n\n/* Define to 1 if you have the declaration of `snprintf', and to 0 if you\n   don't. */\n#undef HAVE_DECL_SNPRINTF\n\n/* Define to 1 if you have the declaration of `strtoull', and to 0 if you\n   don't. */\n#undef HAVE_DECL_STRTOULL\n\n/* Define to 1 if you have the declaration of `_putenv', and to 0 if you\n   don't. */\n#undef HAVE_DECL__PUTENV\n\n/* Define to 1 if you have the declaration of `_SC_LARGE_PAGESIZE', and to 0\n   if you don't. */\n#undef HAVE_DECL__SC_LARGE_PAGESIZE\n\n/* Define to 1 if you have the declaration of `_SC_NPROCESSORS_CONF', and to 0\n   if you don't. */\n#undef HAVE_DECL__SC_NPROCESSORS_CONF\n\n/* Define to 1 if you have the declaration of `_SC_NPROCESSORS_ONLN', and to 0\n   if you don't. */\n#undef HAVE_DECL__SC_NPROCESSORS_ONLN\n\n/* Define to 1 if you have the declaration of `_SC_NPROC_CONF', and to 0 if\n   you don't. */\n#undef HAVE_DECL__SC_NPROC_CONF\n\n/* Define to 1 if you have the declaration of `_SC_NPROC_ONLN', and to 0 if\n   you don't. */\n#undef HAVE_DECL__SC_NPROC_ONLN\n\n/* Define to 1 if you have the declaration of `_SC_PAGESIZE', and to 0 if you\n   don't. */\n#undef HAVE_DECL__SC_PAGESIZE\n\n/* Define to 1 if you have the declaration of `_SC_PAGE_SIZE', and to 0 if you\n   don't. */\n#undef HAVE_DECL__SC_PAGE_SIZE\n\n/* Define to 1 if you have the declaration of `_strdup', and to 0 if you\n   don't. */\n#undef HAVE_DECL__STRDUP\n\n/* Define to 1 if you have the <dirent.h> header file. */\n#undef HAVE_DIRENT_H\n\n/* Define to 1 if you have the <dlfcn.h> header file. */\n#undef HAVE_DLFCN_H\n\n/* Define to 1 if you have the `ffs' function. */\n#undef HAVE_FFS\n\n/* Define to 1 if you have the `ffsl' function. */\n#undef HAVE_FFSL\n\n/* Define to 1 if you have the `fls' function. */\n#undef HAVE_FLS\n\n/* Define to 1 if you have the `flsl' function. */\n#undef HAVE_FLSL\n\n/* Define to 1 if you have the `getpagesize' function. */\n#undef HAVE_GETPAGESIZE\n\n/* Define to 1 if the system has the type `GROUP_AFFINITY'. */\n#undef HAVE_GROUP_AFFINITY\n\n/* Define to 1 if the system has the type `GROUP_RELATIONSHIP'. */\n#undef HAVE_GROUP_RELATIONSHIP\n\n/* Define to 1 if you have the `host_info' function. */\n#undef HAVE_HOST_INFO\n\n/* Define to 1 if you have the <inttypes.h> header file. */\n#undef HAVE_INTTYPES_H\n\n/* Define to 1 if the system has the type `KAFFINITY'. */\n#undef HAVE_KAFFINITY\n\n/* Define to 1 if you have the <kstat.h> header file. */\n#undef HAVE_KSTAT_H\n\n/* Define to 1 if we have -lgdi32 */\n#undef HAVE_LIBGDI32\n\n/* Define to 1 if we have -lkstat */\n#undef HAVE_LIBKSTAT\n\n/* Define to 1 if we have -llgrp */\n#undef HAVE_LIBLGRP\n\n/* Define to 1 if you have the <libudev.h> header file. */\n#undef HAVE_LIBUDEV_H\n\n/* Define to 1 if the system has the type `LOGICAL_PROCESSOR_RELATIONSHIP'. */\n#undef HAVE_LOGICAL_PROCESSOR_RELATIONSHIP\n\n/* Define to 1 if you have the <mach/mach_host.h> header file. */\n#undef HAVE_MACH_MACH_HOST_H\n\n/* Define to 1 if you have the <mach/mach_init.h> header file. */\n#undef HAVE_MACH_MACH_INIT_H\n\n/* Define to 1 if you have the <malloc.h> header file. */\n#undef HAVE_MALLOC_H\n\n/* Define to 1 if you have the `memalign' function. */\n#undef HAVE_MEMALIGN\n\n/* Define to 1 if you have the <memory.h> header file. */\n#undef HAVE_MEMORY_H\n\n/* Define to 1 if you have the <numaif.h> header file. */\n#undef HAVE_NUMAIF_H\n\n/* Define to 1 if the system has the type `NUMA_NODE_RELATIONSHIP'. */\n#undef HAVE_NUMA_NODE_RELATIONSHIP\n\n/* Define to 1 if you have the <NVCtrl/NVCtrl.h> header file. */\n#undef HAVE_NVCTRL_NVCTRL_H\n\n/* Define to 1 if you have the <nvml.h> header file. */\n#undef HAVE_NVML_H\n\n/* Define to 1 if you have the `openat' function. */\n#undef HAVE_OPENAT\n\n/* Define to 1 if you have the <OpenCL/cl_ext.h> header file. */\n#undef HAVE_OPENCL_CL_EXT_H\n\n/* Define to 1 if you have the <picl.h> header file. */\n#undef HAVE_PICL_H\n\n/* Define to 1 if you have the `posix_memalign' function. */\n#undef HAVE_POSIX_MEMALIGN\n\n/* Define to 1 if the system has the type `PROCESSOR_CACHE_TYPE'. */\n#undef HAVE_PROCESSOR_CACHE_TYPE\n\n/* Define to 1 if the system has the type `PROCESSOR_GROUP_INFO'. */\n#undef HAVE_PROCESSOR_GROUP_INFO\n\n/* Define to 1 if the system has the type `PROCESSOR_NUMBER'. */\n#undef HAVE_PROCESSOR_NUMBER\n\n/* Define to 1 if the system has the type `PROCESSOR_RELATIONSHIP'. */\n#undef HAVE_PROCESSOR_RELATIONSHIP\n\n/* Define to '1' if program_invocation_name is present and usable */\n#undef HAVE_PROGRAM_INVOCATION_NAME\n\n/* Define to 1 if the system has the type `PSAPI_WORKING_SET_EX_BLOCK'. */\n#undef HAVE_PSAPI_WORKING_SET_EX_BLOCK\n\n/* Define to 1 if the system has the type `PSAPI_WORKING_SET_EX_INFORMATION'.\n   */\n#undef HAVE_PSAPI_WORKING_SET_EX_INFORMATION\n\n/* Define to 1 if you have the <pthread_np.h> header file. */\n#undef HAVE_PTHREAD_NP_H\n\n/* Define to 1 if the system has the type `pthread_t'. */\n#undef HAVE_PTHREAD_T\n\n/* Define to 1 if the system has the type `RelationProcessorPackage'. */\n#undef HAVE_RELATIONPROCESSORPACKAGE\n\n/* Define to 1 if you have the `setlocale' function. */\n#undef HAVE_SETLOCALE\n\n/* Define to 1 if the system has the type `ssize_t'. */\n#undef HAVE_SSIZE_T\n\n/* Define to 1 if you have the <stdint.h> header file. */\n#undef HAVE_STDINT_H\n\n/* Define to 1 if you have the <stdlib.h> header file. */\n#undef HAVE_STDLIB_H\n\n/* Define to 1 if you have the `strcasecmp' function. */\n#undef HAVE_STRCASECMP\n\n/* Define to 1 if you have the `strftime' function. */\n#undef HAVE_STRFTIME\n\n/* Define to 1 if you have the <strings.h> header file. */\n#undef HAVE_STRINGS_H\n\n/* Define to 1 if you have the <string.h> header file. */\n#undef HAVE_STRING_H\n\n/* Define to 1 if you have the `strncasecmp' function. */\n#undef HAVE_STRNCASECMP\n\n/* Define to 1 if you have the `strtoull' function. */\n#undef HAVE_STRTOULL\n\n/* Define to '1' if sysctl is present and usable */\n#undef HAVE_SYSCTL\n\n/* Define to '1' if sysctlbyname is present and usable */\n#undef HAVE_SYSCTLBYNAME\n\n/* Define to 1 if the system has the type\n   `SYSTEM_LOGICAL_PROCESSOR_INFORMATION'. */\n#undef HAVE_SYSTEM_LOGICAL_PROCESSOR_INFORMATION\n\n/* Define to 1 if the system has the type\n   `SYSTEM_LOGICAL_PROCESSOR_INFORMATION_EX'. */\n#undef HAVE_SYSTEM_LOGICAL_PROCESSOR_INFORMATION_EX\n\n/* Define to 1 if you have the <sys/cpuset.h> header file. */\n#undef HAVE_SYS_CPUSET_H\n\n/* Define to 1 if you have the <sys/lgrp_user.h> header file. */\n#undef HAVE_SYS_LGRP_USER_H\n\n/* Define to 1 if you have the <sys/mman.h> header file. */\n#undef HAVE_SYS_MMAN_H\n\n/* Define to 1 if you have the <sys/param.h> header file. */\n#undef HAVE_SYS_PARAM_H\n\n/* Define to 1 if you have the <sys/stat.h> header file. */\n#undef HAVE_SYS_STAT_H\n\n/* Define to 1 if you have the <sys/sysctl.h> header file. */\n#undef HAVE_SYS_SYSCTL_H\n\n/* Define to 1 if you have the <sys/types.h> header file. */\n#undef HAVE_SYS_TYPES_H\n\n/* Define to 1 if you have the <sys/utsname.h> header file. */\n#undef HAVE_SYS_UTSNAME_H\n\n/* Define to 1 if you have the `uname' function. */\n#undef HAVE_UNAME\n\n/* Define to 1 if you have the <unistd.h> header file. */\n#undef HAVE_UNISTD_H\n\n/* Define to 1 if you have the <valgrind/valgrind.h> header file. */\n#undef HAVE_VALGRIND_VALGRIND_H\n\n/* Define to 1 if you have the <X11/keysym.h> header file. */\n#undef HAVE_X11_KEYSYM_H\n\n/* Define to 1 if you have the <X11/Xlib.h> header file. */\n#undef HAVE_X11_XLIB_H\n\n/* Define to 1 if you have the <X11/Xutil.h> header file. */\n#undef HAVE_X11_XUTIL_H\n\n/* Define to '1' if __progname is present and usable */\n#undef HAVE___PROGNAME\n\n/* Define to 1 on AIX */\n#undef HWLOC_AIX_SYS\n\n/* Define to 1 on BlueGene/Q */\n#undef HWLOC_BGQ_SYS\n\n/* Whether C compiler supports symbol visibility or not */\n#undef HWLOC_C_HAVE_VISIBILITY\n\n/* Define to 1 on Darwin */\n#undef HWLOC_DARWIN_SYS\n\n/* Whether we are in debugging mode or not */\n#undef HWLOC_DEBUG\n\n/* Define to 1 on *FREEBSD */\n#undef HWLOC_FREEBSD_SYS\n\n/* Whether your compiler has __attribute__ or not */\n#undef HWLOC_HAVE_ATTRIBUTE\n\n/* Whether your compiler has __attribute__ aligned or not */\n#undef HWLOC_HAVE_ATTRIBUTE_ALIGNED\n\n/* Whether your compiler has __attribute__ always_inline or not */\n#undef HWLOC_HAVE_ATTRIBUTE_ALWAYS_INLINE\n\n/* Whether your compiler has __attribute__ cold or not */\n#undef HWLOC_HAVE_ATTRIBUTE_COLD\n\n/* Whether your compiler has __attribute__ const or not */\n#undef HWLOC_HAVE_ATTRIBUTE_CONST\n\n/* Whether your compiler has __attribute__ deprecated or not */\n#undef HWLOC_HAVE_ATTRIBUTE_DEPRECATED\n\n/* Whether your compiler has __attribute__ format or not */\n#undef HWLOC_HAVE_ATTRIBUTE_FORMAT\n\n/* Whether your compiler has __attribute__ hot or not */\n#undef HWLOC_HAVE_ATTRIBUTE_HOT\n\n/* Whether your compiler has __attribute__ malloc or not */\n#undef HWLOC_HAVE_ATTRIBUTE_MALLOC\n\n/* Whether your compiler has __attribute__ may_alias or not */\n#undef HWLOC_HAVE_ATTRIBUTE_MAY_ALIAS\n\n/* Whether your compiler has __attribute__ nonnull or not */\n#undef HWLOC_HAVE_ATTRIBUTE_NONNULL\n\n/* Whether your compiler has __attribute__ noreturn or not */\n#undef HWLOC_HAVE_ATTRIBUTE_NORETURN\n\n/* Whether your compiler has __attribute__ no_instrument_function or not */\n#undef HWLOC_HAVE_ATTRIBUTE_NO_INSTRUMENT_FUNCTION\n\n/* Whether your compiler has __attribute__ packed or not */\n#undef HWLOC_HAVE_ATTRIBUTE_PACKED\n\n/* Whether your compiler has __attribute__ pure or not */\n#undef HWLOC_HAVE_ATTRIBUTE_PURE\n\n/* Whether your compiler has __attribute__ sentinel or not */\n#undef HWLOC_HAVE_ATTRIBUTE_SENTINEL\n\n/* Whether your compiler has __attribute__ unused or not */\n#undef HWLOC_HAVE_ATTRIBUTE_UNUSED\n\n/* Whether your compiler has __attribute__ warn unused result or not */\n#undef HWLOC_HAVE_ATTRIBUTE_WARN_UNUSED_RESULT\n\n/* Whether your compiler has __attribute__ weak alias or not */\n#undef HWLOC_HAVE_ATTRIBUTE_WEAK_ALIAS\n\n/* Define to 1 if your `ffs' function is known to be broken. */\n#undef HWLOC_HAVE_BROKEN_FFS\n\n/* Define to 1 if you have the `clz' function. */\n#undef HWLOC_HAVE_CLZ\n\n/* Define to 1 if you have the `clzl' function. */\n#undef HWLOC_HAVE_CLZL\n\n/* Define to 1 if the CPU_SET macro works */\n#undef HWLOC_HAVE_CPU_SET\n\n/* Define to 1 if the CPU_SET_S macro works */\n#undef HWLOC_HAVE_CPU_SET_S\n\n/* Define to 1 if you have the `cudart' SDK. */\n#undef HWLOC_HAVE_CUDART\n\n/* Define to 1 if function `clz' is declared by system headers */\n#undef HWLOC_HAVE_DECL_CLZ\n\n/* Define to 1 if function `clzl' is declared by system headers */\n#undef HWLOC_HAVE_DECL_CLZL\n\n/* Define to 1 if function `ffs' is declared by system headers */\n#undef HWLOC_HAVE_DECL_FFS\n\n/* Define to 1 if function `ffsl' is declared by system headers */\n#undef HWLOC_HAVE_DECL_FFSL\n\n/* Define to 1 if function `fls' is declared by system headers */\n#undef HWLOC_HAVE_DECL_FLS\n\n/* Define to 1 if function `flsl' is declared by system headers */\n#undef HWLOC_HAVE_DECL_FLSL\n\n/* Define to 1 if function `strcasecmp' is declared by system headers */\n#undef HWLOC_HAVE_DECL_STRCASECMP\n\n/* Define to 1 if function `strncasecmp' is declared by system headers */\n#undef HWLOC_HAVE_DECL_STRNCASECMP\n\n/* Define to 1 if you have the `ffs' function. */\n#undef HWLOC_HAVE_FFS\n\n/* Define to 1 if you have the `ffsl' function. */\n#undef HWLOC_HAVE_FFSL\n\n/* Define to 1 if you have the `fls' function. */\n#undef HWLOC_HAVE_FLS\n\n/* Define to 1 if you have the `flsl' function. */\n#undef HWLOC_HAVE_FLSL\n\n/* Define to 1 if you have the GL module components. */\n#undef HWLOC_HAVE_GL\n\n/* Define to 1 if you have libudev. */\n#undef HWLOC_HAVE_LIBUDEV\n\n/* Define to 1 if you have the `libxml2' library. */\n#undef HWLOC_HAVE_LIBXML2\n\n/* Define to 1 if building the Linux PCI component */\n#undef HWLOC_HAVE_LINUXPCI\n\n/* Define to 1 if mbind is available. */\n#undef HWLOC_HAVE_MBIND\n\n/* Define to 1 if migrate_pages is available. */\n#undef HWLOC_HAVE_MIGRATE_PAGES\n\n/* Define to 1 if move_pages is available. */\n#undef HWLOC_HAVE_MOVE_PAGES\n\n/* Define to 1 if you have the `NVML' library. */\n#undef HWLOC_HAVE_NVML\n\n/* Define to 1 if glibc provides the old prototype (without length) of\n   sched_setaffinity() */\n#undef HWLOC_HAVE_OLD_SCHED_SETAFFINITY\n\n/* Define to 1 if you have the `OpenCL' library. */\n#undef HWLOC_HAVE_OPENCL\n\n/* Define to 1 if the hwloc library should support dynamically-loaded plugins\n   */\n#undef HWLOC_HAVE_PLUGINS\n\n/* `Define to 1 if you have pthread_getthrds_np' */\n#undef HWLOC_HAVE_PTHREAD_GETTHRDS_NP\n\n/* Define to 1 if pthread mutexes are available */\n#undef HWLOC_HAVE_PTHREAD_MUTEX\n\n/* Define to 1 if glibc provides a prototype of sched_setaffinity() */\n#undef HWLOC_HAVE_SCHED_SETAFFINITY\n\n/* Define to 1 if set_mempolicy is available. */\n#undef HWLOC_HAVE_SET_MEMPOLICY\n\n/* Define to 1 if you have the <stdint.h> header file. */\n#undef HWLOC_HAVE_STDINT_H\n\n/* Define to 1 if function `syscall' is available */\n#undef HWLOC_HAVE_SYSCALL\n\n/* Define to 1 if you have the `windows.h' header. */\n#undef HWLOC_HAVE_WINDOWS_H\n\n/* Define to 1 if X11 headers including Xutil.h and keysym.h are available. */\n#undef HWLOC_HAVE_X11_KEYSYM\n\n/* Define to 1 if you have x86 cpuid */\n#undef HWLOC_HAVE_X86_CPUID\n\n/* Define to 1 on HP-UX */\n#undef HWLOC_HPUX_SYS\n\n/* Define to 1 on Irix */\n#undef HWLOC_IRIX_SYS\n\n/* Define to 1 on Linux */\n#undef HWLOC_LINUX_SYS\n\n/* Define to 1 on *NETBSD */\n#undef HWLOC_NETBSD_SYS\n\n/* Define to 1 on OSF */\n#undef HWLOC_OSF_SYS\n\n/* The size of `unsigned int', as computed by sizeof */\n#undef HWLOC_SIZEOF_UNSIGNED_INT\n\n/* The size of `unsigned long', as computed by sizeof */\n#undef HWLOC_SIZEOF_UNSIGNED_LONG\n\n/* Define to 1 on Solaris */\n#undef HWLOC_SOLARIS_SYS\n\n/* The hwloc symbol prefix */\n#undef HWLOC_SYM_PREFIX\n\n/* The hwloc symbol prefix in all caps */\n#undef HWLOC_SYM_PREFIX_CAPS\n\n/* Whether we need to re-define all the hwloc public symbols or not */\n#undef HWLOC_SYM_TRANSFORM\n\n/* Define to 1 on unsupported systems */\n#undef HWLOC_UNSUPPORTED_SYS\n\n/* The library version, always available, even in embedded mode, contrary to\n   VERSION */\n#undef HWLOC_VERSION\n\n/* Define to 1 on WINDOWS */\n#undef HWLOC_WIN_SYS\n\n/* Define to 1 on x86_32 */\n#undef HWLOC_X86_32_ARCH\n\n/* Define to 1 on x86_64 */\n#undef HWLOC_X86_64_ARCH\n\n/* Define to the sub-directory where libtool stores uninstalled libraries. */\n#undef LT_OBJDIR\n\n/* Define to the address where bug reports for this package should be sent. */\n#undef PACKAGE_BUGREPORT\n\n/* Define to the full name of this package. */\n#undef PACKAGE_NAME\n\n/* Define to the full name and version of this package. */\n#undef PACKAGE_STRING\n\n/* Define to the one symbol short name of this package. */\n#undef PACKAGE_TARNAME\n\n/* Define to the home page for this package. */\n#undef PACKAGE_URL\n\n/* Define to the version of this package. */\n#undef PACKAGE_VERSION\n\n/* enable qlogic */\n#undef QLOGIC\n\n/* The size of `unsigned int', as computed by sizeof. */\n#undef SIZEOF_UNSIGNED_INT\n\n/* The size of `unsigned long', as computed by sizeof. */\n#undef SIZEOF_UNSIGNED_LONG\n\n/* The size of `void *', as computed by sizeof. */\n#undef SIZEOF_VOID_P\n\n/* Define to 1 if you have the ANSI C header files. */\n#undef STDC_HEADERS\n\n/* Enable extensions on HP-UX. */\n#ifndef _HPUX_SOURCE\n# undef _HPUX_SOURCE\n#endif\n\n\n/* Enable extensions on AIX 3, Interix.  */\n#ifndef _ALL_SOURCE\n# undef _ALL_SOURCE\n#endif\n/* Enable GNU extensions on systems that have them.  */\n#ifndef _GNU_SOURCE\n# undef _GNU_SOURCE\n#endif\n/* Enable threading extensions on Solaris.  */\n#ifndef _POSIX_PTHREAD_SEMANTICS\n# undef _POSIX_PTHREAD_SEMANTICS\n#endif\n/* Enable extensions on HP NonStop.  */\n#ifndef _TANDEM_SOURCE\n# undef _TANDEM_SOURCE\n#endif\n/* Enable general extensions on Solaris.  */\n#ifndef __EXTENSIONS__\n# undef __EXTENSIONS__\n#endif\n\n\n/* Define to 1 if the X Window System is missing or not being used. */\n#undef X_DISPLAY_MISSING\n\n/* Are we building for HP-UX? */\n#undef _HPUX_SOURCE\n\n/* Define to 1 if on MINIX. */\n#undef _MINIX\n\n/* Define to 2 if the system does not provide POSIX.1 features except with\n   this defined. */\n#undef _POSIX_1_SOURCE\n\n/* Define to 1 if you need to in order for `stat' and other things to work. */\n#undef _POSIX_SOURCE\n\n/* Define this to the process ID type */\n#undef hwloc_pid_t\n\n/* Define this to the thread ID type */\n#undef hwloc_thread_t\n",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/src/scripts/configure.ac": "# Decimal representation of Charm++ release line and API revision\n# Increment the last 2 digits when making an API change\n# Increase the first three after branching for a release\n\nAC_INIT(Charm++, 61002, [charm@cs.illinois.edu], charm, [http://charm.cs.illinois.edu/])\n\nAC_CONFIG_SRCDIR(./Makefile)\n\nAC_CONFIG_HEADER(conv-autoconfig.h)\n\nAC_CONFIG_COMMANDS([config-cleanup],\n                   [sed -i -e 's:^#define\\s\\+PACKAGE://&:' conv-autoconfig.h])\n\nget_full_command_name()\n{\n    if test \"$(basename \"$*\")\" != \"$*\"; then\n        echo \"$(cd \"$(dirname \"$*\")\" && pwd)/$(basename \"$*\")\"\n    else\n        echo \"$*\"\n    fi\n}\n\nConvSh='../tmp/conv-mach-opt.sh'\nConvMak='../tmp/conv-mach-opt.mak'\n\n#clean up conv-mach-opt.sh\nsed -e '/Option added by configure/d' \"$ConvSh\" | sed -e '/^$/d' > conv-mach-opt.sh.clean\ncp -f conv-mach-opt.sh.clean   \"$ConvSh\"\nrm -f conv-mach-opt.sh.clean\n\n#clean up conv-mach-opt.mak\nsed -e '/Option added by configure/d' \"$ConvMak\" | sed -e '/^$/d' > conv-mach-opt.mak.clean\ncp -f conv-mach-opt.mak.clean   \"$ConvMak\"\nrm -f conv-mach-opt.mak.clean\n\nCHARMINC=\".\"\nCHARMBIN=\"../bin\"\ntest -r ./conv-config.sh && . ./conv-config.sh\n\necho AC_PACKAGE_VERSION > ../include/VERSION\nAC_DEFINE_UNQUOTED([CHARM_VERSION], AC_PACKAGE_VERSION, [Charm++ Release/API version number])\n\ncharmout=\"charmconfig.out\"\n/bin/rm -rf $charmout\nMAKEFILE_EXT=Make.extlib\n\nEcho() {\n\techo $* \n\techo $* >> $charmout\n}\n\n# add into conv-mach-opt.sh\n# add_flag $1 $2\n# $2 is description\nadd_flag() {\n        key=$1\n        key=\"${key%%=*}\"\n        last=`grep -w \"$key\" \"$ConvSh\" 2>/dev/null | tail -1 | sed -e 's/ *#.*$//'`\n        skip=0\n\tif test -n \"$last\" -a  \"$last\" = \"$1\" \n\tthen\n\t  skip=1\n        fi\n\tif test $skip = 0\n        then\n\t  cat >> \"$ConvSh\" << EOT\n\n$1   # Option added by configure script's $2 section\nEOT\n\tfi\n}\n\n# remove_flag $1\nremove_flag() {\n     sed -e '/^'\"$1\"'=/d' \"$ConvSh\" > tmp.$$\n     cp tmp.$$ \"$ConvSh\"\n     /bin/rm -f tmp.$$\n}\n\n# add into conv-mach-opt.mak\n# add_make_flag $1 $2\n# $2 is description\nadd_make_flag() {\n        key=$1\n        key=\"${key%%=*}\"\n        key=\"${key%%:*}\"\n        last=`grep -w \"$key\" \"$ConvMak\" 2>/dev/null | tail -1 | sed -e 's/ *#.*$//'`\n        skip=0\n\tif test -n \"$last\" -a  \"$last\" = \"$1\"\n\tthen\n\t  skip=1\n        fi\n\tif test $skip = 0\n        then\n\t  # The lack of whitespace around $1 here is necessary.\n\t  cat >> \"$ConvMak\" << EOT\n\n$1# Option added by configure script's $2 section\nEOT\n\tfi\n}\n\n# remove_make_flag $1\nremove_make_flag() {\n     sed -e '/^'\"$1\"'=/d' \"$ConvMak\" > tmp.$$\n     cp tmp.$$ \"$ConvMak\"\n     /bin/rm -f tmp.$$\n}\n\nadd_flag \"OPTS_CC='$OPTS_CC'\"   'Pass through user-provided C compiler options'\nadd_flag \"OPTS_CXX='$OPTS_CXX'\" 'Pass through user-provided C++ compiler options'\nadd_make_flag \"CMK_COMPILER:=$CMK_COMPILER\" 'basic setup'\nadd_make_flag \"CMK_SMP:=$CMK_SMP\" 'basic setup'\nadd_make_flag \"CMK_SHARED_SUF:=$CMK_SHARED_SUF\" 'basic setup'\nadd_make_flag \"CMK_NO_PARTITIONS:=$CMK_NO_PARTITIONS\" 'basic setup'\nadd_make_flag \"CMK_MACOSX:=$CMK_MACOSX\" 'basic setup'\nadd_make_flag \"CMK_BLUEGENEQ:=$CMK_BLUEGENEQ\" 'basic setup'\nadd_make_flag \"CMK_MULTICORE:=$CMK_MULTICORE\" 'basic setup'\nadd_make_flag \"CMK_UTH:=$CMK_UTH\" 'basic setup'\nadd_make_flag \"CMK_USE_LRTS:=$CMK_USE_LRTS\" 'basic setup'\nadd_make_flag \"BUILD_CUDA:=$BUILD_CUDA\" 'basic setup'\n\n# enable/disable error checking\nAC_ARG_ENABLE([error-checking],\n            [AS_HELP_STRING([--enable-error-checking],\n              [enable error checking])], ,\n            [enable_error_checking=yes])\n\nif test \"$enable_error_checking\" = \"no\"\nthen\n  Echo \"Charm++/LIBS error checking is disabled\" \n  AC_DEFINE_UNQUOTED(CMK_ERROR_CHECKING, 0, [disable error checking])\n  add_flag 'OPTS_CC=\"$OPTS_CC -U_FORTIFY_SOURCE\"' 'error checking'\n  add_flag 'OPTS_CXX=\"$OPTS_CXX -U_FORTIFY_SOURCE\"' 'error checking'\nelse\n  Echo \"Charm++/LIBS error checking is enabled\" \n  AC_DEFINE_UNQUOTED(CMK_ERROR_CHECKING, 1, [enable error checking])\nfi\n\n# enable/disable AMPI error checking\nAC_ARG_ENABLE([ampi-error-checking],\n            [AS_HELP_STRING([--enable-ampi-error-checking],\n              [enable AMPI error checking])], ,\n            [enable_ampi_error_checking=yes])\n\nif test \"$enable_ampi_error_checking\" = \"no\"\nthen\n  Echo \"AMPI error checking is disabled\"\n  AC_DEFINE_UNQUOTED(AMPI_ERROR_CHECKING, 0, [disable ampi error checking])\nelse\n  Echo \"AMPI error checking is enabled\"\n  AC_DEFINE_UNQUOTED(AMPI_ERROR_CHECKING, 1, [enable ampi error checking])\nfi\n\n# enable/disable statistics collection\nAC_ARG_ENABLE([stats],\n            [AS_HELP_STRING([--enable-stats],\n              [enable statistics collection])], ,\n            [enable_stats=yes])\n\nif test \"$enable_stats\" = \"no\"\nthen\n  Echo \"Statistics collection is disabled\" \n  AC_DEFINE_UNQUOTED(CMK_WITH_STATS, 0, [disable statistics collection])\nelse\n  Echo \"Statistics collection is enabled\" \n  AC_DEFINE_UNQUOTED(CMK_WITH_STATS, 1, [enable statistics collection])\nfi\n\n# check enable/disable\nAC_ARG_ENABLE([tracing],\n            [AS_HELP_STRING([--enable-tracing],\n              [enable tracing modules])], ,\n            [enable_tracing=yes])\n\nif test \"$enable_tracing\" = \"no\"\nthen\n  Echo \"Charm tracing is disabled\"\n  AC_DEFINE_UNQUOTED(CMK_TRACE_ENABLED, 0, [disable tracing])\n  add_flag CMK_TRACE_ENABLED=0\n  add_make_flag 'CMK_TRACE_ENABLED:=0' 'tracing'\nelse\n  Echo \"Charm tracing is enabled\"\n  AC_DEFINE_UNQUOTED(CMK_TRACE_ENABLED, 1, [enable tracing])\n  add_flag CMK_TRACE_ENABLED=1\n  add_make_flag 'CMK_TRACE_ENABLED:=1' 'tracing'\nfi\n\nAC_ARG_ENABLE([tracing-commthread],\n            [AS_HELP_STRING([--enable-tracing-commthread],\n              [enable tracing communication thread])], ,\n            [enable_tracing_commthread=no])\n\nif test \"$enable_tracing_commthread\" = \"yes\"\nthen\n  Echo \"Charm tracing communication thread is enabled\"\n  AC_DEFINE_UNQUOTED(CMK_SMP_TRACE_COMMTHREAD, 1, [enable tracing comm thread])\nelse\n  Echo \"Charm tracing communication thread is disabled\"\n  AC_DEFINE_UNQUOTED(CMK_SMP_TRACE_COMMTHREAD, 0, [disable tracing comm thread])\nfi\n\n\n# enable task queue\nAC_ARG_ENABLE([task_queue],\n            [AS_HELP_STRING([--enable-task-queue],\n              [enable task queue])],\n            [enable_task_queue=$enableval],\n            [enable_task_queue=no])\n\nif test \"$enable_task_queue\" = \"no\"\nthen\n  Echo \"Task Queue is disabled\"\n  AC_DEFINE_UNQUOTED(CMK_TASKQUEUE, 0, [disable task queue])\nelse\n  Echo \"Task Queue is enabled\"\n  AC_DEFINE_UNQUOTED(CMK_TASKQUEUE, 1, [enable task queue])\nfi\n\n# enable drone mode\nAC_ARG_ENABLE([drone_mode],\n            [AS_HELP_STRING([--enable-drone-mode],\n              [enable drone mode])],\n            [enable_drone_mode=$enableval],\n            [enable_drone_mode=no])\n\nif test \"$enable_drone_mode\" = \"no\"\nthen\n  Echo \"Drone mode is disabled\"\n  AC_DEFINE_UNQUOTED(CMK_DRONE_MODE, 0, [disable drone mode])\nelse\n  Echo \"Drone mode is enabled\"\n  AC_DEFINE_UNQUOTED(CMK_DRONE_MODE, 1, [enable drone mode])\nfi\n\nAC_ARG_ENABLE([charmdebug],\n            [AS_HELP_STRING([--enable-charmdebug],\n              [enable charmDebug])], ,\n            [enable_charmdebug=yes])\n\nif test \"$enable_charmdebug\" = \"no\" -o \"$CMK_CCS_AVAILABLE\" = '0'\nthen\n  Echo \"CharmDebug is disabled\" \n  AC_DEFINE_UNQUOTED(CMK_CHARMDEBUG, 0, [disable charmdebug])\n  add_flag CMK_CHARMDEBUG=0\n  add_make_flag 'CMK_CHARMDEBUG:=0'\nelse\n  Echo \"CharmDebug is enabled\" \n  AC_DEFINE_UNQUOTED(CMK_CHARMDEBUG, 1, [enable charmdebug])\n  add_flag CMK_CHARMDEBUG=1\n  add_make_flag 'CMK_CHARMDEBUG:=1'\nfi\n\nAC_ARG_ENABLE([replay],\n            [AS_HELP_STRING([--enable-replay],\n              [enable record/replay])],\n            [enable_replay=$enableval],\n            [enable_replay=yes])\n\nif test \"$enable_replay\" = \"no\"\nthen\n  Echo \"Charm record/replay is disabled\"\n  AC_DEFINE_UNQUOTED(CMK_REPLAYSYSTEM, 0, [disable replay])\nelse\n  if test \"$enable_tracing\" = \"no\"\n  then\n    Echo \"Charm record/replay is disabled because tracing is disabled\"\n    AC_DEFINE_UNQUOTED(CMK_REPLAYSYSTEM, 0, [disable replay])\n  else\n    Echo \"Charm record/replay is enabled\"\n    AC_DEFINE_UNQUOTED(CMK_REPLAYSYSTEM, 1, [enable replay])\n  fi\nfi\n\nAC_ARG_ENABLE([ccs],\n            [AS_HELP_STRING([--enable-ccs],\n              [enable CCS])], ,\n            [enable_ccs=yes])\n\nif test \"$enable_ccs\" = \"no\" -o \"$CMK_CCS_AVAILABLE\" = '0'\nthen\n  Echo \"CCS is disabled\" \n  AC_DEFINE_UNQUOTED(CMK_CCS_AVAILABLE, 0, [disable ccs])\nelse\n  Echo \"CCS is enabled\" \n  AC_DEFINE_UNQUOTED(CMK_CCS_AVAILABLE, 1, [enable ccs])\nfi\n\nAC_ARG_ENABLE([controlpoint],\n            [AS_HELP_STRING([--enable-controlpoint],\n              [enable control point])],\n            [enable_controlpoint=$enableval],\n            [enable_controlpoint=yes])\n\nif test \"$enable_controlpoint\" = \"yes\"\nthen\n  Echo \"Charm control point is enabled\"\n  AC_DEFINE_UNQUOTED(CMK_WITH_CONTROLPOINT, 1, [enable controlpoint])\nelse\n  Echo \"Charm control point is disabled\"\n  AC_DEFINE_UNQUOTED(CMK_WITH_CONTROLPOINT, 0, [disable controlpoint])\nfi\n\nAC_ARG_ENABLE([lbuserdata],\n            [AS_HELP_STRING([--enable-lbuserdata],\n              [enable LB user data])],\n            [enable_lbuserdata=$enableval],\n            [enable_lbuserdata=no])\n\nif test \"$enable_lbuserdata\" = \"yes\"\nthen\n  Echo \"Charm LB user data is enabled\"\n  AC_DEFINE_UNQUOTED(CMK_LB_USER_DATA, 1, [enable lb user data])\nelse\n  Echo \"Charm LB user data  is disabled\"\n  AC_DEFINE_UNQUOTED(CMK_LB_USER_DATA, 0, [disable lb user data])\nfi\n\nAC_ARG_ENABLE([lockless-queue],\n            [AS_HELP_STRING([--enable-lockless-queue],\n              [enable lockless queue for PE local and node queue])],\n            [enable_lockless_queue=$enableval],\n            [enable_lockless_queue=no])\n\nif test \"$enable_lockless_queue\" = \"no\"\nthen\n  Echo \"Lockless queue for PE local and node queue is disabled\"\n  AC_DEFINE_UNQUOTED(CMK_LOCKLESS_QUEUE, 0, [disable lockless queue for pe/node queue])\nelse\n  Echo \"Lockless queue for PE local and node queue is enabled\"\n  AC_DEFINE_UNQUOTED(CMK_LOCKLESS_QUEUE, 1, [enable lockless queue for pe/node queue])\nfi\n\n\nAC_ARG_ENABLE([shrinkexpand],\n            [AS_HELP_STRING([--enable-shrinkexpand],\n              [enable malleable jobs / shrink expand])],\n            [enable_shrinkexpand=$enableval],\n            [enable_shrinkexpand=no])\n\nif test \"$enable_shrinkexpand\" = \"yes\"\nthen\n  if test \"$enable_ccs\" = \"no\"\n  then\n    Echo \"CCS cannot be disabled when enabling shrink-expand\"\n    test_finish 1\n  else\n    Echo \"Charm shrink expand is enabled - Controlpoint is disabled.\"\n    AC_DEFINE_UNQUOTED(CMK_SHRINK_EXPAND, 1, [enable shrinkexpand])\n    AC_DEFINE_UNQUOTED(CMK_WITH_CONTROLPOINT, 0, [disable controlpoint])\n  fi\nelse\n  Echo \"Charm shrink expand is disabled\"\n  AC_DEFINE_UNQUOTED(CMK_SHRINK_EXPAND, 0, [disable shrinkexpand])\nfi\n\nAC_ARG_ENABLE([charmpy],\n            [AS_HELP_STRING([--enable-charmpy],\n              [enable charm4py support])],\n            [enable_charmpy=$enableval],\n            [enable_charmpy=no])\n\nif test \"$enable_charmpy\" = \"yes\"\nthen\n  Echo \"charm4py support is enabled\"\n  AC_DEFINE_UNQUOTED(CMK_CHARMPY, 1, [enable charmpy])\nelse\n  Echo \"charm4py support is disabled\"\n  AC_DEFINE_UNQUOTED(CMK_CHARMPY, 0, [disable charmpy])\nfi\n\nAC_ARG_WITH([numa],\n            [AS_HELP_STRING([--with-numa],\n              [support memory affinity with NUMA])],\n            [],\n            [with_numa=no])\n\nWITH_NUMA=no\nif test \"$with_numa\" = \"yes\"\nthen\n  Echo \"Charm NUMA support is builtin\"\n  WITH_NUMA=yes\nfi\n\nAC_ARG_WITH([lbtime-type],\n            [AS_HELP_STRING([--with-lbtime-type=type],\n                            [load balancing timer type])],\n            [], [with_lbtime_type=double])\n\nif test \"$with_lbtime_type\" = \"float\" -o \"$with_lbtime_type\" = \"double\"\nthen\n  Echo \"Setting load balancing timer type as '$with_lbtime_type'\"\n  AC_DEFINE_UNQUOTED(CMK_LBTIME_TYPE, $with_lbtime_type, [Setting load balancing timer type])\nelse\n  Echo \"Invalid type specified for load balancing timer type\"\n  test_finish 1\nfi\n\nAC_DEFINE_UNQUOTED(CMK_LBID_64BIT, 1, [enable 64 bit LB ID])\n\nAC_DEFINE_UNQUOTED(CMK_CKSECTIONINFO_STL, 1, [enable STL CkSectionInfo])\n\nAC_ARG_WITH([qlogic],\n            [AS_HELP_STRING([--with-qlogic],\n              [QLogic based Infiniband])],[with_qlogic=yes],\n            [with_qlogic=no])\n\nif test \"$with_qlogic\" = \"no\"\nthen\n  AC_DEFINE_UNQUOTED(QLOGIC, 0, [disable qlogic])\nelse\n  Echo \"QLogic based Infiniband\"\n  AC_DEFINE_UNQUOTED(QLOGIC, 1, [enable qlogic])\nfi\n\n#\nAC_MSG_CHECKING(machine name)\nversion=`pwd | awk -F/ '{print $(NF-1)}'`\nbase_version=\"$CMK_VDIR\"\nAC_DEFINE_UNQUOTED(CMK_MACHINE_NAME, \"$version\",[machine name])\nAC_MSG_RESULT($version)\nAC_SUBST(base_version)\n\nt=\"test.cpp\"\ntc=\"test.c\"\n\n# test result passed in $1\n# If the test suceeded, print $3 and set \"pass\"/clear \"fail\"\n# If the test failed, print $2 and clear \"pass\"/set \"fail\"\ntest_result() {\n\tif test $1 -eq 0\n\tthen\n                AC_MSG_RESULT(\"$3\")\n\t\tpass=\"1\"\n\t\tfail=\"0\"\n\telse\n                AC_MSG_RESULT(\"$4\")\n\t\tpass=\"0\"\n\t\tfail=\"1\"\n# For debugging the configure script, just \"export autoconf_debug=1\"\n#  to get this verbose data on any failed tests:\n\t\tif test ! -z \"$autoconf_debug\"\n\t\tthen\n\t\t\techo \"------- test script for $2 failed:\"\n\t\t\tcat out\n\t\t\techo \"------- the test program was:\"\n\t\t\tcat $t\n\t\t\techo \"-------\"\n\t\tfi\n\tfi\n}\n\n# Test: tries to compile C file $t (described by $1).\n#  If successful, prints $2 and sets $pass/clears $fail\n#  If failure, prints $3 and sets $pass/clears $fail\n#  additional arguments to c++ compiler are passed as $4\ntest_cc() {\n        AC_MSG_CHECKING(\"$1\")\n\techo \"### $1\" >> $charmout\n\tcat $tc >> $charmout\n\techo $CMK_CC $CMK_CC_FLAGS -I../include -I. $CMK_INCDIR $CMK_SYSINC $OPTS_CC -c $tc -o test.o $4 >> $charmout\n\t$CMK_CC $CMK_CC_FLAGS -I../include -I. $CMK_INCDIR $CMK_SYSINC $OPTS_CC -c $tc -o test.o $4 > out 2>&1\n\ttest_result $? \"$1\" \"$2\" \"$3\"\n \tstrictpass=$pass\n\tstrictfail=$fail\n        if test $pass -eq 1\n\tthen \n          if grep -i \"warn\" out > /dev/null 2>&1 || grep -i \"(W)\" out > /dev/null 2>&1\n\t  then \n\t    strictpass=\"0\" && strictfail=\"1\"\n          fi\n        fi\n\tcat out >> $charmout\n\t/bin/rm -f out\n}\n\n# Test: tries to compile C++ file $t (described by $1).\n#  If successful, prints $2 and sets $pass/clears $fail\n#  If failure, prints $3 and sets $pass/clears $fail\n#  additional arguments to c++ compiler are passed as $4\ntest_cxx() {\n        AC_MSG_CHECKING(\"$1\")\n\techo \"### $1\" >> $charmout\n\tcat $t >> $charmout\n\techo $CMK_CXX $CMK_CXX_FLAGS -I../include -I. $CMK_INCDIR $CMK_SYSINC $OPTS_CXX -c $t -o test.o $4 >> $charmout\n\t$CMK_CXX $CMK_CXX_FLAGS -I../include -I. $CMK_INCDIR $CMK_SYSINC $OPTS_CXX -c $t -o test.o $4 > out 2>&1\n\ttest_result $? \"$1\" \"$2\" \"$3\"\n \tstrictpass=$pass\n\tstrictfail=$fail\n        if test $pass -eq 1\n\tthen \n          if grep -i \"warn\" out > /dev/null 2>&1 || grep -i \"(W)\" out > /dev/null 2>&1\n\t  then \n\t    strictpass=\"0\" && strictfail=\"1\"\n          fi\n        fi\n\tcat out >> $charmout\n\t/bin/rm -f out\n}\n\n# Test: tries to compile C++ file $t (described by $1) using native compiler.\n#  If successful, prints $2 and sets $pass/clears $fail\n#  If failure, prints $3 and sets $pass/clears $fail\n#  additional arguments to c++ compiler are passed as $4\ntest_native_cxx() {\n        AC_MSG_CHECKING(\"$1\")\n\techo \"### $1\" >> $charmout\n\tcat $t >> $charmout\n\techo $CMK_NATIVE_CXX $CMK_NATIVE_CXX_FLAGS -I../include -I. $CMK_INCDIR $CMK_SYSINC $OPTS_CXX -c $t -o test.o $4 >> $charmout\n\t$CMK_NATIVE_CXX $CMK_NATIVE_CXX_FLAGS -I../include -I. $CMK_INCDIR $CMK_SYSINC $OPTS_CXX -c $t -o test.o $4 > out 2>&1\n\ttest_result $? \"$1\" \"$2\" \"$3\"\n\tstrictpass=$pass\n\tstrictfail=$fail\n        if test $pass -eq 1\n\tthen\n          if grep -i \"warn\" out > /dev/null 2>&1 || grep -i \"(W)\" out > /dev/null 2>&1\n\t  then\n\t    strictpass=\"0\" && strictfail=\"1\"\n          fi\n        fi\n\tcat out >> $charmout\n\t/bin/rm -f out\n}\n\n# Testlink: tries to compile and link a C++ file $t (described by $1).\n#  If successful, prints $2 and sets $pass/clears $fail\n#  If failure, prints $3 and sets $pass/clears $fail\n#  additional arguments to c++ compiler are passed as $4\ntest_link() {\n        AC_MSG_CHECKING(\"$1\")\n\techo \"### $1\" >> $charmout\n\tcat $t >> $charmout\n\techo $CMK_CXX $CMK_CXX_FLAGS -I../include -I. $CMK_INCDIR $CMK_SYSINC $OPTS_CXX -c $t -o test.o $4 >> $charmout\n\t$CMK_CXX $CMK_CXX_FLAGS -I../include -I. $CMK_INCDIR $CMK_SYSINC $OPTS_CXX -c $t -o test.o $4 > out 2>&1\n        if test $? -ne 0\n        then\n          test_result 1 \"$1\" \"$2\" \"$3\"\n        else\n          echo $CMK_LDXX $CMK_LDXX_FLAGS $CMK_LINK_BINARY -o testlink test.o $CMK_LIBDIR $OPTS_LD $CMK_SYSLIBS $4 $5 >> $charmout\n          $CMK_LDXX $CMK_LDXX_FLAGS $CMK_LINK_BINARY -o testlink test.o $CMK_LIBDIR $OPTS_LD $CMK_SYSLIBS $4 $5 >> out 2>&1\n          ret=$?\n\t  test ! -x testlink && ret=1\n          test_result $ret \"$1\" \"$2\" \"$3\"\n        fi\n \tstrictpass=$pass\n\tstrictfail=$fail\n        if test $pass -eq 1\n\tthen \n \t  if cat out | grep -i \"warn\" > /dev/null 2>&1\n\t  then \n\t    strictpass=\"0\" && strictfail=\"1\"\n          fi\n        fi\n\tcat out >> $charmout\n\t/bin/rm -f out\n}\n\n# Testlinkc: tries to compile and link a C file $t (described by $1).\n#  If successful, prints $2 and sets $pass/clears $fail\n#  If failure, prints $3 and sets $pass/clears $fail\n#  additional arguments to c++ compiler are passed as $4\ntest_linkc() {\n        AC_MSG_CHECKING(\"$1\")\n\techo \"### $1\" >> $charmout\n\tcat $tc >> $charmout\n\techo $CMK_CC $CMK_CC_FLAGS -I../include -I. $CMK_INCDIR $CMK_SYSINC $OPTS_CC -c $tc -o test.o $4 >> $charmout\n\t$CMK_CC $CMK_CC_FLAGS -I../include -I. $CMK_INCDIR $CMK_SYSINC $OPTS_CC -c $tc -o test.o $4 > out 2>&1\n        if test $? -ne 0\n        then\n          test_result 1 \"$1\" \"$2\" \"$3\"\n        else\n          echo $CMK_LD $CMK_LD_FLAGS $CMK_LINK_BINARY -o testlink test.o $CMK_LIBDIR $OPTS_LD $CMK_SYSLIBS $4 >> $charmout\n          $CMK_LD $CMK_LD_FLAGS $CMK_LINK_BINARY -o testlink test.o $CMK_LIBDIR $OPTS_LD $CMK_SYSLIBS $4 >> out 2>&1\n          test_result $? \"$1\" \"$2\" \"$3\"\n        fi\n \tstrictpass=$pass\n\tstrictfail=$fail\n        if test $pass -eq 1\n\tthen \n \t  if cat out | grep -i \"warn\" > /dev/null 2>&1\n\t  then \n\t    strictpass=\"0\" && strictfail=\"1\"\n          fi\n        fi\n\tcat out >> $charmout\n\t/bin/rm -f out\n}\n\n# test_linkso $1 $2 $3 $4, where\n# $1: debug msg\n# $2: yes msg\n# $3: no msg\n# $4: extra link option\ntest_linkso() {\n        AC_MSG_CHECKING(\"$1\")\n\techo $1 >> $charmout\n\tcat $t >> $charmout\n\techo $CMK_CXX $CMK_CXX_FLAGS -I../include -I. $CMK_INCDIR $CMK_SYSINC $OPTS_CXX $CMK_PIC -c $t -o test.o $4 >> $charmout\n\t$CMK_CXX $CMK_CXX_FLAGS -I../include -I. $CMK_INCDIR $CMK_SYSINC $OPTS_CXX -c $CMK_PIC $t -o test.o $4 > out 2>&1\n        if test $? = 1\n        then\n          test_result 1 \"$1\" \"$2\" \"$3\"\n        else\n\t  echo $CMK_LD $CMK_LD_FLAGS $CMK_LIBDIR $OPTS_LD $CMK_LD_SHARED $CMK_SYSLIBS test.o -o testlink.$CMK_SHARED_SUF $4 >> $charmout\n\t  $CMK_LD $CMK_LD_FLAGS $CMK_LIBDIR $OPTS_LD $CMK_LD_SHARED $CMK_SYSLIBS test.o -o testlink.$CMK_SHARED_SUF $4 > out 2>&1\n\t  test_result $? \"$1\" \"$2\" \"$3\"\n\tfi\n\tcat out >> $charmout\n\t/bin/rm -f out testlink.$CMK_SHARED_SUF\n}\n\ntest_finish() {\n\trm -f $t $tc testlink test.o\t> /dev/null 2>&1\n\t/bin/rm -f out\n\ttest $1 -eq 1 && echo \"*** Please find detailed output in tmp/charmconfig.out ***\"\n\texit $1\n}\n\n# detect certain architectures\nif cat /proc/cpuinfo 2>/dev/null | grep 'POWER7'  > /dev/null\nthen\n  AC_DEFINE_UNQUOTED(CMK_POWER7, 1, [whether is power7])\nfi\n\n# detect OS\nOSNAME=`uname -s`\nif test $OSNAME = \"Linux\"\nthen\n  AC_DEFINE_UNQUOTED(CMK_OS_IS_LINUX, 1, [OS is Linux])\nelse\n  AC_DEFINE_UNQUOTED(CMK_OS_IS_LINUX, 0, [OS is Linux])\nfi\n\n# test cp -p\nAC_MSG_CHECKING(\"cp command as\")\nCP=\"cp -p\"\ntouch test_file\nif ! $CP test_file test_file.cp 2>err\nthen\n  CP=\"cp\"\nfi\nrm -f test_file test_file.cp\nAC_MSG_RESULT($CP)\nadd_flag CP=\\\"\"$CP\"\\\" \"cp command\"\n \n\ncat > $t <<EOT\n#include <stdio.h>\nvoid foo(void) {\n\tprintf(\"Hello, world!\\n\");\n}\nEOT\n\nif test \"$CMK_BUILD_CRAY\" = \"1\"\nthen\n#echo \"Test for known incompatible compiler versions\"\n\n if test \"$CRAY_CC_VERSION\" = \"8.1.4\"\n then\n\techo \"CCE 8.1.4 produces incorrect Charm++ code\"\n\techo \"Please use a newer version of the CCE compiler\"\n\techo \"e.g. module load cce/8.1.7\"\n\ttest_finish 1\n fi\nfi\n\n#echo \"set C++ compiler as: $CMK_CXX $OPTS_CXX $OPTS\"\nAC_MSG_CHECKING(\"C++ compiler as\")\nAC_MSG_RESULT(\"$CMK_CXX $OPTS_CXX\")\ntest_cxx \"whether C++ compiler works\" \"ok\" \"no\" \"\"\nif test $fail -eq 1\nthen\n\techo \"Cannot compile C++ programs with $CMK_CXX\"\n\techo \" (check your charm++ version)\"\n\ttest_finish 1\nfi\n\ncat > $t <<EOT\n#include <stdio.h>\nint main() {\n\tprintf(\"Hello, world!\\n\");\n\treturn 0;\n}\nEOT\n#echo \"set C++ linker as: $CMK_LDXX $OPTS_LD\"\nAC_MSG_CHECKING(\"C++ linker as\")\nAC_MSG_RESULT(\"$CMK_LDXX $OPTS_LD\")\ntest_link \"whether linker works\" \"ok\" \"no\" \"\"\nif test $fail -eq 1\nthen\n\techo \"Cannot link C++ programs with $CMK_LDXX\"\n\techo \" (check your charm++ version)\"\n\ttest_finish 1\nfi\n\nAC_MSG_CHECKING(\"Native C++ compiler as\")\nAC_MSG_RESULT(\"$CMK_NATIVE_CXX\")\nAC_MSG_CHECKING(\"Sequential C++ compiler as\")\nAC_MSG_RESULT(\"$CMK_SEQ_CXX\")\n\nif echo \"$CMK_CC\" | grep -E \"gcc|clang|icc\" > /dev/null 2> /dev/null\nthen\n  test_link \"whether compiler accept -fno-stack-protector\" \"ok\" \"no\" \"-fno-stack-protector\"\n  if test $strictpass -eq 1\n  then\n\tadd_flag OPTS_CC='\"$OPTS_CC -fno-stack-protector\"' \"stack-protection disabling\"\n\tadd_flag OPTS_CXX='\"$OPTS_CXX -fno-stack-protector\"' \"stack-protection disabling\"\n  fi\nfi\n\n#### check if C++ compiler will accept C++11 features without warning ####\ncat > $t <<EOT\n// Check for Intel compiler incompatibility with the active g++/libstdc++ by\n// including an arbitrary standard library header (cf bug #1560)\n#include <map>\n\n// Check for an excessively old g++/libstdc++ that can't handle features we use\n#include <memory>\n#include <vector>\nstd::unique_ptr<int> i;\n\nclass CkMigrateMessage;\n\nstruct base {\n  base(void) { }\n  base(CkMigrateMessage *) { }\n};\n\ntemplate <class Parent>\nstruct CBaseT1 : Parent {\n  std::vector<int> v; // check for C++11's shrink_to_fit()\n\n  CBaseT1(void) :Parent()  { v.shrink_to_fit(); }\n  CBaseT1(CkMigrateMessage *m) :Parent(m) { }\n  CBaseT1(CBaseT1&& rhs) :Parent() { }\n\n  template <typename... Args>\n    CBaseT1(Args... args) : Parent(args...) { }\n};\n\ntemplate struct CBaseT1<base>;\nEOT\ngot_cpp11=\"\"\ntest_cxx \"whether C++ compiler supports C++11 without flags\" \"yes\" \"no\" \"\"\nif test $strictpass -eq 1\nthen\n  got_cpp11=\"true\"\nelse\n# Flags for g++/clang++/icpc/xlC++, pgCC, and CrayCC respectively\nfor i in \"-std=c++11\" \"--c++11\" \"-h std=c++11\"; do\n    test_cxx \"whether C++ compiler supports C++11 with '$i'\" \"yes\" \"no\" \"$i\"\n    if test $strictpass -eq 1\n    then\n      add_flag \"$(echo OPTS_CXX=\\\"\\$OPTS_CXX $i\\\")\" \"Enable C++11 support\"\n      OPTS_CXX=\"$OPTS_CXX $i\"\n      got_cpp11=\"true\"\n      break\n    fi\ndone\nfi\n\nif test -z $got_cpp11\nthen\n  echo \"Charm++ requires C++11 support, but doesn't know the flag to enable it\"\n  echo\n  echo \"For Intel's compiler please see\"\n  echo \"https://github.com/UIUC-PPL/charm/issues/1560\"\n  echo \"about making a suitable version of gcc/g++/libstdc++ available\"\n  echo\n  echo \"For Blue Gene/Q please use the Clang compiler\"\n  test_finish 1\nfi\n\ntest_native_cxx \"whether native C++ compiler supports C++11 without flags\" \"yes\" \"no\" \"\"\nif test $strictpass -ne 1\nthen\n  # Flags for g++/clang++/icpc/xlC++, pgCC, and CrayCC respectively\n  for i in \"-std=c++11\" \"--c++11\" \"-h std=c++11\"; do\n    test_native_cxx \"whether C++ compiler supports C++11 with '$i'\" \"yes\" \"no\" \"$i\"\n    if test $strictpass -eq 1\n    then\n      add_flag \"$(echo CMK_NATIVE_CXX_FLAGS=\\\"\\$CMK_NATIVE_CXX_FLAGS $i\\\")\" \"Enable C++11 support\"\n      break\n    fi\ndone\nfi\n\n# Workaround for bug #1045 appearing in GCC >6.x\ntest_cxx \"whether C++ compiler accepts -fno-lifetime-dse\" \"yes\" \"no\" \"-fno-lifetime-dse\"\nif test $strictpass -eq 1\nthen\n    add_flag \"$(echo OPTS_CXX=\\\"\\$OPTS_CXX -fno-lifetime-dse\\\")\" \"Disable 'Lifetime DSE' optimization to work around bug #1045 in GCC >6.x\"\n    OPTS_CXX=\"$OPTS_CXX -fno-lifetime-dse\"\nfi\n\n# Test for a flag tlsglobals sometimes depends on\ntest_cxx \"whether C++ compiler accepts -mno-tls-direct-seg-refs\" \"yes\" \"no\" \"-mno-tls-direct-seg-refs\"\nif test $strictpass -eq 1\nthen\n    add_flag 'CMK_COMPILER_KNOWS_TLSDIRECTSEGREFS=\"1\"' \"tlsglobals\"\nfi\n\n# Determine compiler/linker flags to build libcharm.so for charm4py\nif test \"$enable_charmpy\" = \"yes\"\nthen\n\n  cat > $t <<EOT\nint main() { return 0; }\nEOT\n\n  test_cxx \"whether C++ compiler accepts --no-as-needed\" \"yes\" \"no\" \"--no-as-needed\"\n  if test $strictpass -eq 1\n  then\n      add_flag \"$(echo CXX_NO_AS_NEEDED=\\\"--no-as-needed\\\")\" \"--no-as-needed flag necessary for compilers that default to linking with --as-needed\"\n  fi\n\n  got_opt_whole_archive=\"\"\n  # Flags for g++/clang++/icpc, Apple-LLVM respectively\n  for i in \"-Wl,--whole-archive -Wl,--no-whole-archive\" \"-Wl,-all_load\"; do\n      test_link \"whether linker supports '$i'\" \"yes\" \"no\" \"\" \"$i\"\n      if test $strictpass -eq 1\n      then\n        got_opt_whole_archive=\"true\"\n        IFS=' ' read LDXX_WHOLE_ARCHIVE_PRE LDXX_WHOLE_ARCHIVE_POST <<EOF\n        $i\nEOF\n        add_flag \"$(echo LDXX_WHOLE_ARCHIVE_PRE=\\\"$LDXX_WHOLE_ARCHIVE_PRE\\\")\" \"Flags to link whole archives into libcharm.so\"\n        add_flag \"$(echo LDXX_WHOLE_ARCHIVE_POST=\\\"$LDXX_WHOLE_ARCHIVE_POST\\\")\" \"Flags to link whole archives into libcharm.so\"\n        break\n      fi\n  done\n\n  if test -z $got_opt_whole_archive\n  then\n    echo \"Don't know how to build libcharm.so for Charm4py\"\n    test_finish 1\n  fi\nfi\n\n# Figure out if the user has asked to enable the latest language standards\nUSER_ASKED_FOR_NEW_STD=`echo \"$BUILDOPTS\" | grep \"\\-use-new-std\" | wc -l`\n\n# If the user has asked for the newer standards, check if the compilers know about them\nif test $USER_ASKED_FOR_NEW_STD -ge 1\nthen\n\n#### check if c compiler supports c11 compilation flags ####\ncat > $tc <<EOT\n#include <stdio.h>\n\nint foo()\n{\n  return 0;\n}\nEOT\ntest_cc \"whether c compiler knows of the c11 standard\" \"ok\" \"no\" \"$CMK_ENABLE_C11\"\nAC_DEFINE_UNQUOTED(CMK_COMPILER_KNOWS_C11, $pass, [whether c compiler knows of the c11 standard] )\nif test $pass -eq 1\nthen\n        # Record results for charmc's future use\n        add_flag 'CMK_COMPILER_KNOWS_C11=\"1\"' \"c11\"\n        # For the rest of configure, append this to compilation flags\n        OPTS_CC=\"$CMK_ENABLE_C11 $OPTS_CC\"\nfi\nfi # endif USER_ASKED_FOR_NEW_STD\n\n# Perform the tests\n\nAC_ARG_WITH([refnum-type],\n            [AS_HELP_STRING([--with-refnum-type=type],\n                            [size of the envelope refnum field])],\n            [], [with_refnum_type=no])\n\nif test \"$with_refnum_type\" = \"no\" -o \"$with_refnum_type\" = \"short\"\nthen\n  Echo \"Setting charm++ envelope refnum field to unsigned short\"\n  AC_DEFINE_UNQUOTED(CMK_REFNUM_TYPE, unsigned short, [envelope refnum field set to UShort])\nelif test \"$with_refnum_type\" = \"int\"\nthen\n  Echo \"Setting charm++ envelope refnum field to unsigned int\"\n  AC_DEFINE_UNQUOTED(CMK_REFNUM_TYPE, unsigned int, [envelope refnum field set to UInt])\nelse\n  Echo \"Invalid size specified for refnum field\"\n  test_finish 1\nfi\n\n\nAC_ARG_WITH([prio-type],\n            [AS_HELP_STRING([--with-prio-type=type],\n                            [size of expected message priorities])],\n            [], [with_prio_type=bitvec])\n\nif test \"$with_prio_type\" = \"char\" -o \"$with_prio_type\" = \"short\" -o \"$with_prio_type\" = \"int\" -o \"$with_prio_type\" = \"long\" -o \"$with_prio_type\" = \"float\" -o \"$with_prio_type\" = \"double\"\nthen\n  Echo \"Configuring support for message priorities of sizeof type $with_prio_type\"\n  AC_DEFINE_UNQUOTED(CMK_USE_STL_MSGQ, 1, [whether charm scheduler should use an STL-based msg q])\n  AC_DEFINE_UNQUOTED(CMK_MSG_PRIO_TYPE, $with_prio_type, [expected message priorities are sizeof $with_prio_type])\nelif test \"$with_prio_type\" = \"bitvec\"\nthen\n  Echo \"Configuring support for message priorities of arbitrary size (bitvectors)\"\n  AC_DEFINE_UNQUOTED(CMK_USE_STL_MSGQ, 0, [whether charm scheduler should use an STL-based msg q])\n  AC_DEFINE_UNQUOTED(CMK_MSG_PRIO_TYPE, $with_prio_type, [expected message priorities are arbitrarily sized])\nelse\n  Echo \"Invalid size ($with_prio_type) specified for message priorities. Can only accept char, short, int, long, float, double and bitvec\"\n  test_finish 1\nfi\n\n# enable/disable randomized scheduler queue\nAC_ARG_ENABLE([randomized-msgq],\n            [AS_HELP_STRING([--enable-randomized-msgq],\n              [enable a randomized msg queue (for debugging etc)])], ,\n            [enable_randomized_msgq=no])\n\nif test \"$enable_randomized_msgq\" = \"yes\" -a \"$with_prio_type\" != \"bitvec\"\nthen\n  Echo \"The charm message queue will be randomized (and will not respect priorities)\"\n  AC_DEFINE_UNQUOTED(CMK_RANDOMIZED_MSGQ, 1, [enable the randomized msgq in the scheduler])\nelse\n  AC_DEFINE_UNQUOTED(CMK_RANDOMIZED_MSGQ, 0, [disable the randomized msgq in the scheduler])\n  if test \"$enable_randomized_msgq\" = \"yes\"\n  then\n    Echo 'A randomized message queue is only available when --with-prio-type != bitvec.'\n    Echo \"Specify prio-type to be a data type long enough to hold the message priorities in your application\"\n    Echo \"for example: --with-prio-type=int (or short / long etc).\"\n    test_finish 1\n  fi\nfi\n\nAC_ARG_WITH([mempool-cutoff],\n            [AS_HELP_STRING([--with-mempool-cutoff=N],\n                            [exponent of the maximum power of two to use for bin sizes in the mempool])],\n            [], [with_mempool_cutoff=26])\n\nif test \"$((6 < $with_mempool_cutoff && $with_mempool_cutoff < 32))\" = '1'\nthen\n  Echo \"Using mempool cutoff... 2^$with_mempool_cutoff\"\n  AC_DEFINE_UNQUOTED(CMK_MEMPOOL_CUTOFFNUM, $((with_mempool_cutoff - 6)), [mempool cutoff])\nelse\n  Echo \"Invalid number ($with_mempool_cutoff) specified for mempool cutoff. Valid range: 7 <= N <= 31\"\n  test_finish 1\nfi\n\n# enable mpich tests\nAC_ARG_ENABLE([ampi-mpich-tests],\n            [AS_HELP_STRING([--enable-ampi-mpich-tests],\n            [enable mpich tests for ampi])],\n            [enable_ampi_mpich_tests=yes],\n            [enable_ampi_mpich_tests=no])\n\nif test \"$enable_ampi_mpich_tests\" = \"yes\"\nthen\n  AC_DEFINE([AMPI_ERRHANDLER_RETURN], [1], [enable ampi fatal error return])\n  add_make_flag \"BUILD_MPICH_TESTS:=true\" 'mpich tests setup'\nelse\n  AC_DEFINE([AMPI_ERRHANDLER_RETURN], [0], [disable ampi fatal error return])\nfi\n\n#### Check if compiler is 64 bit ####\ncat > $t <<EOT\n#include <stdio.h>\n\nint foo()\n{\nint x[[(int)(sizeof(void *) - 7)]]={0};\nreturn x[[0]];\n}\nEOT\ntest_cxx \"whether compiler generates code for 64-bit\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_SIZET_64BIT, $strictpass, [whether size_t 64bit])\nin64bit=$strictpass\n\n### Check if compiler supports std::is_constructible<> ###\ncat > $t <<EOT\n#include <type_traits>\n\nstruct s {\n       s(int a) { }\n};\n\nbool foo()\n{\n  return std::is_constructible<s, int>::value;\n}\nEOT\ntest_cxx \"whether compiler supports std::is_constructible\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_IS_CONSTRUCTIBLE, $strictpass, [whether compiler supports std::is_constructible])\n\n### Check if compiler supports std::alignment_of<> ###\ncat > $t <<EOT\n#include <type_traits>\n\nint foo()\n{\n  return std::alignment_of<int>::value;\n}\nEOT\ntest_cxx \"whether compiler supports std::alignment_of\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_ALIGNMENT_OF, $strictpass, [whether compiler supports std::alignment_of])\n\n### Check if compiler implements regex ###\ncat > $t <<EOT\n#include <regex>\nvoid foo()\n{\n#if __cplusplus >= 201103L &&                             \\\n    (!defined(__GLIBCXX__) || (__cplusplus >= 201402L) || \\\n        (defined(_GLIBCXX_REGEX_DFS_QUANTIFIERS_LIMIT) || \\\n         defined(_GLIBCXX_REGEX_STATE_LIMIT)           || \\\n             (defined(_GLIBCXX_RELEASE)                && \\\n             _GLIBCXX_RELEASE > 4)))\n// compiler has regex support, continue\n#else\n// force compilation to fail\nstatic_assert(false, \"compiler has no regex implementation\");\n#endif\n}\nEOT\ntest_cxx \"whether compiler implements regex\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_REGEX, $pass, [whether compiler implements regex])\n\n#### test if has values.h ####\ncat > $t <<EOT\n#include <values.h>\nint main() { \n  double d = MAXDOUBLE;\n  return 0;\n}\nEOT\ntest_cxx \"whether has values.h \" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_VALUES_H, $pass, [whether has values.h])\n\n#### test if has stdint.h ####\ncat > $t <<EOT\n#include <stdint.h>\nint main() { \n  return 0;\n}\nEOT\ntest_cxx \"whether has stdint.h \" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_STDINT_H, $pass, [whether has stdint.h])\n\n#### test if has malloc.h ####\ncat > $t <<EOT\n#include <malloc.h>\nint main() { \n  return 0;\n}\nEOT\ntest_cxx \"whether has malloc.h \" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_MALLOC_H, $pass, [whether has malloc.h])\n\n#### test if has alloca.h ####\ncat > $t <<EOT\n#include <alloca.h>\nint main() {\n  double *s=(double *)alloca(sizeof(double));\n  *s=1.0;\n  return 0;\n}\nEOT\ntest_cxx \"whether has alloca.h \" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_ALLOCA_H, $pass, [whether has alloca.h])\n\n#### test if has regex.h ####\ncat > $t <<EOT\n#include <regex.h>\nint main() {\n  regex_t re;\n  regcomp(&re, \".*MOD.*\", REG_EXTENDED|REG_NOSUB);\n  return 0;\n}\nEOT\ntest_cxx \"whether has regex.h \" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_REGEX_H, $pass, [whether has regex.h])\n\n#### Check long long ####\ncat > $t <<EOT\n#include <stdlib.h>\nlong long foo(void) { return 17; }\nEOT\ntest_cxx \"whether long long works\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_LONG_LONG_DEFINED, $pass, [whether long long works])\n\n#### Check __int64 ####\ncat > $t <<EOT\n#include <stdlib.h>\n__int64 foo(void) { return 17; }\nEOT\ntest_cxx \"whether __int64 works\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED([CMK___int64_DEFINED], $pass, [whether __int64 works])\n\n\nCMK_HAS_INT16=0\n\n#### Check __int128 ####\ncat > $t <<EOT\n#include <stdlib.h>\nint foo(void) {\n  __int128   a;\n  int x[[(int)(sizeof(__int128) - 15)]]={0};\n  return x[[0]];\n}\nEOT\ntest_cxx \"whether __int128 (128-bit integer) works\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED([CMK___int128_DEFINED], $pass, [whether __int128 works])\nif test $pass -eq 1\nthen\n  CMK_HAS_INT16=1\n  add_flag CMK_HAS_INT16=1\nfi\n\n#### Check __int128_t ####\ncat > $t <<EOT\n#include <stdlib.h>\nint foo(void) {\n  __int128_t   a;\n  __uint128_t   b;\n  a = a + a;\n  int x[[(int)(sizeof(__int128_t) - 15)]]={0};\n  return x[[0]];\n}\nEOT\ntest_cxx \"whether __int128_t (128-bit integer) works\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED([CMK___int128_t_DEFINED], $pass, [whether __int128_t works])\nif test $pass -eq 1\nthen\n  CMK_HAS_INT16=1\n  add_flag CMK_HAS_INT16=1\nfi\n\n#### Summarize *int128* ####\n\nAC_DEFINE_UNQUOTED([CMK_HAS_INT16], $CMK_HAS_INT16, [whether any 128-bit integer works])\n\n\n### Check if we have C++11 <atomic> ###\ncat > $t <<EOT\n#include <atomic>\nint main(int argc, char** argv) { \n  return 0;\n}\nEOT\ntest_cxx \"whether C++ library has <atomic> \" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_CXX11_ATOMIC, $pass, [whether C++ library has <atomic>])\n\nif test $pass -ne 1\nthen\n### Check if we have pre-C++11 <cstdatomic> ###\ncat > $t <<EOT\n#include <cstdatomic>\nint main(int argc, char** argv) { \n  return 0;\n}\nEOT\ntest_cxx \"whether C++ library has <cstdatomic> \" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_CXX0X_CSTDATOMIC, $pass, [whether C++ library has <cstdatomic>])\nfi\n\nif test $pass -ne 1 -a \"$CMK_COMPILER\" != \"bgxlc\"\nthen\n\techo \"Charm++ requires C++11 atomic support\"\n\ttest_finish 1\nfi\n\n#### Check long double ####\ncat > $t <<EOT\n#include <stdlib.h>\nlong double foo(void) { return 17.0; }\nEOT\ntest_cxx \"whether long double works\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_LONG_DOUBLE_DEFINED, $strictpass, [whether long double works])\n\n#### Check ucontext and FPU pointer ####\ncat > $t <<EOT\n#include <ucontext.h>\nstruct _libc_fpstate   fpstate;\nfpregset_t *fp;\nint main() {\n  ucontext_t context;\n  context.uc_mcontext.fpregs = 0;\n}\nEOT\ntest_cxx \"whether ucontext has FPU pointer\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_CONTEXT_FPU_POINTER, $pass, [whether ucontext has pointer])\n\nif test $pass -eq 1\nthen\ncat > $t <<EOT\n#include <ucontext.h>\n\nint main()\n{\n  ucontext_t context;\n  context.uc_mcontext.uc_regs = 0;\n}\nEOT\ntest_cxx \"whether ucontext uses uc_regs\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_CONTEXT_FPU_POINTER_UCREGS, $pass, [whether ucontext uses uc_regs union])\nfi\n\ncat > $t <<EOT\n#include <ucontext.h>\nvrregset_t *v_regs;\nucontext_t  uc;\n\nvoid foo()\n{\n  vrregset_t *ptr = uc.uc_mcontext.v_regs;\n}\nEOT\ntest_cxx \"whether ucontext has pointer (v_regs) of vector type\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_CONTEXT_V_REGS, $pass, [whether ucontext has pointer (v_regs) of vector type])\n\n#### Check ucontext and FPU pointer ####\ncat > $t <<EOT\n#include <infiniband/verbs.h>\nvoid test()\n{\n    struct ibv_context    *context;\n    int ibPort;\n    struct ibv_port_attr attr;\n    if (ibv_query_port(context, ibPort, &attr) != 0) return;\n    if (attr.link_layer == IBV_LINK_LAYER_INFINIBAND)  return;\n}\nEOT\ntest_cxx \"whether ibverbs ibv_port_attr has link_layer field\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_IBV_PORT_ATTR_HAS_LINK_LAYER, $pass, [whether ibv_port_attr has link_layer field])\n\n\n###################### C++ Compiler Features #####################\n\n#### check C inline ####\ncat > $tc <<EOT\ninline static int foo()\n{\n  return 1;\n}\nEOT\ntest_cc \"whether inline works in C\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_C_INLINE, $strictpass, [whether C inline works in C])\n\n#### check if signed char is same as char ####\ncat > $t <<EOT\n#include <stdlib.h>\nclass er {\n protected:\n   void operator()(char &v,const char *desc=NULL) {};\n   void operator()(signed char &v,const char *desc=NULL) {};\n};\nEOT\ntest_cxx \"whether C++ signed char and char differ\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_SIGNEDCHAR_DIFF_CHAR, $pass, [whether C++ signed char and char differ])\n\n#### check if typeinfo exists and works #####\ncat > $t <<EOT\n#include <typeinfo>\nconst char *foo(void) {\n\tint x;\n\treturn typeid(x).name();\n}\nEOT\ntest_cxx \"whether typeinfo/typeid works\" \"ok\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_TYPEINFO, $pass, [whether typeinfo/typeid works])\n\n#### check if iterator_traits is defined #####\ncat > $t <<EOT\n#include <iterator>\n\ntemplate <typename T> // T models Input Iterator\ntypename std::iterator_traits<T>::value_type accumulate(T first, T last)\n{\n      typename std::iterator_traits<T>::value_type result = 0;\n      while(first != last)\n            result += *first++;\n      return result;\n}\nEOT\ntest_cxx \"whether std::iterator_traits is defined\" \"ok\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_ITERATOR_TRAITS, $pass, [whether iterator_traits works])\n\n#### check if std::distance is defined #####\ncat > $t <<EOT\n#include <vector>\n#include <iterator>\n\nint foo()\n{\n  std::vector<int> tree;\n  return std::distance(tree.begin(), tree.end());\n}\nEOT\ntest_cxx \"whether std::distance is defined\" \"ok\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_STD_DISTANCE, $pass, [whether std::distance works])\n\n#### check if std::inserter is defined #####\ncat > $t <<EOT\n#include <list>\n#include <iterator>\n\nvoid foo()\n{\n  using namespace std;\n  list<int> L;\n  inserter ( L, L.end ( ) ) = 500;\n}\nEOT\ntest_cxx \"whether std::inserter is defined\" \"ok\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_STD_INSERTER, $pass, [whether std::inserter works])\n\n#### check if C++17's std::void_t is defined #####\ncat > $t <<EOT\n#include <type_traits>\n\ntemplate<typename T, typename = std::void_t<>>\nstruct has_pup_member : std::false_type {};\n\nEOT\ntest_cxx \"whether std::void_t is defined\" \"ok\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_STD_VOID_T, $pass, [whether std::void_t works])\n\n####### Check support for features added by the new C11 and CPP11 standards ########\n\n#### test if we can have multiple delete like this ####\ncat > $t <<EOT\nclass foo {\npublic:\n  void operator delete(void*p){};\n  void operator delete(void*p,int*){};\n};\nEOT\ntest_cxx \"whether operator delete can be overloaded in same class\" \"ok\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_MULTIPLE_DELETE, $strictpass, [whether operator delete can be overloaded in same class])\n\n#### test if offsetof exists ####\ncat > $t <<EOT\n#include <stddef.h>\n\nstruct FooType {\n        int f1;\n        int f2;\n        double f3;\n};\n\nvoid foo()\n{\n  int off = offsetof(FooType, f2);\n}\nEOT\ntest_cxx \"whether offsetof is defined\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_OFFSETOF, $pass, [whether offsetof exists])\n\n#### test if we can use gcc x86 assembly like this ####\ncat > $t <<EOT\ndouble foo(void)\n{\n  unsigned long long int v=0;\n  int *lo=0+(int *)&v;\n  int *hi=1+(int *)&v;\n  __asm__ __volatile__(\n      \"rdtsc; movl %%edx,%0; movl %%eax,%1\"\n      : /* output  */ \"=m\" (*hi), \"=m\" (*lo)\n      : /* input */\n      : /* trashes */ \"%edx\", \"%eax\"\n  );\n  return v;\n}\nEOT\ntest_cxx \"whether GCC x86 assembly works\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_GCC_X86_ASM, $strictpass, [Allows gcc x86 assembly.])\n\n#### test if we can use gcc x86 assembly like this ####\nif test $strictpass = 1\nthen\ncat > $t <<EOT\nint foo(void)\n{\n  int x;\n  asm(\"lock incl %0\" :: \"m\" (x));\n  asm(\"lock decl %0\" :: \"m\" (x));\n  return x;\n}\nEOT\ntest_cxx \"whether GCC x86 assembly for atomic increment works\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_GCC_X86_ASM_ATOMICINCREMENT, $strictpass, [Allows gcc x86 assembly for atomic increment.])\nfi\n\n#### test if we can use asm eieio assembly like this ####\ncat > $t <<EOT\ndouble foo(void)\n{\n        unsigned long long int x;\n\tasm volatile(\"eieio\" ::: \"memory\");\n        return x;\n}\nEOT\ntest_cxx \"whether asm eieio assembly works\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_PPC_ASM, $strictpass, [Allows asm eieio assembly.])\n\n\n\n#### test if we can use __thread ####\ncat > $t <<EOT\n__thread unsigned long long int x;\nstatic __thread  int y;\nvoid foo(void)\n{\n\tx = 1;\n\ty = 1;\n}\nEOT\ntest_cxx \"whether __thread (Thread Local Storage) is supported\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_TLS_VARIABLES, $strictpass, [Allows __thread.])\n\n#### check __sync_add_and_fetch ####\ncat > $tc <<EOT\n#include <stdio.h>\nint main()\n{\n  int t=1;\n  __sync_add_and_fetch(&t, 1);\n  return 1;\n}\nEOT\ntest_linkc \"whether synchronization primitives (__sync_add_and_fetch) works in C\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_C_SYNC_ADD_AND_FETCH_PRIMITIVE, $pass, [whether sync_add_and_fetch primitive works in C])\n\n#### check __sync_synchronize ####\ncat > $tc <<EOT\n#include <stdio.h>\nint main()\n{\n  __sync_synchronize();\n}\nEOT\n\ntest_linkc \"whether synchronization primitives (__sync_synchronize) works in C\" \"yes\" \"no\" \"\"\n\nAC_DEFINE_UNQUOTED(CMK_C_SYNC_SYNCHRONIZE_PRIMITIVE, $pass, [whether sync_synchronize primitives works in C])\n\n\n### test for __executable_start ###\n\ncat > $tc <<EOT\nextern int __executable_start;\nint main()\n{\n  return __executable_start;\n}\nEOT\ntest_linkc \"whether has __executable_start\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED([CMK_HAS_EXECUTABLE_START], $pass, [whether has __executable_start])\n\n### test if switching TLS register ###\nif test $in64bit = 1\nthen\ncat > $t <<EOT\nvoid switchTLS() {\n  void * m1, * m2;\n  asm volatile (\"movq %%fs:0x0, %0\\n\\t\"\n                \"movq %1, %%fs:0x0\\n\\t\"\n                : \"=&r\"(m1)\n                : \"r\"(m2));\n}\nEOT\ntest_cxx \"whether switching TLS register (64-bit) is supported\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_TLS_SWITCHING_X86_64, $strictpass, [Allows switching TLS on x86_64.])\nelse\ncat > $t <<EOT\nvoid switchTLS() {\n  void * m1, * m2;\n  asm volatile (\"movl %%gs:0x0, %0\\n\\t\"\n                \"movl %1, %%gs:0x0\\n\\t\"\n                : \"=&r\"(m1)\n                : \"r\"(m2));\n}\nEOT\ntest_cxx \"whether switching TLS register (32-bit) is supported\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_TLS_SWITCHING_X86, $strictpass, [Allows switching TLS on x86.])\nfi\n\n### test for dl_iterate_phdr ###\n\ncat > $tc <<EOT\n#ifndef _GNU_SOURCE\n# define _GNU_SOURCE\n#endif\n#ifndef __USE_GNU\n# define __USE_GNU\n#endif\n#include <link.h>\n#include <stddef.h>\nstatic int callback(struct dl_phdr_info* info, size_t size, void* data)\n{\n  return 0;\n}\nint main()\n{\n  dl_iterate_phdr(callback, NULL);\n  return 0;\n}\nEOT\ntest_linkc \"whether has dl_iterate_phdr\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED([CMK_HAS_DL_ITERATE_PHDR], $pass, [whether has dl_iterate_phdr])\n\n\n### test for __malloc_hook ###\n\ncat > $tc <<EOT\nextern int __malloc_hook;\nint main()\n{\n  return __malloc_hook;\n}\nEOT\ntest_linkc \"whether has __malloc_hook\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED([CMK_HAS_MALLOC_HOOK], $pass, [whether has __malloc_hook])\nadd_make_flag \"CMK_HAS_MALLOC_HOOK:=$pass\" 'whether has __malloc_hook'\n\n\n#### test if we can build OFI ####\nif test \"$CMK_BUILD_OFI\" = 1\nthen\ncat > $tc <<EOT\n#include <rdma/fabric.h>\nint main(int argc, char **argv)\n{\n  struct fi_info *providers;\n  int ret = fi_getinfo(FI_VERSION(1,0), NULL, NULL, 0ULL, NULL, &providers);\n  return 0;\n}\nEOT\ntest_cc \"whether build on OFI\" \"yes\" \"no\" \"-lfabric\"\nAC_DEFINE_UNQUOTED(CMK_BUILD_ON_OFI, $strictpass, [build OFI.])\nBUILD_OFI=$strictpass\n\nif test $BUILD_OFI -eq 0\nthen\n  echo \"Error: Unable to compile OFI\"\n  test_finish 1\nelse\n  test_linkc \"whether -lfabric\" \"ok\" \"no\" \"-lfabric\"\n  if test $pass -eq 0\n  then\n    #test for psm incompatibility\n    PSM_COMPAT_DIR=/usr/lib64/psm2-compat\n    if test -d $PSM_COMPAT_DIR\n    then\n      add_flag CMK_LIBDIR='\"$CMK_LIBDIR -Wl,-rpath=/usr/lib64/psm2-compat\"' \"psm2-compat lib\"\n      CMK_LIBDIR=\"$CMK_LIBDIR -Wl,-rpath=/usr/lib64/psm2-compat\"\n      test_linkc \"whether -lfabric after adding psm2-compatible library\" \"ok\" \"no\" \"-lfabric\"\n      if test $pass -eq 0\n      then\n        echo \"Error: -lfabric not found or not working. Pass '--basedir=/path/to/dir/' if -lfabric is located in a different directory\"\n        test_finish 1\n      fi\n    else\n      echo \"Error: -lfabric not working, $PSM_COMPAT_DIR not found\"\n      echo \"Pass '--basedir=/path/to/dir/' if -lfabric is located in a different directory\"\n      test_finish 1\n    fi\n  fi\nfi\n\nfi\n\n#### test if we can build UCX ####\nif test \"$CMK_BUILD_UCX\" = 1\nthen\ncat > $tc <<EOT\n#include <ucp/api/ucp.h>\nint main(int argc, char **argv)\n{\n  unsigned major, minor, number;\n  ucp_get_version(&major, &minor, &number);\n  return 0;\n}\nEOT\ntest_cc \"whether build on UCX\" \"yes\" \"no\" \"-lucp\"\nAC_DEFINE_UNQUOTED(CMK_BUILD_ON_UCX, $strictpass, [build UCX.])\nBUILD_UCX=$strictpass\n\nif test $BUILD_UCX -eq 0\nthen\n  echo \"Error: Unable to compile UCX\"\n  test_finish 1\nelse\n  test_linkc \"whether -lucp\" \"ok\" \"no\" \"-lucp\"\nfi\n\nfi\n\n#### test if we can build MPI ####\nif test \"$CMK_BUILD_MPI\" = 1\nthen\n\ncat > $tc <<EOT\n#include \"mpi.h\"\nint main(int argc, char **argv)\n{\n  MPI_Init(&argc, &argv);\n  return 0;\n}\nEOT\nmv -f ../include/mpi.h ../include/mpi.h.bak 2>/dev/null\ntest_cc \"whether build on MPI\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_BUILD_ON_MPI, $strictpass, [build MPI.])\nBUILD_MPI=$strictpass\n\nif test $BUILD_MPI -eq 0\nthen\n  echo \"Error: Cannot compile an MPI program\"\n  test_finish 1\nfi\n\nif test $BUILD_MPI -eq 1\nthen\n  test_linkc \"whether need to specify MPI library\" \"no\" \"yes\" \"\"\n  if test $pass -ne 1\n  then\n    if test -z \"$CMK_MPI_LIB\"\n    then\n      test_linkc \"whether -lmpich\" \"ok\" \"no\" \"-lmpich\"\n      if test $pass -eq 1\n      then\n        add_flag CMK_SYSLIBS='\"$CMK_SYSLIBS -lmpich\"' \"mpi lib\"\n      else\n        test_linkc \"whether -lmpi\" \"ok\" \"no\" \"-lmpi\"\n        if test $pass -eq 1\n        then\n                add_flag CMK_SYSLIBS='\"$CMK_SYSLIBS -lmpi\"' \"mpi lib\"\n        else\n                echo \"Error: Cannot find MPI library\"\n                test_finish 1\n        fi\n      fi\n    else\n      add_flag CMK_SYSLIBS='\"$CMK_SYSLIBS $CMK_MPI_LIB\"' \"mpi lib\"\n    fi\n  fi\nfi\n\nif test \"$BUILD_MPI\" = \"1\"\nthen\ncat > $t <<EOT\n#include \"mpi.h\"\nint main(int argc, char **argv)\n{\n  int thread_level, provided;\n  thread_level = MPI_THREAD_FUNNELED;\n  MPI_Init_thread(&argc, &argv, thread_level, &provided);\n}\nEOT\ntest_cxx \"whether MPI_Init_thread is supported\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_MPI_INIT_THREAD, $strictpass, [Allows MPI_Init_thread.])\nfi\nmv -f ../include/mpi.h.bak ../include/mpi.h 2>/dev/null\n\nfi\n\nif test \"$BUILD_MPI\" = \"1\"\nthen\n\ncat > $t <<EOT\n#include <stdio.h>\n#include <mpi.h>\n\nint main (int argc, char** argv) {\n  return 0;\n}\nEOT\ntest_cxx \"whether macro conflicts occurs due to C++ MPI bindings\" \"no\" \"yes\" \"\"\nAC_DEFINE_UNQUOTED(CMK_CXX_MPI_BINDINGS, $strictpass, [Disables conflicting macros.])\nfi\n\n\n################### Syscalls and Libraries ###################\n\n#### test for getrusage with RUSAGE_THREAD ###\ncat > $tc <<EOT\n#ifndef _GNU_SOURCE\n# define _GNU_SOURCE\n#endif\n#ifndef __USE_GNU\n# define __USE_GNU\n#endif\n#include <sys/time.h>\n#include <sys/resource.h>\nint main() {\n  struct rusage usage;\n  getrusage(RUSAGE_THREAD, &usage);\n  return 0;\n}\nEOT\ntest_linkc \"whether getrusage accepts RUSAGE_THREAD\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_RUSAGE_THREAD, $pass, [whether getrusage accepts RUSAGE_THREAD])\n\n#### test for asctime ###\n\ncat > $tc <<EOT\n#include <time.h>\nint main() {\n  struct tm *local;\n  time_t t;\n  t = time(NULL);\n  local = localtime(&t);\n  asctime(local);\n  return 0;\n}\nEOT\ntest_linkc \"whether has asctime\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_ASCTIME, $pass, [whether has asctime])\n\n#### test for log2 ###\ncat > $t <<EOT\n#include <math.h>\nint main() {\n  int i = log2(10);\n  return 0;\n}\nEOT\ntest_link \"whether has log2\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_LOG2, $pass, [whether has log2])\n\n#### test for sqrtf ###\ncat > $t <<EOT\n#include <math.h>\nint main() {\n  float i = sqrtf((float)10.0);\n  return 0;\n}\nEOT\ntest_link \"whether has sqrtf\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_SQRTF, $pass, [whether has sqrtf])\n\n#### test for fabsf ###\ncat > $t <<EOT\n#include <math.h>\nint main() {\n  float i = fabsf((float)10.0);\n  return 0;\n}\nEOT\ntest_link \"whether has fabsf\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_FABSF, $pass, [whether has fabsf])\n\n#### test for mkstemp ###\ncat > $t <<EOT\n#include <stdlib.h>\n#include <string.h>\nint main() {\n  char fname[[128]];\n  strcpy(fname, \"/tmp/fdXXX.XXX\");\n  mkstemp(fname);\n  return 0;\n}\nEOT\ntest_link \"whether has mkstemp\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_USE_MKSTEMP, $pass, [whether has mkstemp])\n\n#### test for system ###\ncat > $t <<EOT\n#include <stdlib.h>\nint main() {\n  system(\"/bin/ls\");\n  return 0;\n}\nEOT\ntest_link \"whether has system\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_SYSTEM, $pass, [whether has system])\n\n#### test for sync() ###\ncat > $t <<EOT\n#include <unistd.h>\nint main() {\n  sync();\n  return 0;\n}\nEOT\ntest_link \"whether has sync()\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_SYNC_FUNC, $pass, [whether has sync])\n\n#### test for fsync() ###\ncat > $t <<EOT\n#include <unistd.h>\nint main() {\n  fsync(0);\n  return 0;\n}\nEOT\ntest_link \"whether has fsync()\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_FSYNC_FUNC, $pass, [whether has fsync])\n\n#### test for fdatasync() ###\ncat > $t <<EOT\n#include <unistd.h>\nint main() {\n  fdatasync(0);\n  return 0;\n}\nEOT\ntest_link \"whether has fdatasync()\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_FDATASYNC_FUNC, $pass, [whether has fdatasync])\n\n#### test for sbrk ###\ncat > $t <<EOT\n#include <unistd.h>\nint main() {\n  void *ptr  = sbrk(0); \n}\nEOT\ntest_link \"whether has sbrk\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_SBRK, $pass, [whether has sbrk])\n\n#### test for _setjmp/_longjmp ###\ncat > $t <<EOT\n#include <setjmp.h>\nint main() {\n  jmp_buf buf;\n  _setjmp(buf);\n  _longjmp(buf, 0);\n}\nEOT\ntest_link \"whether has _setjmp/_longjmp\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_UNDERSCORE_SETJMP, $pass, [whether has _setjmp/_longjmp])\n\n#### test for mstats ###\ncat > $t <<EOT\n#include <malloc.h>\nint main() {\n  struct mstats ms = mstats();\n}\nEOT\ntest_link \"whether has mstats\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_MSTATS, $pass, [whether has mstats])\n\n#### test for mallinfo ###\ncat > $t <<EOT\n#include <malloc.h>\nint main() {\n  struct mallinfo mi = mallinfo();\n}\nEOT\ntest_link \"whether has mallinfo\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_MALLINFO, $pass, [whether has mallinfo])\n\n#### test for __morecore ###\ncat > $t <<EOT\n#include <cstddef>\nint main() {\n  extern void *(*__morecore)(ptrdiff_t);\n  __morecore(0);\n  return 0;\n}\nEOT\ntest_link \"whether expects __morecore symbol\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_EXPECTS_MORECORE, $pass, [whether expects __morecore symbol])\n\n#### test for popen ###\ncat > $t <<EOT\n#include <stdio.h>\nint main() {\n  FILE *p = popen(\"/bin/ps\", \"r\");\n  pclose(p);\n}\nEOT\ntest_link \"whether has popen\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_POPEN, $pass, [whether has popen])\n\n#### test for poll ###\ncat > $t <<EOT\n#include <poll.h>\nvoid foo(void) { \n  struct pollfd pos[[3]];\n  poll(pos, 1, 1);\n}\nEOT\ntest_cxx \"whether has poll\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_USE_POLL, $pass, [whether the poll syscall exists])\n\n#### check if getpagesize exists ####\ncat > $tc <<EOT\n#include <unistd.h>\n\nint main(int argc, char **argv) {\n    int s = getpagesize();\n}\nEOT\ntest_linkc \"whether has getpagesize\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_GETPAGESIZE, $pass, [whether getpagesize exists])\n\n#### check if getpid exists ####\ncat > $tc <<EOT\n#include <sys/types.h>\n#include <unistd.h>\n\nint main(int argc, char **argv) {\n    pid_t pid = getpid();\n}\nEOT\ntest_linkc \"whether has getpid\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_GETPID, $pass, [whether getpid exists])\n\n#### check if kill exists ####\ncat > $tc <<EOT\n#include <sys/types.h>\n#include <unistd.h>\n#include <signal.h>\n\nint main(int argc, char**argv) \n{\n    pid_t pid = getpid();\n    kill(pid, 9);\n}\nEOT\ntest_linkc \"whether has kill\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_KILL, $pass, [whether kill exists])\n\n#### test for setpriority ###\ncat > $t <<EOT\n#include <sys/time.h>\n#include <sys/resource.h>\nvoid foo(void) { \n  setpriority(PRIO_PROCESS, 0, 0);\n}\nEOT\ntest_cxx \"whether has setpriority\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_SETPRIORITY, $pass, [whether the setpriority exists])\n\n#### test for system ###\ncat > $t <<EOT\n#include \"ckdll_system.C\"\nEOT\ntest_cxx \"whether to use signal-safe system() \" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_SIGSAFE_SYSTEM, $pass, [whether to use signal-safe system()])\n\n### test sched_setaffinity ####\ncat > $tc <<EOT\n#define _GNU_SOURCE\n#include <sched.h>\n\nint main()\n{\n  cpu_set_t cpuset;\n  CPU_ZERO(&cpuset);\n  CPU_SET(0, &cpuset);\n  if (sched_setaffinity(0, sizeof(cpuset), &cpuset) < 0) {\n    return -1;\n  }\n  return 0;\n}\nEOT\ntest_linkc \"whether sched_setaffinity call exists\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_SETAFFINITY, $pass, [whether the sched_setaffinity() exists])\n\n### test pthread_setaffinity_np ####\ncat > $tc <<EOT\n#include <stdlib.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <pthread.h>\n\nint main()\n{\n  unsigned long mask = 0xffffffff;\n  unsigned int len = sizeof(mask);\n\n  if (pthread_setaffinity_np(pthread_self(), len, &mask) < 0) {\n    return -1;\n  }\n  return 0;\n}\nEOT\ntest_linkc \"whether pthread_setaffinity_np call exists\" \"yes\" \"no\" \"-lpthread\"\nAC_DEFINE_UNQUOTED(CMK_HAS_PTHREAD_SETAFFINITY, $pass, [whether the pthread_setaffinity_np() exists])\n\n### test pthread_spin_lock ####\ncat > $tc <<EOT\n#include <stdlib.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <pthread.h>\n\nint main()\n{\n  pthread_spinlock_t  lock;\n\n  pthread_spin_init(&lock, 0);\n\n  pthread_spin_lock(&lock);\n\n  return 0;\n}\nEOT\ntest_linkc \"whether pthread_spin_lock exists\" \"yes\" \"no\" \"-lpthread\"\nAC_DEFINE_UNQUOTED(CMK_HAS_SPINLOCK, $pass, [whether the pthread_spin_lock exists])\n\n### check libnuma on Linux ####\nif test \"$WITH_NUMA\" = \"yes\"\nthen\ncat > $tc <<EOT\n#include <stdlib.h>\n#include <stdio.h>\n#include <linux/mempolicy.h>\n#include <numaif.h>\n#include <numa.h>\n\nint main()\n{\n  if (get_mempolicy(NULL, NULL, 0, 0, 0) == 0) return 0;\n  return -1;\n}\nEOT\ntest_linkc \"whether libnuma exists\" \"yes\" \"no\" \"-lnuma\"\nAC_DEFINE_UNQUOTED(CMK_HAS_NUMACTRL, $pass, [whether NUMA control related functions exist])\nif test $pass -eq 1\nthen\n        add_flag 'CMK_SYSLIBS=\"$CMK_SYSLIBS -lnuma\"' \"libnuma\"\nfi\nfi\n\n#### check bindprocessors on AIX ####\ncat > $tc <<EOT\n#include <stdlib.h>\n#include <stdio.h>\n#include <unistd.h>\n\n#include <sys/processor.h>\n\nint main()\n{\n  int retValue = 0;\n  int pid;\n  pid = getpid();\n  if (bindprocessor(BINDPROCESS, pid, 0) == -1) return -1;\n  return 0;\n}\nEOT\ntest_linkc \"whether bindprocessor call exists\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_BINDPROCESSOR, $pass, [whether the bindprocessor()\nexists])\n\n\n#### check if dlopen works ####\nskip_dl=0\n# for bproc, ignore -ldl\ntest -n \"$CMK_BPROC\" && skip_dl=1\ntest -n \"$CMK_NO_DL\" && skip_dl=1\ndl_opt='-ldl'\n#workaround for pgcc 4.0, -ldl crash linking, so use -Wl,-ldl to skip the prelinker.\ncase \"$CMK_CXX\" in\npgCC*) dl_opt='-Wl,-ldl' ;;\nesac\n\nif test $skip_dl -eq 0 \nthen\n\ncat > $t <<EOT\n#include \"ckdll_dlopen.C\"\nint main() {\n\tCkDll dll(\"foo.so\");\n\treturn 0;\n}\nEOT\ntest_link \"whether dlopen links without $dl_opt\" \"yes\" \"no\" \"\"\nnoldl=$pass\ntest_link \"whether dlopen links with $dl_opt\" \"yes\" \"no\" \"$dl_opt\"\nif test $pass -eq 1\nthen \n#dlopen requires -ldl: add it to our link line\n\tadd_flag CMK_LIBS='\"$CMK_LIBS '$dl_opt'\"' \"dlopen\"\nfi\n\nif test $pass -eq 1 -o $noldl -eq 1\nthen\n\tCMK_HAS_DLOPEN='1'\n# One version or another of dlopen worked: compile it in\n\tAC_DEFINE_UNQUOTED(CMK_DLL_USE_DLOPEN, 1, [dlopen])\nfi\n\ncat > $tc <<EOT\n#ifndef _GNU_SOURCE\n# define _GNU_SOURCE\n#endif\n#ifndef __USE_GNU\n# define __USE_GNU\n#endif\n#include <dlfcn.h>\n#include <stddef.h>\nint main()\n{\n  return dlsym(RTLD_DEFAULT, \"main\") != NULL;\n}\nEOT\ntest_cc \"whether has RTLD_DEFAULT\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_RTLD_DEFAULT, $pass, [whether has RTLD_DEFAULT])\n\ncat > $tc <<EOT\n#ifndef _GNU_SOURCE\n# define _GNU_SOURCE\n#endif\n#ifndef __USE_GNU\n# define __USE_GNU\n#endif\n#include <dlfcn.h>\n#include <stddef.h>\nint main()\n{\n  return dlsym(RTLD_NEXT, \"main\") != NULL;\n}\nEOT\ntest_cc \"whether has RTLD_NEXT\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_RTLD_NEXT, $pass, [whether has RTLD_NEXT])\n\ncat > $tc <<EOT\n#ifndef _GNU_SOURCE\n# define _GNU_SOURCE\n#endif\n#ifndef __USE_GNU\n# define __USE_GNU\n#endif\n#include <dlfcn.h>\n#include <stddef.h>\nint main()\n{\n  return dlmopen(LM_ID_NEWLM, \"foo.so\", 0) == NULL;\n}\nEOT\ntest_cc \"whether has dlmopen\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_DLMOPEN, $pass, [whether has dlmopen])\nCMK_HAS_DLMOPEN=\"$pass\"\n\ncat > $tc <<EOT\n#include <unistd.h>\nint main()\n{\n  char exe[[1024]];\n  return readlink(\"/proc/self/exe\", exe, sizeof(exe)-1) == -1;\n}\nEOT\ntest_cc \"whether has readlink\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_READLINK, $pass, [whether has readlink])\nCMK_HAS_READLINK=\"$pass\"\n\ncat > $tc <<EOT\n#include <limits.h>\n#include <stdlib.h>\nint main()\n{\n  return realpath(\"/proc/self/exe\", NULL) == NULL;\n}\nEOT\ntest_cc \"whether has realpath\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_REALPATH, $pass, [whether has realpath])\nCMK_HAS_REALPATH=\"$pass\"\n\ncase \"$CMK_VDIR\" in\n  *-win-*|*-win64)\n    CMK_CAN_GET_BINARY_PATH='1'\n    CMK_CAN_OPEN_SHARED_OBJECTS_DYNAMICALLY='0' # TODO: technically possible, but more work to be done\n    ;;\n  *-darwin*)\n    CMK_CAN_GET_BINARY_PATH='1'\n    CMK_CAN_OPEN_SHARED_OBJECTS_DYNAMICALLY=\"$CMK_HAS_DLOPEN\"\n    ;;\n  *)\n    if test \"$CMK_HAS_READLINK\" = '1' -o \"$CMK_HAS_REALPATH\" = '1'\n    then\n      CMK_CAN_GET_BINARY_PATH='1'\n    else\n      CMK_CAN_GET_BINARY_PATH='0'\n    fi\n    CMK_CAN_OPEN_SHARED_OBJECTS_DYNAMICALLY=\"$CMK_HAS_DLOPEN\"\n    ;;\nesac\n\nif test \"$CMK_CAN_OPEN_SHARED_OBJECTS_DYNAMICALLY\" = '1' -a \"$CMK_CAN_GET_BINARY_PATH\" = '1'\nthen\n  CMK_SUPPORTS_FSGLOBALS='1'\nelse\n  CMK_SUPPORTS_FSGLOBALS='0'\nfi\nAC_DEFINE_UNQUOTED(CMK_SUPPORTS_FSGLOBALS, $CMK_SUPPORTS_FSGLOBALS, [whether supports filesystem globals])\nadd_flag \"CMK_SUPPORTS_FSGLOBALS=$CMK_SUPPORTS_FSGLOBALS\" 'filesystem globals'\nadd_make_flag \"CMK_SUPPORTS_FSGLOBALS:=$CMK_SUPPORTS_FSGLOBALS\" 'filesystem globals'\n\nif test \"$CMK_HAS_DLMOPEN\" = '1' -a \"$CMK_CAN_GET_BINARY_PATH\" = '1'\nthen\n  CMK_SUPPORTS_PIPGLOBALS='1'\nelse\n  CMK_SUPPORTS_PIPGLOBALS='0'\nfi\nAC_DEFINE_UNQUOTED(CMK_SUPPORTS_PIPGLOBALS, $CMK_SUPPORTS_PIPGLOBALS, [whether supports PiP globals])\nadd_flag \"CMK_SUPPORTS_PIPGLOBALS=$CMK_SUPPORTS_PIPGLOBALS\" 'PiP globals'\nadd_make_flag \"CMK_SUPPORTS_PIPGLOBALS:=$CMK_SUPPORTS_PIPGLOBALS\" 'PiP globals'\n\n\n### test gethostname ####\ncat > $tc <<EOT\n#ifdef _WIN32\n#include <Winsock2.h>\n#else\n#include <stdlib.h>\n#include <stdio.h>\n#include <unistd.h>\n#endif\n\nint main()\n{\n  char hostname[[1000]];\n  gethostname(hostname, 999);\n  return 0;\n}\nEOT\ntest_cc \"whether gethostname call exists\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_GETHOSTNAME, $pass, [whether gethostname() exists])\n\n#### check if getProcAddress works ####\ncat > $t <<EOT\n#include \"ckdll_win32.C\"\nEOT\ntest_cxx \"whether getProcAddress works\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_DLL_USE_WIN32, $pass, [whether getProcAddress works])\n\nfi    # end of skip_dl\n\n#### check if socklen_t exists ####\ncat > $t <<EOT\n#include <sys/types.h>\n#include <sys/socket.h>\n\nvoid foo(void) {\n\tint i;\n\tsocklen_t s=sizeof(i);\n}\nEOT\ntest_cxx \"whether has socklen_t\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_SOCKLEN, $pass, [whether has socklen_t])\n\n### test getifaddrs ####\ncat > $tc <<EOT\n#include <netinet/in.h> /* for sockaddr_in */\n#include <ifaddrs.h> /* for getifaddrs */\n#include <net/if.h> /* for IFF_RUNNING */\n\nint main()\n{\n  struct ifaddrs *interfaces=0;\n  if( getifaddrs(&interfaces) == 0 ) {\n        struct ifaddrs *interface;\n        for( interface=interfaces; interface; interface=interface->ifa_next ) {\n            if( (interface->ifa_flags & IFF_UP) && ! (interface->ifa_flags & IFF_LOOPBACK) ) {\n                const struct sockaddr_in *addr = (const struct sockaddr_in*)interface->ifa_addr;\n                if( addr && addr->sin_family==AF_INET ) {\n                    break;\n                }\n            }\n        }\n        freeifaddrs(interfaces);\n  }\n}\nEOT\ntest_linkc \"whether getifaddrs call exists\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_GETIFADDRS, $pass, [whether getifaddrs() exists])\n\n#### check if mmap exists ####\ncat > $t <<EOT\n#include <sys/types.h>\n#include <sys/mman.h>\n\nvoid *foo(void *a,int l,int fd) {\n\treturn mmap((caddr_t)a,l,PROT_READ+PROT_WRITE,\n                 MAP_FIXED+MAP_PRIVATE,fd,0);\n}\nEOT\ntest_cxx \"whether the mmap() syscall exists\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_MMAP, $pass, [whether the mmap() syscall exists])\nadd_flag \"CMK_HAS_MMAP=$pass\"\nadd_make_flag \"CMK_HAS_MMAP:=$pass\"\n\n#### check if mmap accepts MAP_ANON ####\ncat > $t <<EOT\n#include <sys/types.h>\n#include <sys/mman.h>\n\nvoid *foo(void *a,int l) {\n\treturn mmap((caddr_t)a,l,PROT_READ+PROT_WRITE,\n                MAP_FIXED+MAP_PRIVATE+MAP_ANON,-1,0);\n}\nEOT\ntest_cxx \"whether mmap() accepts MAP_ANON\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_MMAP_ANON, $pass, [whether mmap() accepts MAP_ANON])\n\n#### check if mmap accepts MAP_NORESERVE ####\ncat > $t <<EOT\n#include <sys/types.h>\n#include <sys/mman.h>\n\nvoid *foo(void *a,int l) {\n\treturn mmap((caddr_t)a,l,PROT_READ+PROT_WRITE,\n                MAP_FIXED+MAP_PRIVATE+MAP_NORESERVE,-1,0);\n}\nEOT\ntest_cxx \"whether mmap() accepts MAP_NORESERVE\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_MMAP_NORESERVE, $pass, [whether mmap() accepts MAP_NORESERVE])\n\n#### check if get_myaddress exists ####\ncat > $t <<EOT\n#include <rpc/rpc.h>\n\nvoid foo(void *a) {\n    get_myaddress((struct sockaddr_in*)a);\n}\nEOT\ntest_cxx \"whether has get_myaddress\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_GET_MYADDRESS, $pass, [whether has get_myaddress])\n\n#### check if mprotect exists ####\ncat > $t <<EOT\n#include <stdio.h>\n#include <sys/mman.h>\n\nvoid foo(void *a,int l,int fd) {\n     void *pg = NULL;\n     size_t pagesize = 4096;\n     mprotect(pg, pagesize, PROT_READ | PROT_WRITE);\n}\nEOT\ntest_cxx \"whether has mprotect\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_MPROTECT, $pass, [whether has mprotect])\n\n#### check if support for SHM through CMA exists ####\ncat > $t <<EOT\n#define _GNU_SOURCE\n#include <sys/uio.h>\n#include <errno.h>\nint main() {\n  pid_t pid;\n  struct iovec *local, *remote;\n  int nread = process_vm_readv(pid, local, 1, remote, 1, 0);\n  nread = process_vm_writev(pid, local, 1, remote, 1, 0);\n  return errno;\n}\nEOT\ntest_link \"whether has support for shm transport using Cross Memory Attach\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_CMA, $pass, [whether supports cma])\nCMK_HAS_CMA=\"$pass\"\n\ntest \"$CMK_HAS_CMA\" = '1' -a \"$CMK_MULTICORE\" != '1' -a \"$CMK_BLUEGENEQ\" != '1' && CMK_USE_CMA='1' || CMK_USE_CMA='0'\nadd_make_flag \"CMK_USE_CMA:=$CMK_USE_CMA\" 'Cross Memory Attach'\n\n#### check if -rdynamic works ####\ncat > $t <<EOT\nint main() {\n  return 0;\n}\nEOT\nTRACE_LINK_FLAG=''\nCAN_EXPORT_SYMBOLS='0'\nfor i in '-rdynamic' '-Wl,--export-dynamic'; do\n  test_link \"whether has $i\" \"yes\" \"no\" \"$i\"\n  if test \"$strictpass\" = '1'; then\n    TRACE_LINK_FLAG=\"$i\"\n    CAN_EXPORT_SYMBOLS='1'\n    break\n  fi\ndone\n\nif test \"$CAN_EXPORT_SYMBOLS\" = '1'; then\n  add_flag 'CMK_LD=\"$CMK_LD '$TRACE_LINK_FLAG'\"' \"exporting program symbols to shared objects\"\n  add_flag 'CMK_LDXX=\"$CMK_LDXX '$TRACE_LINK_FLAG'\"' \"exporting program symbols to shared objects\"\nfi\n\n#### check if glibc backtrace exists ####\ncat > $t <<EOT\n#include \"cmibacktrace.C\"\n\nint main() {\n\tint nLevels=1;\n\tvoid *stack;\n\tCmiBacktraceRecord(&stack,0,&nLevels);\n\treturn 0;\n}\nEOT\ntest_link \"whether glibc backtrace works\" \"yes\" \"no\" \"-DCMK_USE_BACKTRACE=1 $TRACE_LINK_FLAG\"\nAC_DEFINE_UNQUOTED(CMK_USE_BACKTRACE, $pass, [whether glibc backtrace works])\n\n#### test sleep ####\ncat > $t <<EOT\n#include <unistd.h>\nint main() {\n  sleep(1);\n  return 0;\n}\nEOT\ntest_cxx \"whether has sleep \" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_SLEEP, $pass, [whether has sleep])\n\n#### test usleep ####\ncat > $t <<EOT\n#include <unistd.h>\nint main() {\n  usleep(100);\n  return 0;\n}\nEOT\ntest_cxx \"whether has usleep \" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_USLEEP, $pass, [whether has usleep])\n\n#### test personality() and ADDR_NO_RANDOMIZE ####\n# Only works on modern Linux systems\ncat > $t <<EOT\n#include <sys/personality.h>\nint main() {\n    int orig_persona = personality(0xffffffff);\n    personality(orig_persona | ADDR_NO_RANDOMIZE);\n    return 0;\n}\nEOT\ntest_cxx \"whether personality() and ADDR_NO_RANDOMIZE exist\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_ADDR_NO_RANDOMIZE, $pass, [whether personality() and ADDR_NO_RANDOMIZE exist])\n\n\n# enable/disable zlib\nAC_ARG_ENABLE([zlib],\n            [AS_HELP_STRING([--enable-zlib],\n              [enable zlib support])],\n            [enable_zlib=$enableval],\n            [enable_zlib=yes])\n\n#### test if has zlib ####\n# bproc doesnot like -lz in any case\nif test -z \"$CMK_BPROC\" && test \"$enable_zlib\" = \"yes\"\nthen\n\ncat > $t <<EOT\n#include <zlib.h>\nint main() { \n  gzFile f = gzopen(\"/tmp/x\",\"r\");\n  gzprintf(f, \"test...\\n\");\n  gzclose(f);\n  return 0;\n}\nEOT\ntest_link \"whether has zlib\" \"yes\" \"no\" \"-lz\"\nAC_DEFINE_UNQUOTED(CMK_USE_ZLIB, $pass, [whether has zlib])\nif test $pass -eq 1\nthen \n\tadd_flag 'CMK_SYSLIBS=\"$CMK_SYSLIBS -lz\"' \"zlib\"\nfi\n\nfi\n\n#### test if has elf.h ####\ncat > $t <<EOT\n#include <elf.h>\ntypedef Elf32_Addr ELF_TYPE_Addr;\nint main() { \n}\nEOT\ntest_cxx \"whether has elf.h \" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED([CMK_HAS_ELF_H], $pass, [whether has elf.h])\nif test $pass -eq 1\nthen\n\tadd_flag \"CMK_HAS_ELF_H='1'\" \"elf.h\"\nfi\n\n#### test if has Multiprocessing.h for apple ####\ncat > $t <<EOT\n#include <Carbon/Carbon.h>\n#include <Multiprocessing.h>\nint main() {\n  int a = MPProcessorsScheduled();\n}\nEOT\ntest_cxx \"whether has Multiprocessing.h for Apple \" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED([CMK_HAS_MULTIPROCESSING_H], $pass, [whether has Multiprocessing.h])\n\n#### test if \"ntohl\" is available ####\ncat > $t <<EOT\n#if defined(_WIN32) || defined(__MINGW_H)\n#include <winsock.h>\n#else\n#include <stdint.h>\n#include <arpa/inet.h>\n#include <netinet/in.h>\n#endif\n\nint main() {\n  int i = 100;\n  i = ntohl(i);\n  return 0;\n}\nEOT\ntest_cc \"whether ntohl is available\" \"yes\" \"no\" \"\"\nAC_DEFINE_UNQUOTED(CMK_HAS_NTOHL, $pass, [whether ntohl is available])\n\n### test for libjpeg ####\ncat > $t <<EOT\n#include <stdio.h>\n#include <stdlib.h>\n#include \"jpeglib.h\"\n\nint main()\n{\n  struct jpeg_compress_struct cinfo;\n  jpeg_create_compress(&cinfo);\n  return 0;\n}\nEOT\ntest_link \"whether has libjpeg\" \"yes\" \"no\" \"-ljpeg\"\nAC_DEFINE_UNQUOTED(CMK_USE_LIBJPEG, $pass, [whether has libjpeg])\nif test $pass -eq 1\nthen\n        add_flag 'CMK_LIBJPEG=\"-ljpeg\"' \"libjpeg\"\n        add_make_flag 'CMK_LIBJPEG:=-ljpeg' 'libjpeg'\nfi\n\n#### check if PAPI exists ####\nif test -n \"$CMK_USE_PAPI\"\nthen\ncat > $t <<EOT\n#include <stdio.h>\n#include <papi.h>\n                                                                                \nint main() {\n    if (PAPI_library_init(PAPI_VER_CURRENT) != PAPI_VER_CURRENT) return 1;\n    return 0;\n}\nEOT\ntest_link \"whether PAPI exists\" \"yes\" \"no\" \"-lpapi\"\nAC_DEFINE_UNQUOTED(CMK_HAS_COUNTER_PAPI, $pass, [whether PAPI exists])\nif test \"$enable_tracing\" = \"no\"\nthen\n\techo \"Error: Cannot build papi version when tracing is disabled, build with --enable-tracing\"\n\ttest_finish 1\nelif test $fail -eq 1\nthen\n\techo \"Error: Cannot find papi library\"\n\ttest_finish 1\nelse\n\tadd_flag 'CMK_LIBS=\"$CMK_LIBS -lpapi\"' \"papi\"\nfi\nfi\n\n#### test if Python headers are installed ####\nPYTHON_VERSION=`python -V 2>&1 | awk {'print $2'} | awk -F. {'print $1\".\"$2'}`\ncat > $t <<EOT\n#include \"python${PYTHON_VERSION}/Python.h\"\n#include \"python${PYTHON_VERSION}/compile.h\"\n#include \"python${PYTHON_VERSION}/eval.h\"\n#include \"python${PYTHON_VERSION}/node.h\"\n\nint main() {\n    Py_Initialize();\n    PyEval_InitThreads();\n    struct _node* programNode = PyParser_SimpleParseString(\"return 1\\n\",Py_file_input);\n    PyCodeObject *program = PyNode_Compile(programNode, \"\");\n}\nEOT\ntest_link \"whether Python is installed\" \"yes\" \"no\" \"-lpython$PYTHON_VERSION -lpthread -lutil -ldl\"\nAC_DEFINE_UNQUOTED(CMK_HAS_PYTHON, $pass, [whether Python is installed])\nAC_DEFINE_UNQUOTED(CMK_PYTHON_VERSION, ${PYTHON_VERSION}, [Python version])\nif test $pass -eq 1\nthen\n\tadd_flag \"CMK_BUILD_PYTHON=$PYTHON_VERSION\" \"python\"\n\tadd_make_flag \"CMK_BUILD_PYTHON:=$PYTHON_VERSION\" 'python'\nfi\n\n## Cray specific test\nif test \"$CMK_BUILD_CRAY\" = \"1\"\nthen\n#echo \"Test for known incompatible compiler versions\"\n\n if test \"$CRAY_CC_VERSION\" = \"8.1.4\"\n then\n\techo \"CCE 8.1.4 produces incorrect Charm++ code\"\n\techo \"Please use a newer version of the CCE compiler\"\n\techo \"e.g. module load cce/8.1.7\"\n\ttest_finish 1\n fi\n\n#### test if Cray node topology will work ####\ncat > $tc <<EOT\n#include <pmi.h>\n\nint main() {\n    int nid;\n    PMI_Get_nid(0, &nid);\n\n    return 0;\n}\nEOT\ntest_linkc \"whether PMI_Get_nid exists\" \"yes\" \"no\" \"$CMK_CRAY_LIBS\"\nAC_DEFINE_UNQUOTED(CMK_HAS_PMI_GET_NID, $pass, [whether PMI_Get_nid exists])\n\n#### test if Cray mesh topology will work ####\ncat > $tc <<EOT\n#include <rca_lib.h>\n\nint main() {\n    rca_mesh_coord_t xyz;\n    rca_get_meshcoord(0, &xyz);\n\n    return 0;\n}\nEOT\ntest_linkc \"whether Cray rca library is available\" \"yes\" \"no\" \"$CRAY_RCA_POST_LINK_OPTS -lrca\"\nAC_DEFINE_UNQUOTED(CMK_HAS_RCALIB, $pass, [whether Cray rca library is available])\n\n#### test if Cray mesh dimension query function will work ####\ncat > $tc <<EOT\n#include <rca_lib.h>\n\nint main() {\n    rca_mesh_coord_t xyz;\n    rca_get_max_dimension(&xyz);\n\n    return 0;\n}\nEOT\ntest_linkc \"whether Cray rca_has get_max_dimension\" \"yes\" \"no\" \"$CRAY_RCA_POST_LINK_OPTS -lrca\"\nAC_DEFINE_UNQUOTED(CMK_HAS_RCA_MAX_DIMENSION, $pass, [whether Cray rca has rca_get_max_dimension])\n\n#### query Cray machine max NID if get_max_dimension not exist ####\n\nif test $pass -eq 0\nthen\ncmd=`which xtprocadmin 2>/dev/null`\nif test -n \"$cmd\"\nthen\n    #maxnid=`xtprocadmin  | tail -1  | awk '{print $1}'`\n    # workaround for hopper\n    (export SHELL=/bin/csh; xtprocadmin >& t.$$)\n    maxnid=`cat t.$$  | tail -1  | awk '{print $1}'`\n    /bin/rm -f t.$$\n    AC_MSG_CHECKING(Cray machine maxnid)\n    AC_MSG_RESULT(\"$maxnid\")\n    if test -n \"$maxnid\"\n    then\n    AC_DEFINE_UNQUOTED(CMK_CRAY_MAXNID, $maxnid, [Cray MAXNID])\n    fi\nfi\nfi\n\n\n\n\n#### query Cray machine supports BANDWIDTH_INJECTION controls####\n\nif test \"$CMK_BUILD_MPI\" = \"1\"\nthen\necho \"BALANCED_INJECTION test disabled on MPI\"\nelif test \"$GNI_CRAYXC\" = \"1\"\nthen\necho \"BALANCED_INJECTION test disabled on Aries network\"\nelse\ncat > $tc <<EOT\n#include <stdint.h>\n#include <gni_pub.h>\n\nint main() {\n    gni_bi_desc_t gni_bi_desc;\n    uint32_t gni_device_id = 0;\n    gni_return_t gni_rc = GNI_GetBIConfig(gni_device_id, &gni_bi_desc);\n    if (gni_rc == GNI_RC_SUCCESS) {\n    }\n    return 0;\n}\nEOT\ntest_linkc \"whether GNI_GetBIConfig exists\" \"yes\" \"no\" \"$CMK_CRAY_LIBS\"\nAC_DEFINE_UNQUOTED(CMK_BALANCED_INJECTION_API, $pass, [whether Cray gni_pub has GNI_GetBIConfig])\nfi # end of BIConfig test\n\n\nfi  # end of Cray specific test\n\n#### test if it can build shared library ####\ncat > $t <<EOT\n#include \"stdlib.h\"\nextern int foo();\nint foo1() { \n  void * t= malloc(2);\n  foo();\n  return 0;\n}\nEOT\ntest_linkso \"whether can build shared library\" \"yes\" \"no\" \"\"\nif test $pass -eq 0\nthen \n\tadd_flag 'CMK_NO_BUILD_SHARED=\"true\"' \"build-shared\"\n\tadd_make_flag 'CMK_NO_BUILD_SHARED:=true' 'build-shared'\n\tCMK_NO_BUILD_SHARED='true'\nelse\n\tBUILD_SHARED=1\n        if test \"$BUILD_MPI\" = \"1\"\n\tthen\ncat > $t <<EOT\n#include \"stdlib.h\"\n#include \"mpi.h\"\nextern int foo();\nint foo(int argc, char ** argv) {\n  void * t= malloc(2);\n  foo();\n  MPI_Init(&argc, &argv);\n  return 0;\n}\nEOT\n\t\ttest_linkso \"whether can build shared library with MPI\" \"yes\" \"no\" \"\"\n\t\tBUILD_SHARED=$pass\n\tfi\n\tif test $BUILD_SHARED -eq 0\n\tthen\n\t\tadd_flag 'CMK_NO_BUILD_SHARED=\"true\"' \"build-shared\"\n\t\tadd_make_flag 'CMK_NO_BUILD_SHARED:=true' 'build-shared'\n\t\tCMK_NO_BUILD_SHARED='true'\n\tfi\nfi\n\n#### test the version number of bproc ####\nif test -n \"$CMK_BPROC\"\nthen\ncat > $t <<EOT\n#include <stdio.h>\n#include <sys/bproc.h>\nint main()\n{\n  struct bproc_version_t vers;\n  bproc_version(&vers);\n  printf(\"%s\\n\", vers.version_string);\n}\nEOT\ntest_link \"whether bproc compiles\" \"yes\" \"no\" \"-lbproc\"\nif test $pass -eq 1\nthen \nAC_MSG_CHECKING(\"bproc version\")\nbproc_ver=`./testlink`\nif test x$bproc_ver = x\nthen\ntest_result 0 \"bproc version\" \"ERROR\" \"\"\ntest_finish 1\nelse\ntest_result 0 \"bproc version\" \"$bproc_ver\" \"\"\nfi\nbproc_ver=`echo $bproc_ver | cut -d'.' -f1`\nAC_DEFINE_UNQUOTED(CMK_BPROC_VERSION, $bproc_ver, [bproc version])\nfi\nfi\n\n#### test the if command sync exists ####\nAC_CHECK_PROG(SYNC, sync, sync )\nif test -n \"$SYNC\"\nthen\nAC_DEFINE_UNQUOTED(CMK_HAS_SYNC, 1, [sync program])\nfi\n\n################## Fortran #########################\n\n#echo \"set F77 compiler as: $CMK_CF77\"\nAC_MSG_CHECKING(\"F77 compiler as\")\nAC_MSG_RESULT(\"$CMK_CF77\")\n\nAC_MSG_CHECKING(\"whether Fortran 77 compiler works\")\n### test fortran 77 compiler ###\ncat > conftest.f <<EOF\n      SUBROUTINE FOO_foo\n      END\nEOF\n$CMK_CF77 -c conftest.f > /dev/null 2> /dev/null\nif test ! -r conftest.o\nthen\n  AC_MSG_RESULT(\"no\")\nelse\n  AC_MSG_RESULT(\"yes\")\nfi\n\n### test fortran 90 compiler ###\n#echo \"set F90 compiler as: $CMK_CF90\"\nAC_MSG_CHECKING(\"F90 compiler as\")\nAC_MSG_RESULT(\"$CMK_CF90\")\n\nAC_MSG_CHECKING(\"whether Fortran 90 compiler works\")\ncat > conftest2.f90 <<EOF\n      SUBROUTINE FOO_foo\n      END\nEOF\n$CMK_CF90 -c conftest2.f90 > /dev/null 2> /dev/null\nif test ! -r conftest2.o\nthen\n  AC_MSG_RESULT(\"no\")\nelse\n  AC_MSG_RESULT(\"yes\")\n  mv -f conftest2.o conftest.o\n  USE_FORTRAN90=1\nfi\n\n### check fortran name mangling\nAC_MSG_CHECKING(subroutine name used by Fortran 90 compiler)\n\nif test -r conftest.o\nthen\n  AC_CACHE_VAL(_cv_fortran_postfix,\n\n  NAME=`$CMK_NM conftest.o | grep \"foo_foo__\"`\n  if test \"$NAME\" != \"\"\n  then\n    _cv_fortran_postfix=TWOSCORE\n    AC_DEFINE_UNQUOTED(CMK_FORTRAN_USES_TWOSCORE, 1, [TWOSCORE])\n  else\n    NAME=`$CMK_NM conftest.o | grep \"foo_foo_\"`\n    if test \"$NAME\" != \"\"\n    then\n      _cv_fortran_postfix=ONESCORE\n      AC_DEFINE_UNQUOTED(CMK_FORTRAN_USES_ONESCORE, 1, [ONESCORE])\n    else\n      NAME=`$CMK_NM conftest.o | grep \"foo_foo\"`\n      if test \"$NAME\" != \"\"\n      then\n        _cv_fortran_postfix=NOSCORE\n        AC_DEFINE_UNQUOTED(CMK_FORTRAN_USES_NOSCORE, 1, [NOSCORE])\n      else\n        NAME=`$CMK_NM conftest.o | grep \"FOO_FOO\"`\n        if test \"$NAME\" != \"\"\n        then\n          _cv_fortran_postfix=ALLCAPS\n          AC_DEFINE_UNQUOTED(CMK_FORTRAN_USES_ALLCAPS, 1, [ALLCAPS])\n        else\n          echo \"#################################################\"\n          echo \"FORTRAN compiler generated name not supported yet\"\n          echo \"#################################################\"\n        fi\n      fi\n    fi\n  fi\n  rm -f conftest.f conftest.o\n  )\n  AC_MSG_RESULT($_cv_fortran_postfix)\nelse\n  AC_MSG_RESULT(\"Fortran compiler not working\")\nfi\n\n### check module name ###\n\nif test \"$USE_FORTRAN90\" = 1\nthen\n  cat > conftest.f90 <<EOF\n      MODULE testmod\n        interface \n          function fpup_issizing(p)\n          INTEGER :: p\n          logical fpup_issizing\n          end function\n        end interface\n      END MODULE\nEOF\n  AC_MSG_CHECKING(Fortran 90 mod name is capital)\n  $CMK_CF90 -c conftest.f90 > /dev/null 2> /dev/null\n  name=`ls TESTMOD.* 2>/dev/null`\n  if test -n \"$name\"\n  then\n        AC_MSG_RESULT(\"yes\")\n\tadd_flag 'CMK_MOD_NAME_ALLCAPS=1' \"mod name capital\"\n  else\n        AC_MSG_RESULT(\"no\")\n\tname=`ls testmod.* 2>/dev/null`\n  fi\n  if test -n \"$name\"\n  then\n  \tAC_MSG_CHECKING(Fortran 90 mod name extension)\n    \text=`echo $name | sed -e 's/^[[^.]]*\\.//'`\n\tadd_flag 'CMK_MOD_EXT=\"'$ext'\"' \"mod name extension\"\n        AC_MSG_RESULT(\"$ext\")\n        /bin/rm -f $name\n  fi\n  /bin/rm -f conftest.f90\nfi\n\n### test if the C++ linker succeeds with a Fortran entry point ##\n\ncat > conftest.f90 <<EOF\n      PROGRAM empty\n      END PROGRAM\nEOF\ntest_link_fortran_main() {\n  AC_MSG_CHECKING(\"$1\")\n  echo \"### $1\" >> $charmout\n  cat conftest.f90 >> $charmout\n  echo $CMK_CF90 -c conftest.f90 -o test.o $4 >> $charmout\n  $CMK_CF90 -c conftest.f90 -o test.o $4 > out 2>&1\n  if test $? -ne 0\n  then\n    test_result 1 \"$1\" \"$2\" \"$3\"\n  else\n    echo $CMK_LDXX $CMK_LDXX_FLAGS $CMK_LINK_BINARY -o testlink test.o $CMK_LIBDIR $OPTS_LD $CMK_SYSLIBS $CMK_F90LIBS $CMK_F90MAINLIBS $4 $5 >> $charmout\n    $CMK_LDXX $CMK_LDXX_FLAGS $CMK_LINK_BINARY -o testlink test.o $CMK_LIBDIR $OPTS_LD $CMK_SYSLIBS $CMK_F90LIBS $CMK_F90MAINLIBS $4 $5 >> out 2>&1\n    ret=$?\n    test ! -x testlink && ret=1\n    test_result $ret \"$1\" \"$2\" \"$3\"\n  fi\n  cat out >> $charmout\n}\ntest_link_fortran_main \"whether the C++ linker succeeds with a Fortran entry point\" \"yes\" \"no\" \"\"\n/bin/rm -f conftest.f90 test.o testlink out\nif test $pass -eq 1\nthen\n  add_flag \"CMK_CAN_LINK_FORTRAN='1'\" \"Fortran\"\nfi\n\n### check for OpenMP availability ###\ncat > $tc <<EOT\n#include <stdio.h>\n#include <omp.h>\n\nint main(void)\n{\n  int iam = 0, np = 1;\n\n  #pragma omp parallel default(shared) private(iam, np)\n  {\n    np = omp_get_num_threads();\n    iam = omp_get_thread_num();\n    printf(\"Hello from thread %d of %d\\n\", iam, np);\n  }\n\n  return 0;\n}\nEOT\ntest_linkc \"whether OpenMP is supported\" \"yes\" \"no\" \"$CMK_C_OPENMP\"\nif test $pass -eq 1\nthen\n\tadd_flag \"CMK_HAS_OPENMP='1'\" \"OpenMP\"\nfi\n\n### check for Lustre FS availability ###\ncat > $tc <<EOT\n#include <stdio.h>\n#include <lustre/lustreapi.h>\n#include <lustre/lustre_user.h>\n\nint main() {\n  llapi_printf(LLAPI_MSG_NORMAL, \"Lustre FS is available\");\n  return 0;\n}\nEOT\ntest_linkc \"whether has lustre fs\" \"yes\" \"no\" \"-llustreapi\"\nAC_DEFINE_UNQUOTED(CMK_HAS_LUSTREFS, $pass, [whether has lustrefs])\nif test $pass -eq 1\nthen\n  add_make_flag 'CMK_LUSTREAPI:=-llustreapi' \"lustreapi\"\nelse\n  add_make_flag 'CMK_LUSTREAPI:=' \"lustreapi\"\nfi\n\n\n# for hwloc\neval \"`./charmc -print-building-blocks $OPTS`\"\nexport CC=\"$(get_full_command_name \"$CMK_SEQ_CC\")\"\nexport CXX=\"$(get_full_command_name \"$CMK_SEQ_CXX\")\"\nexport CC_FOR_BUILD=\"$(get_full_command_name \"$CMK_NATIVE_CC\")\"\nAC_SUBST(CC_FOR_BUILD)\nexport HWLOC_FLAGS=\"$CHARM_CC_FLAGS\"\nexport CFLAGS=\"$CMK_SEQ_CC_FLAGS\"\nexport AR=\"$(get_full_command_name \"${CMK_SEQ_AR%% *}\")\"\nenable_embedded_mode='yes'\nenable_static='yes'\nif test \"$CMK_NO_BUILD_SHARED\" = 'false'\nthen\n  enable_shared='yes'\n  export am_libhwloc_embedded_la_rpath=\"-rpath $CHARMLIBSO\"\nelse\n  enable_shared='no'\n  export am_libhwloc_embedded_la_rpath=''\nfi\nAC_SUBST(am_libhwloc_embedded_la_rpath)\nenable_libnuma='no'\nenable_pci='no'\nenable_libudev='no'\nenable_libxml2='no'\nenable_visibility='no'\nenable_nvml='no'\nenable_opencl='no'\nenable_gl='no'\nenable_cairo='no'\n. hwloc/VERSION\nexport libhwloc_so_version\nAC_SUBST(libhwloc_so_version)\n\necho \"Configuring hwloc:\"\nAC_CONFIG_AUX_DIR(hwloc/config)\nAC_CANONICAL_TARGET\nAC_USE_SYSTEM_EXTENSIONS\nLT_INIT\n\nAM_INIT_AUTOMAKE([no-define])\n\nAC_CONFIG_MACRO_DIR(hwloc/config)\nHWLOC_SET_SYMBOL_PREFIX([cmi_])\nHWLOC_SETUP_CORE([hwloc], [happy=yes], [happy=no])\nHWLOC_DO_AM_CONDITIONALS\nadd_flag 'CMK_HWLOC_LIBS=\"-lhwloc_embedded '\"$HWLOC_EMBEDDED_LIBS\"'\"' \"hwloc\"\n\nAC_OUTPUT\n",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/src/libs/ck-libs/ampi/ampi_funcptr_pipglobals.C": "\n#include \"ampi_funcptr_loader.h\"\n\n#include <string>\n#include <atomic>\n\nstatic std::atomic<size_t> rank_count{};\n\nint main(int argc, char ** argv)\n{\n  SharedObject myexe;\n\n  // open the user binary for this rank in a unique namespace\n  {\n    static const char FUNCPTR_SHIM_SUFFIX[] = \".user\";\n\n    std::string binary_path{ampi_binary_path};\n    binary_path += FUNCPTR_SHIM_SUFFIX;\n\n    const Lmid_t lmid = rank_count++ == 0 ? LM_ID_BASE : LM_ID_NEWLM;\n    myexe = dlmopen(lmid, binary_path.c_str(), RTLD_NOW|RTLD_LOCAL);\n  }\n\n  if (myexe == nullptr)\n  {\n    CkError(\"dlmopen error: %s\\n\", dlerror());\n    CkAbort(\"Could not open pipglobals user program!\");\n  }\n\n  return AMPI_FuncPtr_Loader(myexe, argc, argv);\n}\n",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/ampi/manual.rst": "===================\nAdaptive MPI (AMPI)\n===================\n\n.. contents::\n   :depth: 3\n\n\nIntroduction\n============\n\nThis manual describes Adaptive MPI (AMPI), which is an implementation of\nthe MPI standard [1]_ on top of Charm++. AMPI acts as a regular MPI\nimplementation (akin to MPICH, OpenMPI, MVAPICH, etc.) with several\nbuilt-in extensions that allow MPI developers to take advantage of\nCharm++\u2019s dynamic runtime system, which provides support for process\nvirtualization, overlap of communication and computation, load\nbalancing, and fault tolerance with zero to minimal changes to existing\nMPI codes.\n\nIn this manual, we first describe the philosophy behind Adaptive MPI,\nthen give a brief introduction to Charm++ and rationale for AMPI. We\nthen describe AMPI in detail. Finally we summarize the changes required\nfor existing MPI codes to run with AMPI. Appendices contain the details\nof installing AMPI, and building and running AMPI programs.\n\nOverview\n--------\n\nDeveloping parallel Computational Science and Engineering (CSE)\napplications is a complex task. One has to implement the right physics,\ndevelop or choose and code appropriate numerical methods, decide and\nimplement the proper input and output data formats, perform\nvisualizations, and be concerned with correctness and efficiency of the\nprograms. It becomes even more complex for multi-physics coupled\nsimulations, many of which are dynamic and adaptively refined so that\nload imbalance becomes a major challenge. In addition to imbalance\ncaused by dynamic program behavior, hardware factors such as latencies,\nvariability, and failures must be tolerated by applications. Our\nphilosophy is to lessen the burden of application developers by\nproviding advanced programming paradigms and versatile runtime systems\nthat can handle many common programming and performance concerns\nautomatically and let application programmers focus on the actual\napplication content.\n\nMany of these concerns can be addressed using the processor\nvirtualization and over-decomposition philosophy of Charm++. Thus, the\ndeveloper only sees virtual processors and lets the runtime system deal\nwith underlying physical processors. This is implemented in AMPI by\nmapping MPI ranks to Charm++ user-level threads as illustrated in Figure\n:numref:`fig_virt`. As an immediate and simple benefit, the\nprogrammer can use as many virtual processors (\"MPI ranks\") as the\nproblem can be easily decomposed to. For example, suppose the problem\ndomain has :math:`n*2^n` parts that can be easily distributed but\nprogramming for general number of MPI processes is burdensome, then the\ndeveloper can have :math:`n*2^n` virtual processors on any number of\nphysical ones using AMPI.\n\n.. _fig_virt:\n.. figure:: figs/virtualization.png\n   :width: 4.6in\n\n   MPI ranks are implemented as user-level threads in AMPI rather than\n   Operating System processes.\n\n\n\nAMPI\u2019s execution model consists of multiple user-level threads per\nProcessing Element (PE). The Charm++ scheduler coordinates execution of\nthese user-level threads (also called Virtual Processors or VPs) and\ncontrols execution. These VPs can also migrate between PEs for the\npurpose of load balancing or other reasons. The number of VPs per PE\nspecifies the virtualization ratio (degree of over-decomposition). For\nexample, in Figure :numref:`fig_virt` the virtualization ratio\nis :math:`3.5` (there are four VPs on PE 0 and three VPs on PE 1).\nFigure :numref:`fig_prac` shows how the problem domain can be\nover-decomposed in AMPI\u2019s VPs as opposed to other MPI implementations.\n\n.. _fig_prac:\n.. figure:: figs/prac.png\n   :width: 4.6in\n\n   The problem domain is over-decomposed to more VPs than PEs.\n\n\n\nAnother benefit of virtualization is communication and computation\noverlap, which is automatically realized in AMPI without programming\neffort. Techniques such as software pipelining require significant\nprogramming effort to achieve this goal and improve performance.\nHowever, one can use AMPI to have more virtual processors than physical\nprocessors to overlap communication and computation. Each time a VP is\nblocked for communication, the Charm++ scheduler picks the next VP among\nthose that are ready to execute. In this manner, while some of the VPs\nof a physical processor are waiting for a message to arrive, others can\ncontinue their execution. Thus, performance improves without any changes\nto the application source code.\n\nAnother potential benefit is that of better cache utilization. With\nover-decomposition, a smaller subdomain is accessed by a VP repeatedly\nin different function calls before getting blocked by communication and\nswitching to another VP. That smaller subdomain may fit into cache if\nover-decomposition is enough. This concept is illustrated in Figure\n:numref:`fig_virt` where each AMPI rank\u2019s subdomain is smaller\nthan the corresponding MPI subdomain and so may fit into cache memory.\nThus, there is a potential performance improvement without changing the\nsource code.\n\nOne important concern is that of load imbalance. New generation parallel\napplications are dynamically varying, meaning that processors\u2019 load is\nshifting during execution. In a dynamic simulation application such as\nrocket simulation, burning solid fuel, sub-scaling for a certain part of\nthe mesh, crack propagation, particle flows all contribute to load\nimbalance. A centralized load balancing strategy built into an\napplication is impractical since each individual module is developed\nmostly independently by various developers. In addition, embedding a\nload balancing strategy in the code complicates it greatly, and\nprogramming effort increases significantly. The runtime system is\nuniquely positioned to deal with load imbalance. Figure\n:numref:`fig_migrate` shows the runtime system migrating a VP\nafter detecting load imbalance. This domain may correspond to a weather\nforecast model where there is a storm cell in the top-left quadrant,\nwhich requires more computation to simulate. AMPI will then migrate VP 1\nto balance the division of work across processors and improve\nperformance. Note that incorporating this sort of load balancing inside\nthe application code may take a lot of effort and complicate the code.\n\n.. _fig_migrate:\n.. figure:: figs/migrate.png\n   :width: 4.6in\n\n   AMPI can migrate VPs across processes for load balancing.\n\n\n\nThere are many different load balancing strategies built into Charm++\nthat can be selected by an AMPI application developer. Among those, some\nmay fit better for a particular application depending on its\ncharacteristics. Moreover, one can write a new load balancer, best\nsuited for an application, by the simple API provided inside Charm++\ninfrastructure. Our approach is based on actual measurement of load\ninformation at runtime, and on migrating computations from heavily\nloaded to lightly loaded processors.\n\nFor this approach to be effective, we need the computation to be split\ninto pieces many more in number than available processors. This allows\nus to flexibly map and re-map these computational pieces to available\nprocessors. This approach is usually called \"multi-domain\ndecomposition\".\n\nCharm++, which we use as a runtime system layer for the work described\nhere, simplifies our approach. It embeds an elaborate performance\ntracing mechanism, a suite of plug-in load balancing strategies,\ninfrastructure for defining and migrating computational load, and is\ninteroperable with other programming paradigms.\n\nCharm++\n=======\n\nCharm++ is an object-oriented parallel programming library for C. It\ndiffers from traditional message passing programming libraries (such as\nMPI) in that Charm++ is \"message-driven\". Message-driven parallel\nprograms do not block the processor waiting for a message to be\nreceived. Instead, each message carries with itself a computation that\nthe processor performs on arrival of that message. The underlying\nruntime system of Charm++ is called Converse, which implements a\n\"scheduler\" that chooses which message to schedule next\n(message-scheduling in Charm++ involves locating the object for which\nthe message is intended, and executing the computation specified in the\nincoming message on that object). A parallel object in Charm++ is a C\nobject on which a certain computations can be asked to be performed from\nremote processors.\n\nCharm++ programs exhibit latency tolerance since the scheduler always\npicks up the next available message rather than waiting for a particular\nmessage to arrive. They also tend to be modular, because of their\nobject-based nature. Most importantly, Charm++ programs can be\n*dynamically load balanced*, because the messages are directed at\nobjects and not at processors; thus allowing the runtime system to\nmigrate the objects from heavily loaded processors to lightly loaded\nprocessors.\n\nSince many CSE applications are originally written using MPI, one would\nhave to rewrite existing code if they were to be converted to Charm++ to\ntake advantage of dynamic load balancing and other Charm++ features.\nThis is indeed impractical. However, Converse - the runtime system of\nCharm++ - supports interoperability between different parallel\nprogramming paradigms such as parallel objects and threads. Using this\nfeature, we developed AMPI, which is described in more detail in the\nnext section.\n\nAMPI\n====\n\nAMPI utilizes the dynamic load balancing and other capabilities of\nCharm++ by associating a \"user-level\" thread with each Charm++\nmigratable object. User\u2019s code runs inside this thread, so that it can\nissue blocking receive calls similar to MPI, and still present the\nunderlying scheduler an opportunity to schedule other computations on\nthe same processor. The runtime system keeps track of the computational\nloads of each thread as well as the communication graph between AMPI\nthreads, and can migrate these threads in order to balance the overall\nload while simultaneously minimizing communication overhead.\n\nAMPI Compliance to MPI Standards\n--------------------------------\n\nCurrently AMPI supports the MPI-2.2 standard, with preliminary support\nfor most MPI-3.1 features and a collection of extensions explained in\ndetail in this manual. One-sided communication calls in MPI-2 and MPI-3\nare implemented, but they do not yet take advantage of RMA features.\nNon-blocking collectives have been defined in AMPI since before\nMPI-3.0\u2019s adoption of them. Also ROMIO [2]_ has been integrated into\nAMPI to support parallel I/O features.\n\nAMPI Extensions to MPI Standards\n--------------------------------\n\nThe following are AMPI extensions to the MPI standard, which will be\nexplained in detail in this manual. All AMPI extensions to the MPI\nstandard are prefixed with ``AMPI_`` rather than ``MPI_``. All\nextensions are available in C, C++, and Fortran, with the exception of\n``AMPI_Command_argument_count`` and ``AMPI_Get_command_argument`` which\nare only available in Fortran.\n\n.. code-block:: none\n\n   AMPI_Migrate          AMPI_Register_pup            AMPI_Get_pup_data\n   AMPI_Migrate_to_pe    AMPI_Set_migratable          AMPI_Evacuate\n   AMPI_Load_set_value   AMPI_Load_start_measure      AMPI_Load_stop_measure\n   AMPI_Iget             AMPI_Iget_wait               AMPI_Iget_data\n   AMPI_Iget_free        AMPI_Type_is_contiguous      AMPI_Register_main\n   AMPI_Yield            AMPI_Suspend                 AMPI_Resume\n   AMPI_Alltoall_medium  AMPI_Alltoall_long\n   AMPI_Register_just_migrated         AMPI_Register_about_to_migrate\n   AMPI_Command_argument_count         AMPI_Get_command_argument\n\nAMPI provides a set of built-in attributes on all communicators and\nwindows to find the number of the worker thread, process, or host that a\nrank is currently running on, as well as the total number of worker\nthreads, processes, and hosts in the job. We define a worker thread to\nbe a thread on which one of more AMPI ranks are scheduled. We define a\nprocess here as an operating system process, which may contain one or\nmore worker threads. The built-in attributes are ``AMPI_MY_WTH``,\n``AMPI_MY_PROCESS``, ``AMPI_NUM_WTHS``, and ``AMPI_NUM_PROCESSES``.\nThese attributes are accessible from any rank by calling\n``MPI_Comm_get_attr``, such as:\n\n.. code-block:: fortran\n\n   ! Fortran:\n   integer :: my_wth, flag, ierr\n   call MPI_Comm_get_attr(MPI_COMM_WORLD, AMPI_MY_WTH, my_wth, flag, ierr)\n\n\n.. code-block:: c++\n\n   // C/C++:\n   int my_wth, flag;\n   MPI_Comm_get_attr(MPI_COMM_WORLD, AMPI_MY_WTH, &my_wth, &flag);\n\nAMPI also provides extra communicator types that users can pass to\n``MPI_Comm_split_type``: ``AMPI_COMM_TYPE_HOST`` for splitting a\ncommunicator into disjoint sets of ranks that share the same physical\nhost, ``AMPI_COMM_TYPE_PROCESS`` for splitting a communicator into\ndisjoint sets of ranks that share the same operating system process, and\n``AMPI_COMM_TYPE_WTH``, for splitting a communicator into disjoint sets\nof ranks that share the same worker thread.\n\nFor parsing Fortran command line arguments, AMPI Fortran programs should\nuse our extension APIs, which are similar to Fortran 2003\u2019s standard\nAPIs. For example:\n\n.. code-block:: fortran\n\n   integer :: i, argc, ierr\n   integer, parameter :: arg_len = 128\n   character(len=arg_len), dimension(:), allocatable :: raw_arguments\n\n   call AMPI_Command_argument_count(argc)\n   allocate(raw_arguments(argc))\n   do i = 1, size(raw_arguments)\n       call AMPI_Get_command_argument(i, raw_arguments(i), arg_len, ierr)\n   end do\n\nName for Main Program\n---------------------\n\nTo convert an existing program to use AMPI, the main function or program\nmay need to be renamed. The changes should be made as follows:\n\nFortran\n~~~~~~~\n\nYou must declare the main program as a subroutine called \"MPI_MAIN\". Do\nnot declare the main subroutine as a *program* because it will never be\ncalled by the AMPI runtime.\n\n.. code-block:: fortran\n\n   program pgm -> subroutine MPI_Main\n       ...                       ...\n   end program -> end subroutine\n\nC or C++\n~~~~~~~~\n\nThe main function can be left as is, if ``mpi.h`` is included before the\nmain function. This header file has a preprocessor macro that renames\nmain, and the renamed version is called by the AMPI runtime by each\nthread.\n\nGlobal Variable Privatization\n-----------------------------\n\nFor the before-mentioned benefits to be effective, one needs to map\nmultiple user-level threads onto each processor. Traditional MPI\nprograms assume that the entire processor is allocated to themselves,\nand that only one thread of control exists within the process\u2019s address\nspace. So, they may safely use global and static variables in the\nprogram. However, global and static variables are problematic for\nmulti-threaded environments such as AMPI or OpenMP. This is because\nthere is a single instance of those variables so they will be shared\namong different threads in the single address space, so if programmers\nare not careful a wrong result may be produced by the program. Figure\n:numref:`fig_global` shows an example of a multi-threaded\napplication with two threads in a single process. :math:`var` is a\nglobal or static variable in this example. Thread 1 assigns a value to\nit, then it gets blocked for communication and another thread can\ncontinue. Thereby, thread 2 is scheduled next and accesses :math:`var`\nwhich is wrong. The semantics of this program needs separate instances\nof :math:`var` for each of the threads. That is where the need arises to\nmake some transformations to the original MPI program in order to run\ncorrectly with AMPI. Note, this is the only change necessary to run an\nMPI program with AMPI, that the program be thread-safe and have no\nglobal or static variables whose values differ across different MPI\nranks. Also note that global variables that are constant or are only\nwritten to once to the same value across all ranks during initialization\nare already thread-safe.\n\n.. _fig_global:\n.. figure:: figs/global.png\n   :width: 4.6in\n\n   Mutable global or static variables are an issue for AMPI\n\n\n\nThe basic transformation needed to port the MPI program to AMPI is\nprivatization of global variables. With the MPI process model, each MPI\nnode can keep a copy of its own \"permanent variables\" - variables that\nare accessible from more than one subroutines without passing them as\narguments. Module variables, \"saved\" subroutine local variables, and\ncommon blocks in Fortran90 belong to this category. If such a program is\nexecuted without privatization on AMPI, all the AMPI threads that reside\nin the same process will access the same copy of such variables, which\nis clearly not the desired semantics. To ensure correct execution of the\noriginal source program, it is necessary to make such variables\n\"private\" to individual threads. We provide three choices with varying\ndegrees of developer effort required and varying degrees of portability:\nmanual encapsulation of global state, a thread-local storage based\nautomated mechanism, and global offset table based automated mechanism.\n\nAutomatic Thread-Local Storage Swapping\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThread Local Store (TLS) was originally employed in kernel threads to\nlocalize variables to threads and provide thread safety. It can be used\nby annotating global/static variable declarations in C with\n*thread_local*, in C with *__thread* or C11 with *thread_local* or\n*_Thread_local*, and in Fortran with OpenMP\u2019s *threadprivate*\nattribute. OpenMP is required for using tlsglobals in Fortran code since\nFortran has no other method of using TLS. The *__thread* keyword is not\nan official extension of the C language, though compiler writers are\nencouraged to implement this feature.\n\nIt handles both global and static variables and has no context-switching\noverhead. AMPI provides runtime support for privatizing thread-local\nvariables to user-level threads by changing the TLS segment register\nwhen context switching between user-level threads. The runtime overhead\nis that of changing a single pointer per user-level thread context\nswitch. Currently, Charm++ supports it for x86/x86_64 platforms when\nusing GNU compilers.\n\n.. code-block:: c++\n\n   // C/C++ example:\n   int myrank;\n   double xyz[100];\n\n.. code-block:: fortran\n\n   ! Fortran example:\n   integer :: myrank\n   real*8, dimension(100) :: xyz\n\nFor the example above, the following changes to the code handle the\nglobal variables:\n\n.. code-block:: c++\n\n   // C++ example:\n   thread_local int myrank;\n   thread_local double xyz[100];\n\n   // C example:\n   __thread int myrank;\n   __thread double xyz[100];\n\n.. code-block:: fortran\n\n   ! Fortran example:\n   integer :: myrank\n   real*8, dimension(100) :: xyz\n   !$omp threadprivate(myrank)\n   !$omp threadprivate(xyz)\n\nThe runtime system also should know that TLS-Globals is used at both\ncompile and link time:\n\n.. code-block:: bash\n\n   $ ampicxx -o example example.C -tlsglobals\n\nAutomatic Process-in-Process Runtime Linking Privatization\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nProcess-in-Process (PiP) [PiP2018]_ Globals allows fully automatic\nprivatization of global variables on GNU/Linux systems without\nmodification of user code. All languages (C, C++, Fortran, etc.) are\nsupported. This method currently lacks support for checkpointing and\nmigration, which are necessary for load balancing and fault tolerance.\nAdditionally, overdecomposition is limited to approximately 12 virtual\nranks per logical node, though this can be resolved by building a\npatched version of glibc.\n\nThis method works by combining a specific method of building binaries\nwith a GNU extension to the dynamic linker. First, AMPI's toolchain\nwrapper compiles your user program as a Position Independent Executable\n(PIE) and links it against a special shim of function pointers instead\nof the normal AMPI runtime. It then builds a small loader utility that\nlinks directly against AMPI. For each rank, this loader calls the\nglibc-specific function ``dlmopen`` on the PIE binary with a unique\nnamespace index. The loader uses ``dlsym`` to populate the PIE binary's\nfunction pointers and then it calls the entry point. This ``dlmopen``\nand ``dlsym`` process repeats for each rank. As soon as execution jumps\ninto the PIE binary, any global variables referenced within will appear\nprivatized. This is because PIE binaries locate the global data segment\nimmediately after the code segment so that PIE global variables are\naccessed relative to the instruction pointer, and because ``dlmopen``\ncreates a separate copy of these segments in memory for each unique\nnamespace index.\n\nOptionally, the first step in using PiP-Globals is to build PiP-glibc to\novercome the limitation on rank count per process. Use the instructions\nat https://github.com/RIKEN-SysSoft/PiP/blob/pip-1/INSTALL to download\nan installable PiP package or build PiP-glibc from source by following\nthe ``Patched GLIBC`` section. AMPI may be able to automatically detect\nPiP's location if installed as a package, but otherwise set and export\nthe environment variable ``PIP_GLIBC_INSTALL_DIR`` to the value of\n``<GLIBC_INSTALL_DIR>`` as used in the above instructions. For example:\n\n.. code-block:: bash\n\n   $ export PIP_GLIBC_INSTALL_DIR=~/pip\n\nTo use PiP-Globals in your AMPI program (with or without PiP-glibc),\ncompile and link with the ``-pipglobals`` parameter:\n\n.. code-block:: bash\n\n   $ ampicxx -o example.o -c example.cpp -pipglobals\n   $ ampicxx -o example example.o -pipglobals\n\nNo further effort is needed. Global variables in ``example.cpp`` will be\nautomatically privatized when the program is run. Any libraries and\nshared objects compiled as PIE will also be privatized. However, if\nthese objects call MPI functions, it will be necessary to build them\nwith the AMPI toolchain wrappers, ``-pipglobals``, and potentially also\nthe ``-standalone`` parameter in the case of shared objects. It is\nrecommended to do this in any case so that AMPI can ensure everything is\nbuilt as PIE.\n\nPotential future support for checkpointing and migration will require\nmodification of the ``ld-linux.so`` runtime loader to intercept mmap\nallocations of the previously mentioned segments and redirect them\nthrough Isomalloc. The present lack of support for these features mean\nPiP-Globals is best suited for testing AMPI during exploratory phases\nof development, and for production jobs not requiring load balancing or\nfault tolerance.\n\nAutomatic Filesystem-Based Runtime Linking Privatization\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nFilesystem Globals (FS-Globals) was discovered during the development of\nPiP-Globals and the two are highly similar. Like PiP-Globals, it\nrequires no modification of user code and works with any language.\nIt also currently lacks support for checkpointing and migration,\npreventing use of load balancing and fault tolerance. Unlike PiP-Globals,\nit is portable beyond GNU/Linux and has no limits to overdecomposition\nbeyond available disk space.\n\nFS-Globals works in the same way as PiP-Globals except that instead of\nspecifying namespaces using ``dlmopen``, which is a GNU/Linux-specific\nfeature, this method creates copies of the user's PIE binary on the\nfilesystem for each rank and calls the POSIX-standard ``dlopen``.\n\nTo use FS-Globals, compile and link with the ``-fsglobals`` parameter:\n\n.. code-block:: bash\n\n   $ ampicxx -o example.o -c example.cpp -fsglobals\n   $ ampicxx -o example example.o -fsglobals\n\nNo additional steps are required. Global variables in ``example.cpp``\nwill be automatically privatized when the program is run. Variables in\nstatically linked libraries will also be privatized if compiled as PIE.\nIt is recommended to achieve this by building with the AMPI toolchain\nwrappers and ``-fsglobals``, and this is necessary if the libraries call\nMPI functions. Shared objects are currently not supported by FS-Globals\ndue to the extra overhead of iterating through all dependencies and\ncopying each one per rank while avoiding system components, plus the\ncomplexity of ensuring each rank's program binary sees the proper set of\nobjects.\n\nThis method's use of the filesystem is a drawback in that it is slow\nduring startup and can be considered wasteful. Additionally, support for\nload balancing and fault tolerance would require further development in\nthe future, using the same infrastructure as what PiP-Globals would\nrequire. For these reasons FS-Globals is best suited for the R&D phase\nof AMPI program development and for small jobs, and it may be less\nsuitable for large production environments.\n\nAutomatic Global Offset Table Swapping\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThanks to the ELF Object Format, we have successfully automated the\nprocedure of switching the set of user global variables when switching\nthread contexts. Executable and Linkable Format (ELF) is a common\nstandard file format for Object Files in Unix-like operating systems.\nELF maintains a Global Offset Table (GOT) for globals so it is possible\nto switch GOT contents at thread context-switch by the runtime system.\n\nThe only thing that the user needs to do is pass the flag\n``-swapglobals`` at both compile and link time (e.g. \"ampicc -o prog\nprog.c -swapglobals\"). This method does not require any changes to the\nsource code and works with any language (C, C++, Fortran, etc). However,\nit does not handle static variables, has a context switching overhead\nthat grows with the number of global variables, and is incompatible with\nSMP builds of AMPI, where multiple virtual ranks can execute\nsimultaneously on different scheduler threads within an OS process.\nCurrently, this feature only works on x86 and x86_64 platforms that\nfully support ELF, and it requires ld version 2.23 or older, or else a\npatched version of ld 2.24+ that we provide here:\nhttps://charm.cs.illinois.edu/gerrit/gitweb?p=libbfd-patches.git;a=tree;f=swapglobals\n\nManual Change\n~~~~~~~~~~~~~\n\nWe have employed a strategy of argument passing to do this privatization\ntransformation. That is, the global variables are bunched together in a\nsingle user-defined type, which is allocated by each thread dynamically\nor on the stack. Then a pointer to this type is passed from subroutine\nto subroutine as an argument. Since the subroutine arguments are passed\non the stack, which is not shared across all threads, each subroutine\nwhen executing within a thread operates on a private copy of the global\nvariables.\n\nThis scheme is demonstrated in the following examples. The original\nFortran90 code contains a module ``shareddata``. This module is used in\nthe ``MPI_MAIN`` subroutine and a subroutine ``subA``. Note that\n``PROGRAM PGM`` was renamed to ``SUBROUTINE MPI_MAIN`` and ``END PROGRAM``\nwas renamed to ``END SUBROUTINE``.\n\n.. code-block:: fortran\n\n   !FORTRAN EXAMPLE\n   MODULE shareddata\n     INTEGER :: myrank\n     DOUBLE PRECISION :: xyz(100)\n   END MODULE\n\n   SUBROUTINE MPI_MAIN                               ! Previously PROGRAM PGM\n     USE shareddata\n     include 'mpif.h'\n     INTEGER :: i, ierr\n     CALL MPI_Init(ierr)\n     CALL MPI_Comm_rank(MPI_COMM_WORLD, myrank, ierr)\n     DO i = 1, 100\n       xyz(i) =  i + myrank\n     END DO\n     CALL subA\n     CALL MPI_Finalize(ierr)\n   END SUBROUTINE                                    ! Previously END PROGRAM\n\n   SUBROUTINE subA\n     USE shareddata\n     INTEGER :: i\n     DO i = 1, 100\n       xyz(i) = xyz(i) + 1.0\n     END DO\n   END SUBROUTINE\n\n.. code-block:: c++\n\n   //C Example\n   #include <mpi.h>\n\n   int myrank;\n   double xyz[100];\n\n   void subA();\n   int main(int argc, char** argv){\n     int i;\n     MPI_Init(&argc, &argv);\n     MPI_Comm_rank(MPI_COMM_WORLD, &myrank);\n     for(i=0;i<100;i++)\n       xyz[i] = i + myrank;\n     subA();\n     MPI_Finalize();\n   }\n\n   void subA(){\n     int i;\n     for(i=0;i<100;i++)\n       xyz[i] = xyz[i] + 1.0;\n   }\n\nAMPI executes the main subroutine inside a user-level thread as a\nsubroutine.\n\nNow we transform this program using the argument passing strategy. We\nfirst group the shared data into a user-defined type.\n\n.. code-block:: fortran\n\n   !FORTRAN EXAMPLE\n   MODULE shareddata\n     TYPE chunk ! modified\n       INTEGER :: myrank\n       DOUBLE PRECISION :: xyz(100)\n     END TYPE ! modified\n   END MODULE\n\n.. code-block:: c++\n\n   //C Example\n   struct shareddata{\n     int myrank;\n     double xyz[100];\n   };\n\nNow we modify the main subroutine to dynamically allocate this data and\nchange the references to them. Subroutine ``subA`` is then modified to\ntake this data as argument.\n\n.. code-block:: fortran\n\n   !FORTRAN EXAMPLE\n   SUBROUTINE MPI_Main\n     USE shareddata\n     USE AMPI\n     INTEGER :: i, ierr\n     TYPE(chunk), pointer :: c ! modified\n     CALL MPI_Init(ierr)\n     ALLOCATE(c) ! modified\n     CALL MPI_Comm_rank(MPI_COMM_WORLD, c%myrank, ierr)\n     DO i = 1, 100\n       c%xyz(i) =  i + c%myrank ! modified\n     END DO\n     CALL subA(c)\n     CALL MPI_Finalize(ierr)\n   END SUBROUTINE\n\n   SUBROUTINE subA(c)\n     USE shareddata\n     TYPE(chunk) :: c ! modified\n     INTEGER :: i\n     DO i = 1, 100\n       c%xyz(i) = c%xyz(i) + 1.0 ! modified\n     END DO\n   END SUBROUTINE\n\n.. code-block:: c++\n\n   //C Example\n   void MPI_Main{\n     int i,ierr;\n     struct shareddata *c;\n     ierr = MPI_Init();\n     c = (struct shareddata*)malloc(sizeof(struct shareddata));\n     ierr = MPI_Comm_rank(MPI_COMM_WORLD, c.myrank);\n     for(i=0;i<100;i++)\n       c.xyz[i] = i + c.myrank;\n     subA(c);\n     ierr = MPI_Finalize();\n   }\n\n   void subA(struct shareddata *c){\n     int i;\n     for(i=0;i<100;i++)\n       c.xyz[i] = c.xyz[i] + 1.0;\n   }\n\nWith these changes, the above program can be made thread-safe. Note that\nit is not really necessary to dynamically allocate ``chunk``. One could\nhave declared it as a local variable in subroutine ``MPI_Main``. (Or for\na small example such as this, one could have just removed the\n``shareddata`` module, and instead declared both variables ``xyz`` and\n``myrank`` as local variables). This is indeed a good idea if shared\ndata are small in size. For large shared data, it would be better to do\nheap allocation because in AMPI, the stack sizes are fixed at the\nbeginning (and can be specified from the command line) and stacks do not\ngrow dynamically.\n\nSource-to-source Transformation\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nAnother approach is to do the changes described in the previous scheme\nautomatically. It means that we can use a tool to transform the source\ncode to move global or static variables in an object and pass them\naround. This approach is portable across systems and compilers and may\nalso improve locality and hence cache utilization. It also does not have\nthe context-switch overhead of swapping globals. We have multiple tools\nfor automating these transformations for different languages. Currently,\nthere is a tool called *Photran*\\  [3]_ for refactoring Fortran codes\nthat can do this transformation. It is Eclipse-based and works by\nconstructing Abstract Syntax Trees (ASTs) of the program. We also have a\ntool built on top of the *ROSE compiler*\\  [4]_ that works for C/C++ and\nFortran programs that is available upon request. It emits patches for\nall files containing global variables which can then be applied to the\nsource code.\n\nTable :numref:`tab:portability` shows portability of\ndifferent schemes.\n\n.. _tab:portability:\n.. table:: Portability of current implementations of three privatization schemes. \"Yes\" means we have implemented this technique. \"Maybe\" indicates there are no theoretical problems, but no implementation exists. \"No\" indicates the technique is impossible on this platform.\n\n   ==================== === ====== ====== ==== ======= ===== =====\n   Privatization Scheme x86 x86_64 Mac OS BG/Q Windows PPC   ARM7\n   ==================== === ====== ====== ==== ======= ===== =====\n   Transformation       Yes Yes    Yes    Yes  Yes     Yes   Yes\n   GOT-Globals          Yes Yes    No     No   No      Yes   Yes\n   TLS-Globals          Yes Yes    Yes    No   Maybe   Maybe Maybe\n   PiP-Globals          Yes Yes    No     No   No      Yes   Yes\n   FS-Globals           Yes Yes    Yes    No   Maybe   Yes   Yes\n   ==================== === ====== ====== ==== ======= ===== =====\n\nExtensions for Migrations\n-------------------------\n\nAMPI provides fully automated support for migrating MPI ranks between\nnodes of a system without any application-specific code at all. We do so\nusing a memory allocator, Isomalloc, that allocates memory per\nuser-level thread to globally unique virtual memory addresses. This\nmeans that every worker thread in the system reserves slices of virtual\nmemory for all user-level threads, allowing transparent migration of\nstacks and pointers into memory (Isomalloc requires 64-bit virtual\nmemory addresses and support from the operating system for mapping\nmemory to arbitrary virtual addresses). Applications only need to link\nwith Isomalloc to enable automatic migratability, using *-memory\nisomalloc*.\n\nFor systems that do not support Isomalloc and for users that wish to\nhave more fine-grain control over which application data structures will\nbe copied at migration time, we have added a few calls to AMPI. These\ninclude the ability to register thread-specific data with the run-time\nsystem, to pack and unpack all of the thread\u2019s data, and to express\nwillingness to migrate.\n\nRegistering User Data\n~~~~~~~~~~~~~~~~~~~~~\n\nWhen the AMPI runtime system decides that load imbalance exists within\nthe application, it will invoke one of its internal load balancing\nstrategies, which determines the new mapping of AMPI ranks so as to\nbalance the load. Then the AMPI runtime packs up the rank\u2019s state and\nmoves it to its new home processor. AMPI packs up any internal data in\nuse by the rank, including the thread\u2019s stack in use. This means that\nthe local variables declared in subroutines in a rank, which are created\non stack, are automatically packed up by the AMPI runtime system.\nHowever, it has no way of knowing what other data are in use by the\nrank. Thus upon starting execution, a rank needs to notify the system\nabout the data that it is going to use (apart from local variables).\nEven with the data registration, AMPI cannot determine what size the\ndata is, or whether the registered data contains pointers to other\nplaces in memory. For this purpose, a packing subroutine also needs to\nbe provided to the AMPI runtime system along with registered data. (See\nnext section for writing packing subroutines.) The call provided by AMPI\nfor doing this is ``AMPI_Register_pup``. This function takes three\narguments: a data item to be transported along with the rank, the pack\nsubroutine, and a pointer to an integer which denotes the registration\nidentifier. In C/C++ programs, it may be necessary to use this integer\nvalue after migration completes and control returns to the rank with the\nfunction ``AMPI_Get_pup_data``.\n\nMigration\n~~~~~~~~~\n\nThe AMPI runtime system could detect load imbalance by itself and invoke\nthe load balancing strategy. However, since the application code is\ngoing to pack/unpack the rank\u2019s data, writing the pack subroutine will\nbe complicated if migrations occur at a stage unknown to the\napplication. For example, if the system decides to migrate a rank while\nit is in initialization stage (say, reading input files), application\ncode will have to keep track of how much data it has read, what files\nare open etc. Typically, since initialization occurs only once in the\nbeginning, load imbalance at that stage would not matter much.\nTherefore, we want the demand to perform load balance check to be\ninitiated by the application.\n\nAMPI provides a subroutine ``AMPI_Migrate(MPI_Info hints);`` for this\npurpose. Each rank periodically calls ``AMPI_Migrate``. Typical CSE\napplications are iterative and perform multiple time-steps. One should\ncall ``AMPI_Migrate`` in each rank at the end of some fixed number of\ntimesteps. The frequency of ``AMPI_Migrate`` should be determined by a\ntradeoff between conflicting factors such as the load balancing\noverhead, and performance degradation caused by load imbalance. In some\nother applications, where application suspects that load imbalance may\nhave occurred, as in the case of adaptive mesh refinement; it would be\nmore effective if it performs a couple of timesteps before telling the\nsystem to re-map ranks. This will give the AMPI runtime system some time\nto collect the new load and communication statistics upon which it bases\nits migration decisions. Note that ``AMPI_Migrate`` does NOT tell the\nsystem to migrate the rank, but merely tells the system to check the\nload balance after all the ranks call ``AMPI_Migrate``. To migrate the\nrank or not is decided only by the system\u2019s load balancing strategy.\n\nEssentially, a call to ``AMPI_Migrate`` signifies to the runtime system\nthat the application has reached a point at which it is safe to\nserialize the local state. Knowing this, the runtime system can act in\nseveral ways.\n\nThe MPI_Info object taken as a parameter by ``AMPI_Migrate`` gives users\na way to influence the runtime system\u2019s decision-making and behavior.\nAMPI provides two built-in MPI_Info objects for this, called\n``AMPI_INFO_LB_SYNC`` and ``AMPI_INFO_LB_ASYNC``. Synchronous load\nbalancing assumes that the application is already at a synchronization\npoint. Asynchronous load balancing does not assume this.\n\nCalling ``AMPI_Migrate`` on a rank with pending send requests (i.e. from\nMPI_Isend) is currently not supported, therefore users should always\nwait on any outstanding send requests before calling ``AMPI_Migrate``.\n\n.. code-block:: c++\n\n   // Main time-stepping loop\n   for (int iter=0; iter < max_iters; iter++) {\n\n     // Time step work ...\n\n     if (iter % lb_freq == 0)\n       AMPI_Migrate(AMPI_INFO_LB_SYNC);\n   }\n\nNote that migrating ranks around the cores and nodes of a system can\nchange which ranks share physical resources, such as memory. A\nconsequence of this is that communicators created via\n``MPI_Comm_split_type`` are invalidated by calls to ``AMPI_Migrate``\nthat result in migration which breaks the semantics of that communicator\ntype. The only valid routine to call on such communicators is\n``MPI_Comm_free``.\n\nWe also provide callbacks that user code can register with the runtime\nsystem to be invoked just before and right after migration:\n``AMPI_Register_about_to_migrate`` and ``AMPI_Register_just_migrated``\nrespectively. Note that the callbacks are only invoked on those ranks\nthat are about to actually migrate or have just actually migrated.\n\nAMPI provide routines for starting and stopping load measurements, and\nfor users to explicitly set the load value of a rank using the\nfollowing: ``AMPI_Load_start_measure``, ``AMPI_Load_stop_measure``,\n``AMPI_Load_reset_measure``, and ``AMPI_Load_set_value``. And since AMPI\nbuilds on top of Charm++, users can experiment with the suite of load\nbalancing strategies included with Charm++, as well as write their own\nstrategies based on user-level information and heuristics.\n\nPacking/Unpacking Thread Data\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nOnce the AMPI runtime system decides which ranks to send to which\nprocessors, it calls the specified pack subroutine for that rank, with\nthe rank-specific data that was registered with the system using\n``AMPI_Register_pup``. If an AMPI application uses Isomalloc, then the\nsystem will define the Pack/Unpack routines for the user. This section\nexplains how a subroutine should be written for performing explicit\npack/unpack.\n\nThere are three steps for transporting the rank\u2019s data to another\nprocessor. First, the system calls a subroutine to get the size of the\nbuffer required to pack the rank\u2019s data. This is called the \"sizing\"\nstep. In the next step, which is called immediately afterward on the\nsource processor, the system allocates the required buffer and calls the\nsubroutine to pack the rank\u2019s data into that buffer. This is called the\n\"packing\" step. This packed data is then sent as a message to the\ndestination processor, where first a rank is created (along with the\nthread) and a subroutine is called to unpack the rank\u2019s data from the\nbuffer. This is called the \"unpacking\" step.\n\nThough the above description mentions three subroutines called by the\nAMPI runtime system, it is possible to actually write a single\nsubroutine that will perform all the three tasks. This is achieved using\nsomething we call a \"pupper\". A pupper is an external subroutine that is\npassed to the rank\u2019s pack-unpack-sizing subroutine, and this subroutine,\nwhen called in different phases performs different tasks. An example\nwill make this clear:\n\nSuppose the user data, chunk, is defined as a derived type in Fortran90:\n\n.. code-block:: fortran\n\n   !FORTRAN EXAMPLE\n   MODULE chunkmod\n     INTEGER, parameter :: nx=4, ny=4, tchunks=16\n     TYPE, PUBLIC :: chunk\n         REAL(KIND=8) t(22,22)\n         INTEGER xidx, yidx\n         REAL(KIND=8), dimension(400):: bxm, bxp, bym, byp\n     END TYPE chunk\n   END MODULE\n\n.. code-block:: c++\n\n   //C Example\n   struct chunk{\n     double t;\n     int xidx, yidx;\n     double bxm,bxp,bym,byp;\n   };\n\nThen the pack-unpack subroutine ``chunkpup`` for this chunk module is\nwritten as:\n\n.. code-block:: fortran\n\n   !FORTRAN EXAMPLE\n   SUBROUTINE chunkpup(p, c)\n     USE pupmod\n     USE chunkmod\n     IMPLICIT NONE\n     INTEGER :: p\n     TYPE(chunk) :: c\n\n     call pup(p, c%t)\n     call pup(p, c%xidx)\n     call pup(p, c%yidx)\n     call pup(p, c%bxm)\n     call pup(p, c%bxp)\n     call pup(p, c%bym)\n     call pup(p, c%byp)\n   end subroutine\n\n.. code-block:: c++\n\n   //C Example\n   void chunkpup(pup_er p, struct chunk c){\n     pup_double(p,c.t);\n     pup_int(p,c.xidx);\n     pup_int(p,c.yidx);\n     pup_double(p,c.bxm);\n     pup_double(p,c.bxp);\n     pup_double(p,c.bym);\n     pup_double(p,c.byp);\n   }\n\nThere are several things to note in this example. First, the same\nsubroutine ``pup`` (declared in module ``pupmod``) is called to\nsize/pack/unpack any type of data. This is possible because of procedure\noverloading possible in Fortran90. Second is the integer argument ``p``.\nIt is this argument that specifies whether this invocation of subroutine\n``chunkpup`` is sizing, packing or unpacking. Third, the integer\nparameters declared in the type ``chunk`` need not be packed or unpacked\nsince they are guaranteed to be constants and thus available on any\nprocessor.\n\nA few other functions are provided in module ``pupmod``. These functions\nprovide more control over the packing/unpacking process. Suppose one\nmodifies the ``chunk`` type to include allocatable data or pointers that\nare allocated dynamically at runtime. In this case, when chunk is\npacked, these allocated data structures should be deallocated after\ncopying them to buffers, and when chunk is unpacked, these data\nstructures should be allocated before copying them from the buffers. For\nthis purpose, one needs to know whether the invocation of ``chunkpup``\nis a packing one or unpacking one. For this purpose, the ``pupmod``\nmodule provides functions ``fpup_isdeleting``\\ (``fpup_isunpacking``).\nThese functions return logical value ``.TRUE.`` if the invocation is for\npacking (unpacking), and ``.FALSE.`` otherwise. The following example\ndemonstrates this:\n\nSuppose the type ``dchunk`` is declared as:\n\n.. code-block:: fortran\n\n   !FORTRAN EXAMPLE\n   MODULE dchunkmod\n     TYPE, PUBLIC :: dchunk\n         INTEGER :: asize\n         REAL(KIND=8), pointer :: xarr(:), yarr(:)\n     END TYPE dchunk\n   END MODULE\n\n.. code-block:: c++\n\n   //C Example\n   struct dchunk{\n     int asize;\n     double* xarr, *yarr;\n   };\n\nThen the pack-unpack subroutine is written as:\n\n.. code-block:: fortran\n\n   !FORTRAN EXAMPLE\n   SUBROUTINE dchunkpup(p, c)\n     USE pupmod\n     USE dchunkmod\n     IMPLICIT NONE\n     INTEGER :: p\n     TYPE(dchunk) :: c\n\n     pup(p, c%asize)\n\n     IF (fpup_isunpacking(p)) THEN       !! if invocation is for unpacking\n       allocate(c%xarr(c%asize))\n       ALLOCATE(c%yarr(c%asize))\n     ENDIF\n\n     pup(p, c%xarr)\n     pup(p, c%yarr)\n\n     IF (fpup_isdeleting(p)) THEN        !! if invocation is for packing\n       DEALLOCATE(c%xarr)\n       DEALLOCATE(c%yarr)\n     ENDIF\n\n\n   END SUBROUTINE\n\n.. code-block:: c++\n\n   //C Example\n   void dchunkpup(pup_er p, struct dchunk c){\n     pup_int(p,c.asize);\n     if(pup_isUnpacking(p)){\n       c.xarr = (double *)malloc(sizeof(double)*c.asize);\n       c.yarr = (double *)malloc(sizeof(double)*c.asize);\n     }\n     pup_doubles(p,c.xarr,c.asize);\n     pup_doubles(p,c.yarr,c.asize);\n     if(pup_isPacking(p)){\n       free(c.xarr);\n       free(c.yarr);\n     }\n   }\n\nOne more function ``fpup_issizing`` is also available in module\n``pupmod`` that returns ``.TRUE.`` when the invocation is a sizing one.\nIn practice one almost never needs to use it.\n\nCharm++ also provides higher-level PUP routines for C++ STL data\nstructures and Fortran90 data types. The STL PUP routines will deduce\nthe size of the structure automatically, so that the size of the data\ndoes not have to be passed in to the PUP routine. This facilitates\nwriting PUP routines for large pre-existing codebases. To use it, simply\ninclude pup_stl.h in the user code. For modern Fortran with pointers and\nallocatable data types, AMPI provides a similarly automated PUP\ninterface called apup. User code can include pupmod and then call apup()\non any array (pointer or allocatable, multi-dimensional) of built-in\ntypes (character, short, int, long, real, double, complex, double\ncomplex, logical) and the runtime will deduce the size and shape of the\narray, including unassociated and NULL pointers. Here is the dchunk\nexample from earlier, written to use the apup interface:\n\n.. code-block:: fortran\n\n   !FORTRAN EXAMPLE\n   SUBROUTINE dchunkpup(p, c)\n     USE pupmod\n     USE dchunkmod\n     IMPLICIT NONE\n     INTEGER :: p\n     TYPE(dchunk) :: c\n\n     !! no need for asize\n     !! no isunpacking allocation necessary\n\n     apup(p, c%xarr)\n     apup(p, c%yarr)\n\n     !! no isdeleting deallocation necessary\n\n   END SUBROUTINE\n\nCalling ``MPI_`` routines or accessing global variables that have been\nprivatized by use of tlsglobals or swapglobals from inside a user PUP\nroutine is currently not allowed in AMPI. Users can store MPI-related\ninformation like communicator rank and size in data structures to be be\npacked and unpacked before they are needed inside a PUP routine.\n\nExtensions for Checkpointing\n----------------------------\n\nThe pack-unpack subroutines written for migrations make sure that the\ncurrent state of the program is correctly packed (serialized) so that it\ncan be restarted on a different processor. Using the *same* subroutines,\nit is also possible to save the state of the program to disk, so that if\nthe program were to crash abruptly, or if the allocated time for the\nprogram expires before completing execution, the program can be\nrestarted from the previously checkpointed state. Thus, the pack-unpack\nsubroutines act as the key facility for checkpointing in addition to\ntheir usual role for migration. Just as in load balancing, no\napplication specific code is required when using Isomalloc: the AMPI\nruntime takes care of all the details involved in migrating data.\n\nTo perform a checkpoint in an AMPI program, all you have to do is make a\ncall to ``int AMPI_Migrate(MPI_Info hints)`` with an ``MPI_Info`` object\nthat specifies how you would like to checkpoint. Checkpointing can be\nthought of as migrating AMPI ranks to storage. Users set the\ncheckpointing policy on an ``MPI_Info`` object\u2019s ``\"ampi_checkpoint\"``\nkey to one of the following values: ``\"to_file=directory_name\"`` or\n``\"false\"``. To perform checkpointing in memory a built-in MPI_Info\nobject called ``AMPI_INFO_CHKPT_IN_MEMORY`` is provided.\n\nCheckpointing to file tells the runtime system to save checkpoints in a\ngiven directory. (Typically, in an iterative program, the iteration\nnumber, converted to a character string, can serve as a checkpoint\ndirectory name.) This directory is created, and the entire state of the\nprogram is checkpointed to this directory. One can restart the program\nfrom the checkpointed state (using the same, more, or fewer physical\nprocessors than were checkpointed with) by specifying\n``\"+restart directory_name\"`` on the command-line.\n\nCheckpointing in memory allows applications to transparently tolerate\nfailures online. The checkpointing scheme used here is a double\nin-memory checkpoint, in which virtual processors exchange checkpoints\npairwise across nodes in each other\u2019s memory such that if one node\nfails, that failed node\u2019s AMPI ranks can be restarted by its buddy once\nthe failure is detected by the runtime system. As long as no two buddy\nnodes fail in the same checkpointing interval, the system can restart\nonline without intervention from the user (provided the job scheduler\ndoes not revoke its allocation). Any load imbalance resulting from the\nrestart can then be managed by the runtime system. Use of this scheme is\nillustrated in the code snippet below.\n\n.. code-block:: c++\n\n   // Main time-stepping loop\n   for (int iter=0; iter < max_iters; iter++) {\n\n     // Time step work ...\n\n     if (iter % chkpt_freq == 0)\n       AMPI_Migrate(AMPI_INFO_CHKPT_IN_MEMORY);\n   }\n\nA value of ``\"false\"`` results in no checkpoint being done that step.\nNote that ``AMPI_Migrate`` is a collective function, meaning every\nvirtual processor in the program needs to call this subroutine with the\nsame MPI_Info object. The checkpointing capabilities of AMPI are powered\nby the Charm++ runtime system. For more information about\ncheckpoint/restart mechanisms please refer to the Charm++\nmanual: :numref:`sec:checkpoint`.\n\nExtensions for Memory Efficiency\n--------------------------------\n\nMPI functions usually require the user to preallocate the data buffers\nneeded before the functions being called. For unblocking communication\nprimitives, sometimes the user would like to do lazy memory allocation\nuntil the data actually arrives, which gives the opportunities to write\nmore memory efficient programs. We provide a set of AMPI functions as an\nextension to the standard MPI-2 one-sided calls, where we provide a\nsplit phase ``MPI_Get`` called ``AMPI_Iget``. ``AMPI_Iget`` preserves\nthe similar semantics as ``MPI_Get`` except that no user buffer is\nprovided to hold incoming data. ``AMPI_Iget_wait`` will block until the\nrequested data arrives and runtime system takes care to allocate space,\ndo appropriate unpacking based on data type, and return.\n``AMPI_Iget_free`` lets the runtime system free the resources being used\nfor this get request including the data buffer. Finally,\n``AMPI_Iget_data`` is the routine used to access the data.\n\n.. code-block:: c++\n\n\n   int AMPI_Iget(MPI_Aint orgdisp, int orgcnt, MPI_Datatype orgtype, int rank,\n                 MPI_Aint targdisp, int targcnt, MPI_Datatype targtype, MPI_Win win,\n                 MPI_Request *request);\n\n   int AMPI_Iget_wait(MPI_Request *request, MPI_Status *status, MPI_Win win);\n\n   int AMPI_Iget_free(MPI_Request *request, MPI_Status *status, MPI_Win win);\n\n   int AMPI_Iget_data(void *data, MPI_Status status);\n\nExtensions for Interoperability\n-------------------------------\n\nInteroperability between different modules is essential for coding\ncoupled simulations. In this extension to AMPI, each MPI application\nmodule runs within its own group of user-level threads distributed over\nthe physical parallel machine. In order to let AMPI know which ranks are\nto be created, and in what order, a top level registration routine needs\nto be written. A real-world example will make this clear. We have an MPI\ncode for fluids and another MPI code for solids, both with their main\nprograms, then we first transform each individual code to run correctly\nunder AMPI as standalone codes. Aside from the global and static\nvariable privatization transformations needed, this also involves making\nthe main program into a subroutine and naming it ``MPI_Main``.\n\nThus now, we have two ``MPI_Main``\\ s, one for the fluids code and one\nfor the solids code. We now make these codes co-exist within the same\nexecutable, by first renaming these ``MPI_Main``\\ s as ``Fluids_Main``\nand ``Solids_Main``\\  [5]_ writing a subroutine called ``MPI_Setup``.\n\n.. code-block:: fortran\n\n   !FORTRAN EXAMPLE\n   SUBROUTINE MPI_Setup\n     USE ampi\n     CALL AMPI_Register_main(Solids_Main)\n     CALL AMPI_Register_main(Fluids_Main)\n   END SUBROUTINE\n\n.. code-block:: c++\n\n   //C Example\n   void MPI_Setup(){\n     AMPI_Register_main(Solids_Main);\n     AMPI_Register_main(Fluids_Main);\n   }\n\nThis subroutine is called from the internal initialization routines of\nAMPI and tells AMPI how many numbers of distinct modules exist, and\nwhich orchestrator subroutines they execute.\n\nThe number of ranks to create for each module is specified on the\ncommand line when an AMPI program is run. Appendix B explains how AMPI\nprograms are run, and how to specify the number of ranks (``+vp``\noption). In the above case, suppose one wants to create 128 ranks of\nSolids and 64 ranks of Fluids on 32 physical processors, one would\nspecify those with multiple ``+vp`` options on the command line as:\n\n.. code-block:: bash\n\n   $ ./charmrun gen1.x +p 32 +vp 128 +vp 64\n\nThis will ensure that multiple modules representing different complete\napplications can co-exist within the same executable. They can also\ncontinue to communicate among their own ranks using the same AMPI\nfunction calls to send and receive with communicator argument as\n``MPI_COMM_WORLD``. But this would be completely useless if these\nindividual applications cannot communicate with each other, which is\nessential for building efficient coupled codes. For this purpose, we\nhave extended the AMPI functionality to allow multiple\n\"``COMM_WORLD``\\ s\"; one for each application. These *world\ncommunicators* form a \"communicator universe\" an array of communicators\naptly called *MPI_COMM_UNIVERSE*. This array of communicators is indexed\n[1 . . . ``MPI_MAX_COMM``]. In the current implementation,\n``MPI_MAX_COMM`` is 8, that is, maximum of 8 applications can co-exist\nwithin the same executable.\n\nThe order of these ``COMM_WORLD``\\ s within ``MPI_COMM_UNIVERSE`` is\ndetermined by the order in which individual applications are registered\nin ``MPI_Setup``.\n\nThus, in the above example, the communicator for the Solids module would\nbe ``MPI_COMM_UNIVERSE(1)`` and communicator for Fluids module would be\n``MPI_COMM_UNIVERSE(2)``.\n\nNow any rank within one application can communicate with any rank in the\nother application using the familiar send or receive AMPI calls by\nspecifying the appropriate communicator and the rank number within that\ncommunicator in the call. For example if a Solids rank number 36 wants\nto send data to rank number 47 within the Fluids module, it calls:\n\n.. code-block:: fortran\n\n   !FORTRAN EXAMPLE\n   INTEGER , PARAMETER :: Fluids_Comm = 2\n   CALL MPI_Send(InitialTime, 1, MPI_Double_Precision, tag,\n                 47, MPI_Comm_Universe(Fluids_Comm), ierr)\n\n.. code-block:: c++\n\n   //C Example\n   int Fluids_Comm = 2;\n   ierr = MPI_Send(InitialTime, 1, MPI_DOUBLE, tag,\n                   47, MPI_Comm_Universe(Fluids_Comm));\n\nThe Fluids rank has to issue a corresponding receive call to receive\nthis data:\n\n.. code-block:: fortran\n\n   !FORTRAN EXAMPLE\n   INTEGER , PARAMETER :: Solids_Comm = 1\n   CALL MPI_Recv(InitialTime, 1, MPI_Double_Precision, tag,\n                 36, MPI_Comm_Universe(Solids_Comm), stat, ierr)\n\n.. code-block:: c++\n\n   //C Example\n   int Solids_Comm = 1;\n   ierr = MPI_Recv(InitialTime, 1, MPI_DOUBLE, tag,\n                   36, MPI_Comm_Universe(Solids_Comm), &stat);\n\nCharm++ Interoperability\n------------------------\n\nThere is preliminary support for interoperating AMPI programs with Charm++\nprograms. This allows users to launch an AMPI program with an arbitrary number\nof virtual processes in the same executable as a Charm++ program that contains\narbitrary collections of chares, with both AMPI ranks and chares being co-scheduled\nby the runtime system. We also provide an entry method ``void injectMsg(int n, char buf[n])``\nfor chares to communicate with AMPI ranks. An example program can be found in\n``examples/charm++/AMPI-interop``.\n\nExtensions for Sequential Re-run of a Parallel Node\n---------------------------------------------------\n\nIn some scenarios, a sequential re-run of a parallel node is desired.\nOne example is instruction-level accurate architecture simulations, in\nwhich case the user may wish to repeat the execution of a node in a\nparallel run in the sequential simulator. AMPI provides support for such\nneeds by logging the change in the MPI environment on a certain\nprocessors. To activate the feature, build AMPI module with variable\n\"AMPIMSGLOG\" defined, like the following command in charm directory.\n(Linking with zlib \"-lz\" might be required with this, for generating\ncompressed log file.)\n\n.. code-block:: bash\n\n   $ ./build AMPI netlrts-linux-x86_64 -DAMPIMSGLOG\n\nThe feature is used in two phases: writing (logging) the environment and\nrepeating the run. The first logging phase is invoked by a parallel run\nof the AMPI program with some additional command line options.\n\n.. code-block:: bash\n\n   $ ./charmrun ./pgm +p4 +vp4 +msgLogWrite +msgLogRank 2 +msgLogFilename \"msg2.log\"\n\nIn the above example, a parallel run with 4 worker threads and 4 AMPI\nranks will be executed, and the changes in the MPI environment of worker\nthread 2 (also rank 2, starting from 0) will get logged into diskfile\n\"msg2.log\".\n\nUnlike the first run, the re-run is a sequential program, so it is not\ninvoked by charmrun (and omitting charmrun options like +p4 and +vp4),\nand additional command line options are required as well.\n\n.. code-block:: bash\n\n   $ ./pgm +msgLogRead +msgLogRank 2 +msgLogFilename \"msg2.log\"\n\nUser Defined Initial Mapping\n----------------------------\n\nYou can define the initial mapping of virtual processors (vp) to\nphysical processors (p) as a runtime option. You can choose from\npredefined initial mappings or define your own mappings. The following\npredefined mappings are available:\n\nRound Robin\n   This mapping scheme maps virtual processor to physical processor in\n   round-robin fashion, i.e. if there are 8 virtual processors and 2\n   physical processors then virtual processors indexed 0,2,4,6 will be\n   mapped to physical processor 0 and virtual processors indexed 1,3,5,7\n   will be mapped to physical processor 1.\n\n   .. code-block:: bash\n\n      $ ./charmrun ./hello +p2 +vp8 +mapping RR_MAP\n\nBlock Mapping\n   This mapping scheme maps virtual processors to physical processor in\n   ranks, i.e. if there are 8 virtual processors and 2 physical\n   processors then virtual processors indexed 0,1,2,3 will be mapped to\n   physical processor 0 and virtual processors indexed 4,5,6,7 will be\n   mapped to physical processor 1.\n\n   .. code-block:: bash\n\n      $ ./charmrun ./hello +p2 +vp8 +mapping BLOCK_MAP\n\nProportional Mapping\n   This scheme takes the processing capability of physical processors\n   into account for mapping virtual processors to physical processors,\n   i.e. if there are 2 processors running at different frequencies, then\n   the number of virtual processors mapped to processors will be in\n   proportion to their processing power. To make the load balancing\n   framework aware of the heterogeneity of the system, the flag\n   *+LBTestPESpeed* should also be used.\n\n   .. code-block:: bash\n\n      $ ./charmrun ./hello +p2 +vp8 +mapping PROP_MAP\n      $ ./charmrun ./hello +p2 +vp8 +mapping PROP_MAP +balancer GreedyLB +LBTestPESpeed\n\nIf you want to define your own mapping scheme, please contact us for\nassistance.\n\nPerformance Visualization\n-------------------------\n\nAMPI users can take advantage of Charm++\u2019s tracing framework and\nassociated performance visualization tool, Projections. Projections\nprovides a number of different views of performance data that help users\ndiagnose performance issues. Along with the traditional Timeline view,\nProjections also offers visualizations of load imbalance and\ncommunication-related data.\n\nIn order to generate tracing logs from an application to view in\nProjections, link with ``ampicc -tracemode projections``.\n\nAMPI defines the following extensions for tracing support:\n\n.. code-block:: none\n\n   AMPI_Trace_begin                      AMPI_Trace_end\n\nWhen using the *Timeline* view in Projections, AMPI users can visualize\nwhat each VP on each processor is doing (what MPI method it is running\nor blocked in) by clicking the *View* tab and then selecting *Show\nNested Bracketed User Events* from the drop down menu. See the\nProjections manual for information on performance analysis and\nvisualization.\n\nAMPI users can also use any tracing libraries or tools that rely on\nMPI\u2019s PMPI profiling interface, though such tools may not be aware of\nAMPI process virtualization.\n\nCompiling AMPI Programs\n-----------------------\n\nAMPI provides a cross-platform compile-and-link script called *ampicc*\nto compile C, C++, and Fortran AMPI programs. This script resides in the\n``bin`` subdirectory in the Charm++ installation directory. The main\npurpose of this script is to deal with the differences of various\ncompiler names and command-line options across various machines on which\nAMPI runs. It is recommended that the AMPI compiler scripts be used to\ncompile and link AMPI programs. One major advantage of using these is\nthat one does not have to specify which libraries are to be linked for\nensuring that C++ and Fortran90 codes are linked together correctly.\nAppropriate libraries required for linking such modules together are\nknown to *ampicc* for various machines.\n\nIn spite of the platform-neutral syntax of *ampicc*, one may have to\nspecify some platform-specific options for compiling and building AMPI\ncodes. Fortunately, if *ampicc* does not recognize any particular\noptions on its command line, it promptly passes it to all the individual\ncompilers and linkers it invokes to compile the program. See the\nappendix for more details on building and running AMPI programs.\n\n.. _adaptive-mpi-ampi-codes:\n\nAMPI Example Applications\n-------------------------\n\n| This section contains a list of applications that have been written or\n  adapted to work with AMPI. Most applications are available on git:\n| ``git clone ssh://charm.cs.illinois.edu:9418/benchmarks/ampi-benchmarks``.\n\nMost benchmarks can be compiled with the provided top-level Makefile:\n\n.. code-block:: bash\n\n       $ git clone ssh://charm.cs.illinois.edu:9418/benchmarks/ampi-benchmarks\n       $ cd ampi-benchmarks\n       $ make -f Makefile.ampi\n\nMantevo project v3.0\n~~~~~~~~~~~~~~~~~~~~\n\nSet of mini-apps from the Mantevo project. Download at\nhttps://mantevo.org/download/.\n\nMiniFE\n^^^^^^\n\n-  Mantevo mini-app for unstructured implicit Finite Element\n   computations.\n\n-  No changes necessary to source to run on AMPI. Modify file\n   ``makefile.ampi`` and change variable ``AMPIDIR`` to point to your\n   Charm++ directory, execute ``make -f makefile.ampi`` to build the\n   program.\n\n-  Refer to the ``README`` file on how to run the program. For example:\n   ``./charmrun +p4 ./miniFE.x nx=30 ny=30 nz=30 +vp32``\n\nMiniMD v2.0\n^^^^^^^^^^^\n\n-  Mantevo mini-app for particle interaction in a Lennard-Jones system,\n   as in the LAMMPS MD code.\n\n-  No changes necessary to source code. Modify file ``Makefile.ampi``\n   and change variable ``AMPIDIR`` to point to your Charm++ directory,\n   execute ``make ampi`` to build the program.\n\n-  Refer to the ``README`` file on how to run the program. For example:\n   ``./charmrun +p4 ./miniMD_ampi +vp32``\n\nCoMD v1.1\n^^^^^^^^^\n\n-  Mantevo mini-app for molecular dynamics codes:\n   https://github.com/exmatex/CoMD\n\n-  To AMPI-ize it, we had to remove calls to not thread-safe\n   ``getopt()``. Support for dynamic load balancing has been added in\n   the main loop and the command line options. It will run on all\n   platforms.\n\n-  Just update the Makefile to point to AMPI compilers and run with the\n   provided run scripts.\n\nMiniXYCE v1.0\n^^^^^^^^^^^^^\n\n-  Mantevo mini-app for discrete analog circuit simulation, version 1.0,\n   with serial, MPI, OpenMP, and MPI+OpenMP versions.\n\n-  No changes besides Makefile necessary to run with virtualization. To\n   build, do ``cp common/generate_info_header miniXyce_ref/.``, modify\n   the CC path in ``miniXyce_ref/`` and run ``make``. Run scripts are in\n   ``test/``.\n\n-  Example run command:\n   ``./charmrun +p3 ./miniXyce.x +vp3 -circuit ../tests/cir1.net -t_start 1e-6 -pf params.txt``\n\nHPCCG v1.0\n^^^^^^^^^^\n\n-  Mantevo mini-app for sparse iterative solves using the Conjugate\n   Gradient method for a problem similar to that of MiniFE.\n\n-  No changes necessary except to set compilers in ``Makefile`` to the\n   AMPI compilers.\n\n-  Run with a command such as:\n   ``./charmrun +p2 ./test_HPCCG 20 30 10 +vp16``\n\nMiniAMR v1.0\n^^^^^^^^^^^^\n\n-  miniAMR applies a stencil calculation on a unit cube computational\n   domain, which is refined over time.\n\n-  No changes if using swap-globals. Explicitly extern global variables\n   if using TLS.\n\nNot yet AMPI-zed (reason):\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nMiniAero v1.0 (build issues), MiniGhost v1.0.1 (globals), MiniSMAC2D\nv2.0 (globals), TeaLeaf v1.0 (globals), CloverLeaf v1.1 (globals),\nCloverLeaf3D v1.0 (globals).\n\nLLNL ASC Proxy Apps\n~~~~~~~~~~~~~~~~~~~\n\nLULESH v2.0\n^^^^^^^^^^^\n\n-  LLNL Unstructured Lagrangian-Eulerian Shock Hydrodynamics proxy app:\n   https://codesign.llnl.gov/lulesh.php\n\n-  Charm++, MPI, MPI+OpenMP, Liszt, Loci, Chapel versions all exist for\n   comparison.\n\n-  Manually privatized version of LULESH 2.0, plus a version with PUP\n   routines in subdirectory ``pup_lulesh202/``.\n\nAMG 2013\n^^^^^^^^\n\n-  LLNL ASC proxy app: Algebraic Multi-Grid solver for linear systems\n   arising from unstructured meshes:\n   https://codesign.llnl.gov/amg2013.php\n\n-  AMG is based on HYPRE, both from LLNL. The only change necessary to\n   get AMG running on AMPI with virtualization is to remove calls to\n   HYPRE\u2019s timing interface, which is not thread-safe.\n\n-  To build, point the CC variable in Makefile.include to your AMPI CC\n   wrapper script and ``make``. Executable is ``test/amg2013``.\n\nLassen v1.0\n^^^^^^^^^^^\n\n-  LLNL ASC mini-app for wave-tracking applications with dynamic load\n   imbalance. Reference versions are serial, MPI, Charm++, and\n   MPI/Charm++ interop: https://codesign.llnl.gov/lassen.php\n\n-  No changes necessary to enable AMPI virtualization. Requires some\n   C++11 support. Set ``AMPIDIR`` in Makefile and ``make``. Run with:\n   ``./charmrun +p4 ./lassen_mpi +vp8 default 2 2 2 50 50 50``\n\nKripke v1.1\n^^^^^^^^^^^\n\n-  LLNL ASC proxy app for ARDRA, a full Sn deterministic particle\n   transport application: https://codesign.llnl.gov/kripke.php\n\n-  Charm++, MPI, MPI+OpenMP, MPI+RAJA, MPI+CUDA, MPI+OCCA versions exist\n   for comparison.\n\n-  Kripke requires no changes between MPI and AMPI since it has no\n   global/static variables. It uses cmake so edit the cmake toolchain\n   files in ``cmake/toolchain/`` to point to the AMPI compilers, and\n   build in a build directory:\n\n   .. code-block:: bash\n\n      $ mkdir build; cd build;\n      $ cmake .. -DCMAKE_TOOLCHAIN_FILE=../cmake/Toolchain/linux-gcc-ampi.cmake\n      -DENABLE_OPENMP=OFF\n      $ make\n\n   Run with:\n\n   .. code-block:: bash\n\n      $ ./charmrun +p8 ./src/tools/kripke +vp8 --zones 64,64,64 --procs 2,2,2 --nest ZDG\n\nMCB v1.0.3 (2013)\n^^^^^^^^^^^^^^^^^\n\n-  LLNL ASC proxy app for Monte Carlo particle transport codes:\n   https://codesign.llnl.gov/mcb.php\n\n-  MPI+OpenMP reference version.\n\n-  Run with:\n\n   .. code-block:: bash\n\n      $ OMP_NUM_THREADS=1 ./charmrun +p4 ./../src/MCBenchmark.exe --weakScaling\n       --distributedSource --nCores=1 --numParticles=20000 --multiSigma --nThreadCore=1 +vp16\n\n.. _not-yet-ampi-zed-reason-1:\n\nNot yet AMPI-zed (reason)\n^^^^^^^^^^^^^^^^^^^^^^^^^\n\n: UMT 2013 (global variables).\n\nOther Applications\n~~~~~~~~~~~~~~~~~~\n\nMILC 7.0\n^^^^^^^^\n\n-  MILC is a code to study quantum chromodynamics (QCD) physics.\n   http://www.nersc.gov/users/computational-systems/cori/nersc-8-procurement/trinity-nersc-8-rfp/nersc-8-trinity-benchmarks/milc/\n\n-  Moved ``MPI_Init_thread`` call to ``main()``, added ``__thread`` to\n   all global/static variable declarations. Runs on AMPI with\n   virtualization when using -tlsglobals.\n\n-  Build: edit ``ks_imp_ds/Makefile`` to use AMPI compiler wrappers, run\n   ``make su3_rmd`` in ``ks_imp_ds/``\n\n-  Run with: ``./su3_rmd +vp8 ../benchmark_n8/single_node/n8_single.in``\n\nSNAP v1.01 (C version)\n^^^^^^^^^^^^^^^^^^^^^^\n\n-  LANL proxy app for PARTISN, an Sn deterministic particle transport\n   application: https://github.com/losalamos/SNAP\n\n-  SNAP is an update to Sweep3D. It simulates the same thing as Kripke,\n   but with a different decomposition and slight algorithmic\n   differences. It uses a 1- or 2-dimensional decomposition and the KBA\n   algorithm to perform parallel sweeps over the 3-dimensional problem\n   space. It contains all of the memory, computation, and network\n   performance characteristics of a real particle transport code.\n\n-  Original SNAP code is Fortran90-MPI-OpenMP, but this is a\n   C-MPI-OpenMP version of it provided along with the original version.\n   The Fortran90 version will require global variable privatization,\n   while the C version works out of the box on all platforms.\n\n-  Edit the Makefile for AMPI compiler paths and run with:\n   ``./charmrun +p4 ./snap +vp4 --fi center_src/fin01 --fo center_src/fout01``\n\nSweep3D\n^^^^^^^\n\n-  Sweep3D is a *particle transport* program that analyzes the flux of\n   particles along a space. It solves a three-dimensional particle\n   transport problem.\n\n-  This mini-app has been deprecated, and replaced at LANL by SNAP\n   (above).\n\n-  Build/Run Instructions:\n\n   -  Modify the ``makefile`` and change variable CHARMC to point to\n      your Charm++ compiler command, execute ``make mpi`` to build the\n      program.\n\n   -  Modify file ``input`` to set the different parameters. Refer to\n      file ``README`` on how to change those parameters. Run with:\n      ``./charmrun ./sweep3d.mpi +p8 +vp16``\n\nPENNANT v0.8\n^^^^^^^^^^^^\n\n-  Unstructured mesh Rad-Hydro mini-app for a full application at LANL\n   called FLAG. https://github.com/losalamos/PENNANT\n\n-  Written in C++, only global/static variables that need to be\n   privatized are mype and numpe. Done manually.\n\n-  Legion, Regent, MPI, MPI+OpenMP, MPI+CUDA versions of PENNANT exist\n   for comparison.\n\n-  For PENNANT-v0.8, point CC in Makefile to AMPICC and just \u2019make\u2019. Run\n   with the provided input files, such as:\n   ``./charmrun +p2 ./build/pennant +vp8 test/noh/noh.pnt``\n\nBenchmarks\n~~~~~~~~~~\n\nJacobi-2D (Fortran)\n^^^^^^^^^^^^^^^^^^^\n\n-  Jacobi-2D with 1D decomposition. Problem size and number of\n   iterations are defined in the source code. Manually privatized.\n\nJacobi-3D (C)\n^^^^^^^^^^^^^\n\n-  Jacobi-3D with 3D decomposition. Manually privatized. Includes\n   multiple versions: Isomalloc, PUP, FT, LB, Isend/Irecv, Iput/Iget.\n\nNAS Parallel Benchmarks (NPB 3.3)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n-  A collection of kernels used in different scientific applications.\n   They are mainly implementations of various linear algebra methods.\n   http://www.nas.nasa.gov/Resources/Software/npb.html\n\n-  Build/Run Instructions:\n\n   -  Modify file ``config/make.def`` to make variable ``CHAMRDIR``\n      point to the right Charm++ directory.\n\n   -  Use ``make <benchmark> NPROCS=<P> CLASS=<C>`` to build a\n      particular benchmark. The values for ``<benchmark>`` are (bt, cg,\n      dt, ep, ft, is, lu, mg, sp), ``<P>`` is the number of ranks and\n      ``<C>`` is the class or the problem size (to be chosen from\n      A,B,C,D or E). Some benchmarks may have restrictions on values of\n      ``<P>`` and ``<C>``. For instance, to make CG benchmark with 256\n      ranks and class C, we will use the following command:\n      ``make cg NPROCS=256``\n\n   -  The resulting executable file will be generated in the respective\n      directory for the benchmark. In the previous example, a file\n      *cg.256.C* will appear in the *CG* and ``bin/`` directories. To\n      run the particular benchmark, you must follow the standard\n      procedure of running AMPI programs:\n      ``./charmrun ./cg.C.256 +p64 +vp256 ++nodelist nodelist +isomalloc_sync``\n\nNAS PB Multi-Zone Version (NPB-MZ 3.3)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n-  A multi-zone version of BT, SP and LU NPB benchmarks. The multi-zone\n   intentionally divides the space unevenly among ranks and causes load\n   imbalance. The original goal of multi-zone versions was to offer an\n   test case for hybrid MPI+OpenMP programming, where the load imbalance\n   can be dealt with by increasing the number of threads in those ranks\n   with more computation.\n   http://www.nas.nasa.gov/Resources/Software/npb.html\n\n-  The BT-MZ program shows the heaviest load imbalance.\n\n-  Build/Run Instructions:\n\n   -  Modify file ``config/make.def`` to make variable ``CHAMRDIR``\n      point to the right Charm++ build.\n\n   -  Use the format ``make <benchmark> NPROCS=<P> CLASS=<C>`` to build\n      a particular benchmark. The values for ``<benchmark>`` are (bt-mz,\n      lu-mz, sp-mz), ``<P>`` is the number of ranks and ``<C>`` is the\n      class or the problem size (to be chosen from A,B,C,D or E). Some\n      benchmarks may have restrictions on values of ``<P>`` and ``<C>``.\n      For instance, to make the BT-MZ benchmark with 256 ranks and class\n      C, you can use the following command:\n      ``make bt-mz NPROCS=256 CLASS=C``\n\n   -  The resulting executable file will be generated in the *bin/*\n      directory. In the previous example, a file *bt-mz.256.C* will be\n      created in the ``bin`` directory. To run the particular benchmark,\n      you must follow the standard procedure of running AMPI programs:\n      ``./charmrun ./bt-mz.C.256 +p64 +vp256 ++nodelist nodelist +isomalloc_sync``\n\nHPCG v3.0\n^^^^^^^^^\n\n-  High Performance Conjugate Gradient benchmark, version 3.0. Companion\n   metric to Linpack, with many vendor-optimized implementations\n   available: http://hpcg-benchmark.org/\n\n-  No AMPI-ization needed. To build, modify ``setup/Make.AMPI`` for\n   compiler paths, do\n   ``mkdir build && cd build && configure ../setup/Make.AMPI && make``.\n   To run, do ``./charmrun +p16 ./bin/xhpcg +vp64``\n\nIntel Parallel Research Kernels (PRK) v2.16\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n-  A variety of kernels (Branch, DGEMM, Nstream, Random, Reduce, Sparse,\n   Stencil, Synch_global, Synch_p2p, and Transpose) implemented for a\n   variety of runtimes (SERIAL, OpenMP, MPI-1, MPI-RMA, MPI-SHM,\n   MPI+OpenMP, SHMEM, FG_MPI, UPC, Grappa, Charm++, and AMPI).\n   https://github.com/ParRes/Kernels\n\n-  For AMPI tests, set ``CHARMTOP`` and run: ``make allampi``. There are\n   run scripts included.\n\nOSU Microbenchmarks\n^^^^^^^^^^^^^^^^^^^\n\nMPI collectives performance testing suite.\nhttps://charm.cs.illinois.edu/gerrit/#/admin/projects/benchmarks/osu-collectives-benchmarking\n\n-  Build with: ``./configure CC=~/charm/bin/ampicc && make``\n\nThird Party Open Source Libraries\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nHYPRE-2.11.1\n^^^^^^^^^^^^\n\n-  High Performance Preconditioners and solvers library from LLNL.\n   https://computation.llnl.gov/project/linear_solvers/software.php\n\n-  Hypre-2.11.1 builds on top of AMPI using the configure command:\n\n   .. code-block:: bash\n\n      $ ./configure --with-MPI \\\n            CC=~/charm/bin/ampicc \\\n            CXX=~/charm/bin/ampicxx \\\n            F77=~/charm/bin/ampif77 \\\n            --with-MPI-include=~/charm/include \\\n            --with-MPI-lib-dirs=~/charm/lib \\\n            --with-MPI-libs=mpi --without-timing --without-print-errors\n      $ make -j8\n\n-  All HYPRE tests and examples pass tests with virtualization,\n   migration, etc. except for those that use Hypre\u2019s timing interface,\n   which uses a global variable internally. So just remove those calls\n   and do not define ``HYPRE_TIMING`` when compiling a code that uses\n   Hypre. In the examples directory, you\u2019ll have to set the compilers to\n   your AMPI compilers explicitly too. In the test directory, you\u2019ll\n   have to edit the Makefile to 1) Remove ``-DHYPRE_TIMING`` from both\n   ``CDEFS`` and ``CXXDEFS``, 2) Remove both ``${MPILIBS}`` and\n   ``${MPIFLAGS}`` from ``MPILIBFLAGS``, and 3) Remove ``${LIBS}`` from\n   ``LIBFLAGS``. Then run ``make``.\n\n-  To run the ``new_ij`` test, run:\n   ``./charmrun +p64 ./new_ij -n 128 128 128 -P 4 4 4 -intertype 6 -tol 1e-8 -CF 0 -solver 61 -agg_nl 1 27pt -Pmx 6 -ns 4 -mu 1 -hmis -rlx 13 +vp64``\n\nMFEM-3.2\n^^^^^^^^\n\n-  MFEM is a scalable library for Finite Element Methods developed at\n   LLNL. http://mfem.org/\n\n-  MFEM-3.2 builds on top of AMPI (and METIS-4.0.3 and HYPRE-2.11.1).\n   Download MFEM,\n   `HYPRE <https://computation.llnl.gov/project/linear_solvers/software.php>`__,\n   and `METIS <http://glaros.dtc.umn.edu/gkhome/fsroot/sw/metis/OLD>`__.\n   Untar all 3 in the same top-level directory.\n\n-  Build HYPRE-2.11.1 as described above.\n\n-  Build METIS-4.0.3 by doing ``cd metis-4.0.3/ && make``\n\n-  Build MFEM-3.2 serial first by doing ``make serial``\n\n-  Build MFEM-3.2 parallel by doing:\n\n   -  First, comment out ``#define HYPRE_TIMING`` in\n      ``mfem/linalg/hypre.hpp``. Also, you must add a\n      ``#define hypre_clearTiming()`` at the top of\n      ``linalg/hypre.cpp``, because Hypre-2.11.1 has a bug where it\n      doesn\u2019t provide a definition of this function if you don\u2019t define\n      ``HYPRE_TIMING``.\n\n   -  ``make parallel MFEM_USE_MPI=YES MPICXX=~/charm/bin/ampicxx HYPRE_DIR=~/hypre-2.11.1/src/hypre METIS_DIR=~/metis-4.0.3``\n\n-  To run an example, do\n   ``./charmrun +p4 ./ex15p -m ../data/amr-quad.mesh +vp16``. You may\n   want to add the runtime options ``-no-vis`` and ``-no-visit`` to\n   speed things up.\n\n-  All example programs and miniapps pass with virtualization, and\n   migration if added.\n\nXBraid-1.1\n^^^^^^^^^^\n\n-  XBraid is a scalable library for parallel time integration using\n   MultiGrid, developed at LLNL.\n   https://computation.llnl.gov/project/parallel-time-integration/software.php\n\n-  XBraid-1.1 builds on top of AMPI (and its examples/drivers build on\n   top of MFEM-3.2, HYPRE-2.11.1, and METIS-4.0.3 or METIS-5.1.0).\n\n-  To build XBraid, modify the variables CC, MPICC, and MPICXX in\n   makefile.inc to point to your AMPI compilers, then do ``make``.\n\n-  To build XBraid\u2019s examples/ and drivers/ modify the paths to MFEM and\n   HYPRE in their Makefiles and ``make``.\n\n-  To run an example, do\n   ``./charmrun +p2 ./ex-02 -pgrid 1 1 8 -ml 15 -nt 128 -nx 33 33 -mi 100 +vp8 ++local``.\n\n-  To run a driver, do\n   ``./charmrun +p4 ./drive-03 -pgrid 2 2 2 2 -nl 32 32 32 -nt 16 -ml 15 +vp16 ++local``\n\nOther AMPI codes\n~~~~~~~~~~~~~~~~\n\n-  FLASH\n\n-  BRAMS (Weather prediction model)\n\n-  CGPOP\n\n-  Fractography3D (Crack Propagation)\n\n-  JetAlloc\n\n-  PlasComCM (XPACC)\n\n-  PlasCom2 (XPACC)\n\n-  Harm3D\n\nInstalling AMPI\n===============\n\nAMPI is included in the source distribution of Charm++. To get the\nlatest sources from PPL, visit: http://charm.cs.illinois.edu/software\n\nand follow the download links. Then build Charm++ and AMPI from source.\n\nThe build script for Charm++ is called ``build``. The syntax for this\nscript is:\n\n.. code-block:: bash\n\n   $ build <target> <version> <opts>\n\nFor building AMPI (which also includes building Charm++ and other\nlibraries needed by AMPI), specify ``<target>`` to be ``AMPI``. And\n``<opts>`` are command line options passed to the ``charmc`` compile\nscript. Common compile time options such as\n``-g, -O, -Ipath, -Lpath, -llib`` are accepted.\n\nTo build a debugging version of AMPI, use the option: ``-g``. To build a\nproduction version of AMPI, use the option: ``-with-production``.\n\n``<version>`` depends on the machine, operating system, and the\nunderlying communication library one wants to use for running AMPI\nprograms. See the charm/README file for details on picking the proper\nversion. Here is an example of how to build a debug version of AMPI in a\nlinux and ethernet environment:\n\n.. code-block:: bash\n\n   $ ./build AMPI netlrts-linux-x86_64 -g\n\nAnd the following is an example of how to build a production version of\nAMPI on a Cray XC system, with MPI-level error checking in AMPI turned\noff:\n\n.. code-block:: bash\n\n   $ ./build AMPI gni-crayxc --with-production --disable-ampi-error-checking\n\nAMPI can also be built with support for shared memory on any\ncommunication layer by adding \"smp\" as an option after the build target.\nFor example, on an Infiniband Linux cluster:\n\n.. code-block:: bash\n\n   $ ./build AMPI verbs-linux-x86_64 smp --with-production\n\nAMPI ranks are implemented as user-level threads with a stack size\ndefault of 1MB. If the default is not correct for your program, you can\nspecify a different default stack size (in bytes) at build time. The\nfollowing build command illustrates this for an Intel Omni-Path system:\n\n.. code-block:: bash\n\n   $ ./build AMPI ofi-linux-x86_64 --with-production -DTCHARM_STACKSIZE_DEFAULT=16777216\n\nThe same can be done for AMPI\u2019s RDMA messaging threshold using\n``AMPI_RDMA_THRESHOLD_DEFAULT`` and, for messages sent within the same\naddress space (ranks on the same worker thread or ranks on different\nworker threads in the same process in SMP builds), using\n``AMPI_SMP_RDMA_THRESHOLD_DEFAULT``. Contiguous messages with sizes\nlarger than the threshold are sent via RDMA on communication layers that\nsupport this capability. You can also set the environment variables\n``AMPI_RDMA_THRESHOLD`` and ``AMPI_SMP_RDMA_THRESHOLD`` before running a\njob to override the default specified at build time.\n\nBuilding and Running AMPI Programs\n==================================\n\nBuilding AMPI Programs\n----------------------\n\nAMPI provides a compiler called *ampicc* in your charm/bin/ directory.\nYou can use this compiler to build your AMPI program the same way as\nother compilers like cc. All the command line flags that you would use\nfor other compilers can be used with the AMPI compilers the same way.\nFor example:\n\n.. code-block:: bash\n\n   $ ampicc -c pgm.c -O3\n   $ ampif90 -c pgm.f90 -O0 -g\n   $ ampicc -o pgm pgm.o -lm -O3\n\nTo use Isomalloc for transparently migrating user heap data, link with\n*-memory isomalloc*. To use a Charm++ load balancer, link a strategy or\na suite of strategies in with *-module <LB>*. For example:\n\n.. code-block:: bash\n\n   $ ampicc pgm.c -o pgm -O3 -memory isomalloc -module CommonLBs\n\nRunning AMPI programs\n---------------------\n\nAMPI offers two options to execute an AMPI program, ``charmrun`` and\n``ampirun``.\n\nRunning with charmrun\n~~~~~~~~~~~~~~~~~~~~~\n\nThe Charm++ distribution contains a script called ``charmrun`` that\nmakes the job of running AMPI programs portable and easier across all\nparallel machines supported by Charm++. ``charmrun`` is copied to a\ndirectory where an AMPI program is built using ``ampicc``. It takes a\ncommand line parameter specifying number of processors, and the name of\nthe program followed by AMPI options (such as number of ranks to create,\nand the stack size of every user-level thread) and the program\narguments. A typical invocation of an AMPI program ``pgm`` with\n``charmrun`` is:\n\n.. code-block:: bash\n\n   $ ./charmrun +p16 ./pgm +vp64\n\nHere, the AMPI program ``pgm`` is run on 16 physical processors with 64\ntotal virtual ranks (which will be mapped 4 per processor initially).\n\nTo run with load balancing, specify a load balancing strategy. If\nAddress Space Layout Randomization is enabled on your target system, you\nmay need to add the flag ``+isomalloc_sync`` when running with\nmigration. You can also specify the size of user-level thread\u2019s stack\nusing the ``+tcharm_stacksize`` option, which can be used to decrease\nthe size of the stack that must be migrated, as in the following\nexample:\n\n.. code-block:: bash\n\n   $ ./charmrun +p16 ./pgm +vp128 +tcharm_stacksize 32K +balancer RefineLB\n\nRunning with ampirun\n~~~~~~~~~~~~~~~~~~~~\n\nFor compliance with the MPI standard and simpler execution, AMPI ships\nwith the ``ampirun`` script that is similar to ``mpirun`` provided by\nother MPI runtimes. As with ``charmrun``, ``ampirun`` is copied\nautomatically to the program directory when compiling an application\nwith ``ampicc``.\n\nThe basic usage of ampirun is as follows:\n\n.. code-block:: bash\n\n   $ ./ampirun -np 16 --host h1,h2,h3,h4 ./pgm\n\nThis command will create 16 (non-virtualized) ranks and distribute them\non the hosts h1-h4.\n\nWhen using the ``-vr`` option, AMPI will create the number of ranks\nspecified by the ``-np`` parameter as virtual ranks, and will create\nonly one process per host:\n\n.. code-block:: bash\n\n   $ ./ampirun -np 16 --host h1,h2,h3,h4 -vr ./pgm\n\nOther options (such as the load balancing strategy), can be specified in\nthe same way as for charmrun:\n\n.. code-block:: bash\n\n   $ ./ampirun -np 16 ./pgm +balancer RefineLB\n\nOther options\n~~~~~~~~~~~~~\n\nNote that for AMPI programs compiled with gfortran, users may need to\nset the following environment variable to see program output to stdout:\n\n.. code-block:: bash\n\n   $ export GFORTRAN_UNBUFFERED_ALL=1\n\n.. [1]\n   Currently, AMPI supports the MPI-2.2 standard, and the MPI-3.1\n   standard is under active development, though we already support\n   non-blocking and neighborhood collectives among other MPI-3.1\n   features.\n\n.. [2]\n   http://www-unix.mcs.anl.gov/romio/\n\n.. [3]\n   http://www.eclipse.org/photran\n\n.. [4]\n   http://rosecompiler.org/\n\n.. [5]\n   Currently, we assume that the interface code, which does mapping and\n   interpolation among the boundary values of Fluids and Solids domain,\n   is integrated with one of Fluids and Solids.\n\n.. [PiP2018]\n   Atsushi Hori, Min Si, Balazs Gerofi, Masamichi Takagi, Jai Dayal, Pavan\n   Balaji, and Yutaka Ishikawa. 2018. Process-in-process: techniques for\n   practical address-space sharing.  In Proceedings of the 27th\n   International Symposium on High-Performance Parallel and Distributed\n   Computing (HPDC '18). ACM, New York, NY, USA,  131-143. DOI:\n   https://doi.org/10.1145/3208040.3208045\n",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/cmake/detect-features.cmake": "include(CheckTypeSize)\ninclude(CheckFunctionExists)\ninclude(CheckCXXSymbolExists)\ninclude(CheckCXXSourceCompiles)\ninclude(CheckCSourceCompiles)\ninclude(CheckCXXCompilerFlag)\n\n# C types and type sizes\ncheck_type_size(\"size_t\" size_t_size)\nif(${size_t_size} EQUAL 8)\n    set(CMK_SIZET_64BIT 1)\nelse()\n    set(CMK_SIZET_64BIT 0)\nendif()\n\nset(CMAKE_EXTRA_INCLUDE_FILES sys/types.h sys/socket.h)\nset(CMAKE_REQUIRED_LIBRARIES -lm ${CMAKE_DL_LIBS} -pthread)\nset(CMAKE_REQUIRED_DEFINITIONS -D_GNU_SOURCE)\n\ncheck_type_size(\"GROUP_AFFINITY\" HAVE_GROUP_AFFINITY)\ncheck_type_size(\"GROUP_RELATIONSHIP\" HAVE_GROUP_RELATIONSHIP)\ncheck_type_size(\"KAFFINITY\" HAVE_KAFFINITY)\ncheck_type_size(\"long double\" CMK_LONG_DOUBLE_DEFINED)\ncheck_type_size(\"long long\" CMK_LONG_LONG_DEFINED)\ncheck_type_size(\"pthread_t\" HAVE_PTHREAD_T)\ncheck_type_size(\"socklen_t\" CMK_HAS_SOCKLEN)\ncheck_type_size(\"ssize_t\" HAVE_SSIZE_T)\ncheck_type_size(\"unsigned int\" SIZEOF_UNSIGNED_INT)\ncheck_type_size(\"unsigned long\" SIZEOF_UNSIGNED_LONG)\ncheck_type_size(\"void *\" SIZEOF_VOID_P)\ncheck_type_size(\"__int64\" CMK___int64_DEFINED)\ncheck_type_size(\"__int128_t\" CMK___int128_t_DEFINED)\ncheck_type_size(\"__int128\" CMK___int128_DEFINED)\ncheck_type_size(\"__int128\" CMK_HAS_INT16)\n\n# C++ types\ncheck_type_size(\"std::void_t\" CMK_HAS_STD_VOID_T LANGUAGE CXX)\n\n# C header files\ncheck_include_file(alloca.h CMK_HAS_ALLOCA_H)\ncheck_include_file(ctype.h HAVE_CTYPE_H)\ncheck_include_file(cuda.h HAVE_CUDA_H)\ncheck_include_file(dirent.h HAVE_DIRENT_H)\ncheck_include_file(dlfcn.h HAVE_DLFCN_H)\ncheck_include_file(elf.h CMK_HAS_ELF_H)\ncheck_include_file(inttypes.h HAVE_INTTYPES_H)\ncheck_include_file(kstat.h HAVE_KSTAT_H)\ncheck_include_file(libudev.h HAVE_LIBUDEV_H)\ncheck_include_file(malloc.h HAVE_MALLOC_H)\ncheck_include_file(malloc.h CMK_HAS_MALLOC_H)\ncheck_include_file(memory.h HAVE_MEMORY_H)\ncheck_include_file(numaif.h HAVE_NUMAIF_H)\ncheck_include_file(pthread_np.h HAVE_PTHREAD_NP_H)\ncheck_include_file(stdlib.h HAVE_STDLIB_H)\ncheck_include_file(string.h HAVE_STRING_H)\ncheck_include_file(strings.h HAVE_STRINGS_H)\ncheck_include_file(unistd.h HAVE_UNISTD_H)\ncheck_include_file(regex.h CMK_HAS_REGEX_H)\ncheck_include_file(values.h CMK_HAS_VALUES_H)\ncheck_include_file(stdint.h CMK_HAS_STDINT_H)\ncheck_include_file(sys/utsname.h HAVE_SYS_UTSNAME_H)\ncheck_include_file(sys/sysctl.h HAVE_SYS_SYSCTL_H)\ncheck_include_file(sys/stat.h HAVE_SYS_STAT_H)\ncheck_include_file(sys/param.h HAVE_SYS_PARAM_H)\ncheck_include_file(sys/mman.h HAVE_SYS_MMAN_H)\ncheck_include_file(sys/lgrp_user.h HAVE_SYS_LGRP_USER_H)\ncheck_include_file(sys/cpuset.h HAVE_SYS_CPUSET_H)\ncheck_include_file(valgrind/valgrind.h HAVE_VALGRIND_VALGRIND_H)\ncheck_include_file(Multiprocessing.h CMK_HAS_MULTIPROCESSING_H) # for Apple\n\n# C++ header files\ncheck_include_file_cxx(atomic CMK_HAS_CXX11_ATOMIC)\ncheck_include_file_cxx(cstdatomic CMK_HAS_CXX0X_CSTDATOMIC)\ncheck_include_file_cxx(regex CMK_HAS_REGEX)\n\n# C functions\ncheck_function_exists(_putenv HAVE__PUTENV)\ncheck_function_exists(_strdup HAVE__STRDUP)\ncheck_function_exists(asctime CMK_HAS_ASCTIME)\ncheck_function_exists(backtrace CMK_USE_BACKTRACE)\ncheck_function_exists(bindprocessor CMK_HAS_BINDPROCESSOR)\ncheck_function_exists(clz HAVE_CLZ)\ncheck_function_exists(clzl HAVE_CLZL)\ncheck_symbol_exists(dlopen dlfcn.h CMK_DLL_USE_DLOPEN)\nset(CMK_HAS_DLOPEN ${CMK_DLL_USE_DLOPEN})\ncheck_symbol_exists(dlmopen dlfcn.h CMK_HAS_DLMOPEN)\ncheck_function_exists(fabsf HAVE_DECL_FABSF)\ncheck_function_exists(fabsf CMK_HAS_FABSF)\ncheck_symbol_exists(fdatasync unistd.h CMK_HAS_FDATASYNC_FUNC)\ncheck_function_exists(fsync CMK_HAS_FSYNC_FUNC)\ncheck_function_exists(ffs HAVE_FFS)\ncheck_function_exists(ffsl HAVE_FFSL)\ncheck_function_exists(fls HAVE_FLS)\ncheck_function_exists(flsl HAVE_FLSL)\ncheck_function_exists(getexecname HAVE_DECL_GETEXECNAME)\ncheck_function_exists(gethostname CMK_HAS_GETHOSTNAME)\ncheck_function_exists(getifaddrs CMK_HAS_GETIFADDRS)\ncheck_function_exists(getpagesize HAVE_GETPAGESIZE)\ncheck_function_exists(getpagesize CMK_HAS_GETPAGESIZE)\ncheck_function_exists(getpid CMK_HAS_GETPID)\ncheck_function_exists(getprogname HAVE_DECL_GETPROGNAME)\ncheck_symbol_exists(get_myaddress rpc/rpc.h CMK_HAS_GET_MYADDRESS)\ncheck_function_exists(host_info HAVE_HOST_INFO)\ncheck_function_exists(kill CMK_HAS_KILL)\ncheck_symbol_exists(log2 math.h CMK_HAS_LOG2)\ncheck_function_exists(mallinfo CMK_HAS_MALLINFO)\ncheck_function_exists(mkstemp CMK_USE_MKSTEMP)\ncheck_function_exists(mmap CMK_HAS_MMAP)\ncheck_symbol_exists(MAP_ANON sys/mman.h CMK_HAS_MMAP_ANON)\ncheck_symbol_exists(MAP_NORESERVE sys/mman.h CMK_HAS_MMAP_NORESERVE)\ncheck_function_exists(mprotect CMK_HAS_MPROTECT)\ncheck_symbol_exists(MPI_Init_thread mpi.h CMK_MPI_INIT_THREAD)\ncheck_function_exists(mstats CMK_HAS_MSTATS)\ncheck_function_exists(ntohl CMK_HAS_NTOHL)\ncheck_function_exists(offsetof CMK_HAS_OFFSETOF)\ncheck_function_exists(openat HAVE_OPENAT)\ncheck_function_exists(poll CMK_USE_POLL)\ncheck_function_exists(popen CMK_HAS_POPEN)\ncheck_function_exists(posix_memalign HAVE_POSIX_MEMALIGN)\ncheck_symbol_exists(pthread_getaffinity_np pthread.h HAVE_DECL_PTHREAD_GETAFFINITY_NP)\ncheck_symbol_exists(pthread_setaffinity_np pthread.h HAVE_DECL_PTHREAD_SETAFFINITY_NP)\nset(CMK_HAS_PTHREAD_SETAFFINITY ${HAVE_DECL_PTHREAD_SETAFFINITY_NP})\ncheck_symbol_exists(pthread_spin_lock pthread.h CMK_HAS_SPINLOCK)\ncheck_symbol_exists(RTLD_DEFAULT dlfcn.h CMK_HAS_RTLD_DEFAULT)\ncheck_symbol_exists(RTLD_NEXT dlfcn.h CMK_HAS_RTLD_NEXT)\ncheck_function_exists(readlink CMK_HAS_READLINK)\ncheck_function_exists(realpath CMK_HAS_REALPATH)\ncheck_symbol_exists(RUSAGE_THREAD sys/resource.h CMK_HAS_RUSAGE_THREAD)\ncheck_function_exists(sbrk CMK_HAS_SBRK)\ncheck_function_exists(sched_setaffinity CMK_HAS_SETAFFINITY)\ncheck_function_exists(setlocale HAVE_SETLOCALE)\ncheck_symbol_exists(setpriority sys/resource.h CMK_HAS_SETPRIORITY)\ncheck_function_exists(sleep CMK_HAS_SLEEP)\ncheck_function_exists(snprintf HAVE_DECL_SNPRINTF)\ncheck_function_exists(sqrtf CMK_HAS_SQRTF)\ncheck_function_exists(strcasecmp HAVE_DECL_STRCASECMP)\ncheck_function_exists(strftime HAVE_STRFTIME)\ncheck_function_exists(strncasecmp HAVE_STRNCASECMP)\ncheck_function_exists(strtoull HAVE_DECL_STRTOULL)\ncheck_function_exists(strtoull HAVE_STRTOULL)\ncheck_function_exists(sync CMK_HAS_SYNC_FUNC)\ncheck_function_exists(system CMK_HAS_SYSTEM)\ncheck_function_exists(sysctl HAVE_SYSCTL)\ncheck_function_exists(sysctlbyname HAVE_SYSCTLBYNAME)\ncheck_function_exists(uname HAVE_UNAME)\ncheck_function_exists(usleep CMK_HAS_USLEEP)\n\n\n# Check Fortran naming scheme\n\nset(CMK_FORTRAN_USES_TWOSCORE 0)\nset(CMK_FORTRAN_USES_ONESCORE 0)\nset(CMK_FORTRAN_USES_NOSCORE 0)\nset(CMK_FORTRAN_USES_ALLCAPS 0)\n\nif(${CMK_CAN_LINK_FORTRAN})\n  if(${FortranCInterface_GLOBAL_SUFFIX} STREQUAL \"__\")\n    set(CMK_FORTRAN_USES_TWOSCORE 1)\n  elseif(${FortranCInterface_GLOBAL_SUFFIX} STREQUAL \"_\")\n    set(CMK_FORTRAN_USES_ONESCORE 1)\n  elseif(${FortranCInterface_GLOBAL_SUFFIX} STREQUAL \"\")\n    set(CMK_FORTRAN_USES_NOSCORE 1)\n  elseif(${FortranCInterface_GLOBAL_CASE} STREQUAL \"UPPER\")\n    set(CMK_FORTRAN_USES_ALLCAPS 1)\n  endif()\nendif()\n\n# Check compiler flags\n\ncheck_cxx_compiler_flag(\"-mno-tls-direct-seg-refs\" CMK_COMPILER_KNOWS_TLSDIRECTSEGREFS)\n\ncheck_cxx_compiler_flag(\"-fno-stack-protector\" CMK_COMPILER_KNOWS_FNOSTACKPROTECTOR)\nif(${CMK_COMPILER_KNOWS_FNOSTACKPROTECTOR})\n  set(OPTS_CC \"${OPTS_CC} -fno-stack-protector\")\n  set(OPTS_CXX \"${OPTS_CXX} -fno-stack-protector\")\nendif()\n\ncheck_cxx_compiler_flag(\"-fno-lifetime-dse\" CMK_COMPILER_KNOWS_LIFETIMEDSE)\nif(${CMK_COMPILER_KNOWS_LIFETIMEDSE})\n  set(OPTS_CXX \"${OPTS_CXX} -fno-lifetime-dse\")\nendif()\n\n# Complex tests\n\nif(${CMAKE_SYSTEM_NAME} STREQUAL \"Windows\" OR ${CMAKE_SYSTEM_NAME} STREQUAL \"Darwin\")\n  set(CMK_CAN_GET_BINARY_PATH 1)\nelseif(${CMK_HAS_READLINK} OR ${CMK_HAS_REALPATH})\n  set(CMK_CAN_GET_BINARY_PATH 1)\nelse()\n  set(CMK_CAN_GET_BINARY_PATH 0)\nendif()\n\nfile(WRITE ${CMAKE_BINARY_DIR}/test_file \"\")\nexecute_process(COMMAND cp -p test_file test_file2 ERROR_VARIABLE CP_P_OPTION_ERROR)\nif(NOT ${CP_P_OPTION_ERROR} STREQUAL \"\")\n  set(CP \"cp\")\nelse()\n  set(CP \"cp -p\")\nendif()\nfile(REMOVE ${CMAKE_BINARY_DIR}/test_file ${CMAKE_BINARY_DIR}/test_file2)\n\ncheck_cxx_source_compiles(\"\n#include <type_traits>\nstruct s { s(int a) { } };\nint main()\n{\n  return std::is_constructible<s, int>::value;\n}\" CMK_HAS_IS_CONSTRUCTIBLE)\n\ncheck_cxx_source_compiles(\"\n#include <vector>\n#include <iterator>\nint main()\n{\n  std::vector<int> tree;\n  return std::distance(tree.begin(), tree.end());\n}\n\" CMK_HAS_STD_DISTANCE)\n\ncheck_c_source_compiles(\"\nint main()\n{\n  __sync_synchronize();\n}\n\" CMK_C_SYNC_SYNCHRONIZE_PRIMITIVE)\n\ncheck_c_source_compiles(\"\nint main()\n{\n  int t=1;\n  __sync_add_and_fetch(&t, 1);\n}\n\" CMK_C_SYNC_ADD_AND_FETCH_PRIMITIVE)\n\ncheck_cxx_source_compiles(\"\n#include <stdlib.h>\nclass er {\n protected:\n   void operator()(char &v,const char *desc=NULL) {};\n   void operator()(signed char &v,const char *desc=NULL) {};\n};\nint main() {}\n\" CMK_SIGNEDCHAR_DIFF_CHAR)\n\ncheck_c_source_compiles(\"\n#include <sys/personality.h>\nint main() {\n    int orig_persona = personality(0xffffffff);\n    personality(orig_persona | ADDR_NO_RANDOMIZE);\n    return 0;\n}\n\" CMK_HAS_ADDR_NO_RANDOMIZE)\n\ncheck_cxx_source_compiles(\"\n#include <type_traits>\nint main()\n{\n  return std::alignment_of<int>::value;\n}\n\" CMK_HAS_ALIGNMENT_OF)\n\ncheck_c_source_compiles(\"\n#define _GNU_SOURCE\n#include <sys/uio.h>\n#include <errno.h>\nint main() {\n  pid_t pid;\n  struct iovec *local, *remote;\n  int nread = process_vm_readv(pid, local, 1, remote, 1, 0);\n  nread = process_vm_writev(pid, local, 1, remote, 1, 0);\n  return errno;\n}\n\" CMK_HAS_CMA)\n\ncheck_c_source_compiles(\"\n#include <stdio.h>\n#include <papi.h>\nint main() {\n    if (PAPI_library_init(PAPI_VER_CURRENT) != PAPI_VER_CURRENT) return 1;\n    return 0;\n}\n\" CMK_HAS_COUNTER_PAPI)\n\ncheck_c_source_compiles(\"\n#define _GNU_SOURCE\n#define __USE_GNU\n#include <link.h>\n#include <stddef.h>\nstatic int callback(struct dl_phdr_info* info, size_t size, void* data)\n{\n  return 0;\n}\nint main()\n{\n  dl_iterate_phdr(callback, NULL);\n  return 0;\n}\n\" CMK_HAS_DL_ITERATE_PHDR)\n\ncheck_c_source_compiles(\"\nextern int __executable_start;\nint main()\n{\n  return __executable_start;\n}\n\" CMK_HAS_EXECUTABLE_START)\n\ncheck_cxx_source_compiles(\"\n#include <iterator>\ntemplate <typename T> // T models Input Iterator\ntypename std::iterator_traits<T>::value_type accumulate(T first, T last)\n{\n      typename std::iterator_traits<T>::value_type result = 0;\n      while(first != last)\n            result += *first++;\n      return result;\n}\nint main() {}\n\" CMK_HAS_ITERATOR_TRAITS)\n\ncheck_c_source_compiles(\"\n#include <stdlib.h>\n#include <stdio.h>\n#include <linux/mempolicy.h>\n#include <numaif.h>\n#include <numa.h>\n\nint main()\n{\n  if (get_mempolicy(NULL, NULL, 0, 0, 0) == 0) return 0;\n  return -1;\n}\n\" CMK_HAS_NUMACTRL)\n\ncheck_c_source_compiles(\"\n#include <pmi.h>\nint main() {\n    int nid;\n    PMI_Get_nid(0, &nid);\n\n    return 0;\n}\n\" CMK_HAS_PMI_GET_NID)\n\ncheck_c_source_compiles(\"\n#include <rca_lib.h>\nint main() {\n    rca_mesh_coord_t xyz;\n    rca_get_meshcoord(0, &xyz);\n\n    return 0;\n}\n\" CMK_HAS_RCALIB)\n\ncheck_c_source_compiles(\"\n#include <rca_lib.h>\nint main() {\n    rca_mesh_coord_t xyz;\n    rca_get_max_dimension(&xyz);\n\n    return 0;\n}\n\" CMK_HAS_RCA_MAX_DIMENSION)\n\ncheck_cxx_source_compiles(\"\n#include <list>\n#include <iterator>\nint main()\n{\n  using namespace std;\n  list<int> L;\n  inserter ( L, L.end ( ) ) = 500;\n}\n\" CMK_HAS_STD_INSERTER )\n\ncheck_c_source_compiles(\"\n__thread unsigned long long int x;\nstatic __thread  int y;\nint main(void)\n{\n  x = 1;\n  y = 1;\n}\n\" CMK_HAS_TLS_VARIABLES )\n\ncheck_cxx_source_compiles(\"\n#include <typeinfo>\nint main() {\n  int x;\n  typeid(x).name();\n}\n\" CMK_HAS_TYPEINFO )\n\ncheck_c_source_compiles(\"\n#include <setjmp.h>\nint main() {\n  jmp_buf buf;\n  _setjmp(buf);\n  _longjmp(buf, 0);\n}\n\" CMK_HAS_UNDERSCORE_SETJMP )\n\ncheck_c_source_compiles(\"\n#include <infiniband/verbs.h>\nvoid test()\n{\n    struct ibv_context    *context;\n    int ibPort;\n    struct ibv_port_attr attr;\n    if (ibv_query_port(context, ibPort, &attr) != 0) return;\n    if (attr.link_layer == IBV_LINK_LAYER_INFINIBAND)  return;\n}\n\" CMK_IBV_PORT_ATTR_HAS_LINK_LAYER)\n\ncheck_cxx_source_compiles(\"\nclass foo {\npublic:\n  void operator delete(void*p){};\n  void operator delete(void*p,int*){};\n};\nint main() {}\n\" CMK_MULTIPLE_DELETE)\n\nfile(READ ${CMAKE_SOURCE_DIR}/src/util/ckdll_system.C ckdll_system)\ncheck_cxx_source_compiles(\"${ckdll_system}\\n int main(){}\" CMK_SIGSAFE_SYSTEM)\n\nfile(READ ${CMAKE_SOURCE_DIR}/src/util/ckdll_win32.C ckdll_win32)\ncheck_cxx_source_compiles(\"${ckdll_win32}\\n int main(){}\" CMK_DLL_USE_WIN32)\n\ncheck_c_source_compiles([=[\nvoid main() {\n  void * m1, * m2;\n  asm volatile (\"movq %%fs:0x0, %0\\\\n\\t\"\n                \"movq %1, %%fs:0x0\\\\n\\t\"\n                : \"=&r\"(m1)\n                : \"r\"(m2));\n}\n]=] CMK_TLS_SWITCHING_X86_64)\n\ncheck_c_source_compiles([=[\nvoid main() {\n  void * m1, * m2;\n  asm volatile (\"movl %%gs:0x0, %0\\\\n\\t\"\n                \"movl %1, %%gs:0x0\\\\n\\t\"\n                : \"=&r\"(m1)\n                : \"r\"(m2));\n}\n]=] CMK_TLS_SWITCHING_X86)\n\n\ncheck_c_source_compiles(\"\n#include <stdint.h>\n#include <gni_pub.h>\nint main() {\n    gni_bi_desc_t gni_bi_desc;\n    uint32_t gni_device_id = 0;\n    gni_return_t gni_rc = GNI_GetBIConfig(gni_device_id, &gni_bi_desc);\n    if (gni_rc == GNI_RC_SUCCESS) {\n    }\n    return 0;\n}\n\" CMK_BALANCED_INJECTION_API)\n\nif(${CMK_BUILD_OFI} EQUAL 1)\n  set(tmp ${CMAKE_REQUIRED_LIBRARIES})\n  set(CMAKE_REQUIRED_LIBRARIES \"${CMAKE_REQUIRED_LIBRARIES} -lfabric\")\n  check_c_source_compiles(\"\n    #include <rdma/fabric.h>\n    int main(int argc, char **argv)\n    {\n      struct fi_info *providers;\n      int ret = fi_getinfo(FI_VERSION(1,0), NULL, NULL, 0ULL, NULL, &providers);\n      return 0;\n    }\n  \" CMK_BUILD_ON_OFI)\n  set(CMAKE_REQUIRED_LIBRARIES ${tmp})\n  if(\"${CMK_BUILD_ON_OFI}\" STREQUAL \"\")\n    message(FATAL_ERROR \"Unable to build ofi.\")\n  endif()\nendif()\n\ncheck_cxx_source_compiles(\"\n#include <cstddef>\nint main() {\n  extern void *(*__morecore)(ptrdiff_t);\n  __morecore(0);\n  return 0;\n}\n\" CMK_EXPECTS_MORECORE)\n\ncheck_c_source_compiles(\"\n#include <ucontext.h>\nstruct _libc_fpstate   fpstate;\nfpregset_t *fp;\nint main() {}\n\" CMK_CONTEXT_FPU_POINTER)\n\ncheck_c_source_compiles(\"\n#include <ucontext.h>\nint main()\n{\n  ucontext_t context;\n  context.uc_mcontext.uc_regs = 0;\n}\n\" CMK_CONTEXT_FPU_POINTER_UCREGS)\n\ncheck_c_source_compiles(\"\n#include <ucontext.h>\nvrregset_t *v_regs;\nucontext_t  uc;\n\nint main()\n{\n  vrregset_t *ptr = uc.uc_mcontext.v_regs;\n}\n\" CMK_CONTEXT_V_REGS)\n\ncheck_c_source_compiles(\"\ninline static int foo()\n{\n  return 1;\n}\nint main() {}\n\" CMK_C_INLINE)\n\ncheck_c_source_compiles(\"\nint main(void)\n{\n  unsigned long long int v=0;\n  int *lo=0+(int *)&v;\n  int *hi=1+(int *)&v;\n  __asm__ __volatile__(\n      \\\"rdtsc; movl %%edx,%0; movl %%eax,%1\\\"\n      : /* output  */ \\\"=m\\\" (*hi), \\\"=m\\\" (*lo)\n      : /* input */\n      : /* trashes */ \\\"%edx\\\", \\\"%eax\\\"\n  );\n  return v;\n}\n\" CMK_GCC_X86_ASM)\n\ncheck_c_source_compiles(\"\nint main(void)\n{\n  int x;\n  asm(\\\"lock incl %0\\\" :: \\\"m\\\" (x));\n  asm(\\\"lock decl %0\\\" :: \\\"m\\\" (x));\n  return x;\n}\n\" CMK_GCC_X86_ASM_ATOMICINCREMENT)\n\n# Programs\nfind_program(SYNC sync)\nif(SYNC)\n    set(CMK_HAS_SYNC 1)\nendif()\n\n\nset(CMK_MACHINE_NAME \\\"${CHARM_PLATFORM}\\\")\nset(CHARM_VERSION ${PROJECT_VERSION})\nset(CMK_CCS_AVAILABLE 1)\nset(CMK_HAS_OPENMP ${OPENMP_FOUND})\n\nif(${CMAKE_CXX_COMPILER_ID} STREQUAL \"AppleClang\")\n  # needs external library for OpenMP support, disable for now.\n  set(CMK_HAS_OPENMP 0)\nendif()\n\n# Fortran module names\nset(CMK_MOD_NAME_ALLCAPS 0)\nset(CMK_MOD_EXT mod)\n\n# Create conv-autoconfig.h\nget_cmake_property(_variableNames VARIABLES)\nlist (SORT _variableNames)\n\nset(optfile ${CMAKE_BINARY_DIR}/include/conv-autoconfig.h)\nfile(REMOVE ${optfile})\n\nforeach (v ${_variableNames})\n    if((\"${v}\" MATCHES \"^CMK_\"  OR \"${v}\" MATCHES \"^SIZEOF_\" OR \"${v}\" MATCHES \"^CHARM_\") AND NOT \"${v}\" MATCHES \"_CODE$\")\n        if(\"${${v}}\" STREQUAL \"\" OR \"${${v}}\" STREQUAL \"FALSE\")\n            set(${v} 0)\n        elseif(\"${${v}}\" STREQUAL \"TRUE\")\n            set(${v} 1)\n        endif()\n        file(APPEND ${optfile} \"#define ${v} ${${v}}\\n\" )\n    elseif(\"${v}\" MATCHES \"^HAVE_\")\n        if(\"${${v}}\" STREQUAL \"\" OR \"${${v}}\" STREQUAL \"FALSE\")\n            set(${v} 0)\n            file(APPEND ${optfile} \"/* #define ${v} ${${v}} */\\n\" )\n        elseif(\"${${v}}\" STREQUAL \"TRUE\")\n            set(${v} 1)\n            file(APPEND ${optfile} \"#define ${v} ${${v}}\\n\" )\n        endif()\n    endif()\nendforeach()\n"
    },
    "skipped": [
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/src/libs/ck-libs/metis/manual/manual.pdf",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/src/libs/ck-libs/ampi/romio/doc/users-guide.pdf",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/src/libs/ck-libs/ampi/romio/doc/source-guide.tex",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/src/libs/ck-libs/ampi/romio/adio/common/ad_iwrite_coll.pdf",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/src/libs/ck-libs/ampi/romio/adio/common/ad_iread_coll.pdf",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/src/langs/charj/lib/antlr-3.2.jar",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/src/langs/charj/lib/ant-antlr3.jar",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/src/langs/charj/lib/JSAP-2.1.jar",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/src/ck-ldb/GridCommRefineLB.C",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/src/ck-ldb/rf_model/big_weakmodel.txt.gz",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/src/ck-ldb/rf_model/big_leafdist.txt.gz",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/src/ck-cp/NelderMeadStateDiagram.pdf",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/examples/pose/LBSim/sample-graph.pdf",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/examples/charm++/wave2d/screenshot.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/examples/charm++/satisfiability/TNM/TNM.pdf",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/examples/charm++/satisfiability/TNM/TNM.C",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/examples/bigsim/tools/text2log/examples.tgz",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/viewlog.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/userevent.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/usageprofile.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/timeprofile.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/timeline.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/standard_dialog.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/piechart.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/performancecounters.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/overview.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/outlier_dialog.jpg",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/mainwindow.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/histogram.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/graph.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/front-with-summary.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/commhistogram.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/apoa1_512_overviewEPColored.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/apoa1_512_overview.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/apoa1_512_outlierWithClusters.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/apoa1_512_CommTimeProfile.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/apoa1_512_CommProcessorProfile.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/apoa1_128_userEventsView.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/animation.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/NoiseMiner2.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/projections/fig/NoiseMiner1.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/parfum/fig/parfum_structure.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/netfem/fig/example.pdf",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/mblock/fig/terminology.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/mblock/fig/nodeloc.pdf",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/mblock/fig/indexing.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/mblock/fig/ghostwidth.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/mblock/fig/decompose.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/fem/fig/sym_ghost.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/fem/fig/simple_mesh.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/fem/fig/partitioned_mesh.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/fem/fig/layout.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/fem/fig/indexlists.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/fem/fig/ghost_pre.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/fem/fig/ghost_node.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/fem/fig/ghost_edge.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/fem/fig/forcedecomp.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/fem/fig/create_field.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/fem/fig/conn_indexing_old.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/fem/fig/conn_indexing.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/debugger/figs/snapshot4.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/debugger/figs/snapshot4-crop.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/debugger/figs/snapshot3.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/debugger/figs/snapshot2.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/debugger/figs/snapshot1.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/debugger/figs/menu.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/debugger/figs/memoryView.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/debugger/figs/memoryStatistics.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/debugger/figs/memoryLeaking.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/debugger/figs/memoryInspector.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/debugger/figs/arrayelement.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/charm++/fig/pup.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/charm++/fig/ckgraph.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/charj/fig/fig1.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/charj/fig/fig0.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/bigsim/figures/event_diagram2.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/bigsim/figures/event_diagram2.pdf",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/bigsim/figures/event_diagram.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/bigsim/figures/event_diagram.pdf",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/bigsim/figures/detailedsim_newer.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/bigsim/figures/InterpolationFlow.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/bigsim/figures/InterpolationFlow.pdf",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/bignetsim/figures/detailedsim_newer.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/ampi/figs/virtualization.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/ampi/figs/prac.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/ampi/figs/migrate.png",
        "/var/tmp/sochat1/spack-stage/spack-stage-charmpp-6.10.2-2hqvsyjoajitbpsjkfafd33idv4qs72e/spack-src/doc/ampi/figs/global.png"
    ],
    "total_files": 6152
}